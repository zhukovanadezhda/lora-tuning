{
  "mode": "lora",
  "model": "bert-base-uncased",
  "metrics": {
    "eval_loss": 0.2464117407798767,
    "eval_accuracy": 0.9071100917431193,
    "eval_runtime": 1.3967,
    "eval_samples_per_second": 624.31,
    "eval_steps_per_second": 10.023,
    "epoch": 2.0
  },
  "params": {
    "total_parameters": 110073602,
    "trainable_parameters": 591362,
    "trainable_percentage": 0.5372423444451286
  },
  "elapsed_sec": 519.219667673111,
  "config": {
    "mode": "lora",
    "model_name": "bert-base-uncased",
    "max_length": 128,
    "epochs": 2,
    "lr": 0.0001,
    "train_batch_size": 16,
    "eval_batch_size": 64,
    "warmup_ratio": 0.06,
    "r": 16,
    "alpha": 16.0,
    "lora_dropout": 0.0,
    "output_dir": "outputs/runs",
    "results_path": "/content/drive/MyDrive/lora-tuning/results/lora_r_16.json"
  },
  "log_history": [
    {
      "loss": 0.728,
      "grad_norm": 5.130213260650635,
      "learning_rate": 9.683794466403162e-06,
      "epoch": 0.011876484560570071,
      "step": 50
    },
    {
      "loss": 0.7055,
      "grad_norm": 1.3721309900283813,
      "learning_rate": 1.956521739130435e-05,
      "epoch": 0.023752969121140142,
      "step": 100
    },
    {
      "loss": 0.6938,
      "grad_norm": 1.3166019916534424,
      "learning_rate": 2.9446640316205537e-05,
      "epoch": 0.035629453681710214,
      "step": 150
    },
    {
      "loss": 0.6798,
      "grad_norm": 2.360806703567505,
      "learning_rate": 3.932806324110672e-05,
      "epoch": 0.047505938242280284,
      "step": 200
    },
    {
      "loss": 0.6611,
      "grad_norm": 1.9368113279342651,
      "learning_rate": 4.9209486166007906e-05,
      "epoch": 0.05938242280285035,
      "step": 250
    },
    {
      "loss": 0.6198,
      "grad_norm": 2.206757068634033,
      "learning_rate": 5.90909090909091e-05,
      "epoch": 0.07125890736342043,
      "step": 300
    },
    {
      "loss": 0.4681,
      "grad_norm": 2.530550956726074,
      "learning_rate": 6.897233201581029e-05,
      "epoch": 0.0831353919239905,
      "step": 350
    },
    {
      "loss": 0.3448,
      "grad_norm": 2.2404775619506836,
      "learning_rate": 7.885375494071147e-05,
      "epoch": 0.09501187648456057,
      "step": 400
    },
    {
      "loss": 0.351,
      "grad_norm": 3.253769874572754,
      "learning_rate": 8.873517786561266e-05,
      "epoch": 0.10688836104513064,
      "step": 450
    },
    {
      "loss": 0.3333,
      "grad_norm": 4.582415580749512,
      "learning_rate": 9.861660079051383e-05,
      "epoch": 0.1187648456057007,
      "step": 500
    },
    {
      "loss": 0.3258,
      "grad_norm": 1.2477284669876099,
      "learning_rate": 9.945665908516553e-05,
      "epoch": 0.13064133016627077,
      "step": 550
    },
    {
      "loss": 0.3702,
      "grad_norm": 1.9070266485214233,
      "learning_rate": 9.88248673237301e-05,
      "epoch": 0.14251781472684086,
      "step": 600
    },
    {
      "loss": 0.3216,
      "grad_norm": 1.5348763465881348,
      "learning_rate": 9.819307556229466e-05,
      "epoch": 0.1543942992874109,
      "step": 650
    },
    {
      "loss": 0.2963,
      "grad_norm": 3.172908306121826,
      "learning_rate": 9.756128380085923e-05,
      "epoch": 0.166270783847981,
      "step": 700
    },
    {
      "loss": 0.3255,
      "grad_norm": 1.9609016180038452,
      "learning_rate": 9.69294920394238e-05,
      "epoch": 0.17814726840855108,
      "step": 750
    },
    {
      "loss": 0.3186,
      "grad_norm": 2.4881019592285156,
      "learning_rate": 9.629770027798838e-05,
      "epoch": 0.19002375296912113,
      "step": 800
    },
    {
      "loss": 0.3409,
      "grad_norm": 1.9672826528549194,
      "learning_rate": 9.566590851655295e-05,
      "epoch": 0.20190023752969122,
      "step": 850
    },
    {
      "loss": 0.3129,
      "grad_norm": 2.92983078956604,
      "learning_rate": 9.503411675511752e-05,
      "epoch": 0.21377672209026127,
      "step": 900
    },
    {
      "loss": 0.2995,
      "grad_norm": 3.7582197189331055,
      "learning_rate": 9.44023249936821e-05,
      "epoch": 0.22565320665083136,
      "step": 950
    },
    {
      "loss": 0.2948,
      "grad_norm": 1.668779969215393,
      "learning_rate": 9.377053323224667e-05,
      "epoch": 0.2375296912114014,
      "step": 1000
    },
    {
      "loss": 0.2798,
      "grad_norm": 4.066615104675293,
      "learning_rate": 9.313874147081122e-05,
      "epoch": 0.2494061757719715,
      "step": 1050
    },
    {
      "loss": 0.296,
      "grad_norm": 3.2555739879608154,
      "learning_rate": 9.25069497093758e-05,
      "epoch": 0.26128266033254155,
      "step": 1100
    },
    {
      "loss": 0.27,
      "grad_norm": 3.6216375827789307,
      "learning_rate": 9.187515794794035e-05,
      "epoch": 0.27315914489311166,
      "step": 1150
    },
    {
      "loss": 0.2515,
      "grad_norm": 2.5546083450317383,
      "learning_rate": 9.124336618650493e-05,
      "epoch": 0.2850356294536817,
      "step": 1200
    },
    {
      "loss": 0.3033,
      "grad_norm": 2.037130355834961,
      "learning_rate": 9.06115744250695e-05,
      "epoch": 0.29691211401425177,
      "step": 1250
    },
    {
      "loss": 0.2926,
      "grad_norm": 1.3543736934661865,
      "learning_rate": 8.997978266363407e-05,
      "epoch": 0.3087885985748218,
      "step": 1300
    },
    {
      "loss": 0.2777,
      "grad_norm": 1.2978414297103882,
      "learning_rate": 8.934799090219864e-05,
      "epoch": 0.32066508313539194,
      "step": 1350
    },
    {
      "loss": 0.2766,
      "grad_norm": 2.02531099319458,
      "learning_rate": 8.871619914076321e-05,
      "epoch": 0.332541567695962,
      "step": 1400
    },
    {
      "loss": 0.2629,
      "grad_norm": 2.41560959815979,
      "learning_rate": 8.808440737932779e-05,
      "epoch": 0.34441805225653205,
      "step": 1450
    },
    {
      "loss": 0.2853,
      "grad_norm": 2.5185205936431885,
      "learning_rate": 8.745261561789235e-05,
      "epoch": 0.35629453681710216,
      "step": 1500
    },
    {
      "loss": 0.2941,
      "grad_norm": 1.7210880517959595,
      "learning_rate": 8.682082385645692e-05,
      "epoch": 0.3681710213776722,
      "step": 1550
    },
    {
      "loss": 0.2388,
      "grad_norm": 1.3357986211776733,
      "learning_rate": 8.618903209502148e-05,
      "epoch": 0.38004750593824227,
      "step": 1600
    },
    {
      "loss": 0.2911,
      "grad_norm": 1.7809562683105469,
      "learning_rate": 8.555724033358605e-05,
      "epoch": 0.3919239904988123,
      "step": 1650
    },
    {
      "loss": 0.276,
      "grad_norm": 2.84281587600708,
      "learning_rate": 8.492544857215062e-05,
      "epoch": 0.40380047505938244,
      "step": 1700
    },
    {
      "loss": 0.269,
      "grad_norm": 4.559872627258301,
      "learning_rate": 8.429365681071519e-05,
      "epoch": 0.4156769596199525,
      "step": 1750
    },
    {
      "loss": 0.2751,
      "grad_norm": 2.5665359497070312,
      "learning_rate": 8.366186504927976e-05,
      "epoch": 0.42755344418052255,
      "step": 1800
    },
    {
      "loss": 0.2848,
      "grad_norm": 3.956756591796875,
      "learning_rate": 8.303007328784434e-05,
      "epoch": 0.43942992874109266,
      "step": 1850
    },
    {
      "loss": 0.2707,
      "grad_norm": 1.5455870628356934,
      "learning_rate": 8.239828152640891e-05,
      "epoch": 0.4513064133016627,
      "step": 1900
    },
    {
      "loss": 0.2946,
      "grad_norm": 5.9370503425598145,
      "learning_rate": 8.176648976497347e-05,
      "epoch": 0.46318289786223277,
      "step": 1950
    },
    {
      "loss": 0.2725,
      "grad_norm": 2.673015594482422,
      "learning_rate": 8.113469800353804e-05,
      "epoch": 0.4750593824228028,
      "step": 2000
    },
    {
      "loss": 0.3334,
      "grad_norm": 2.398369550704956,
      "learning_rate": 8.050290624210261e-05,
      "epoch": 0.48693586698337293,
      "step": 2050
    },
    {
      "loss": 0.2477,
      "grad_norm": 2.826190233230591,
      "learning_rate": 7.987111448066717e-05,
      "epoch": 0.498812351543943,
      "step": 2100
    },
    {
      "loss": 0.2562,
      "grad_norm": 1.0492572784423828,
      "learning_rate": 7.923932271923174e-05,
      "epoch": 0.5106888361045131,
      "step": 2150
    },
    {
      "loss": 0.2681,
      "grad_norm": 2.0074622631073,
      "learning_rate": 7.860753095779631e-05,
      "epoch": 0.5225653206650831,
      "step": 2200
    },
    {
      "loss": 0.2438,
      "grad_norm": 2.638964891433716,
      "learning_rate": 7.797573919636088e-05,
      "epoch": 0.5344418052256532,
      "step": 2250
    },
    {
      "loss": 0.2583,
      "grad_norm": 1.3498282432556152,
      "learning_rate": 7.734394743492546e-05,
      "epoch": 0.5463182897862233,
      "step": 2300
    },
    {
      "loss": 0.2562,
      "grad_norm": 2.3314337730407715,
      "learning_rate": 7.671215567349002e-05,
      "epoch": 0.5581947743467933,
      "step": 2350
    },
    {
      "loss": 0.2332,
      "grad_norm": 3.9364571571350098,
      "learning_rate": 7.608036391205459e-05,
      "epoch": 0.5700712589073634,
      "step": 2400
    },
    {
      "loss": 0.2762,
      "grad_norm": 1.2641106843948364,
      "learning_rate": 7.544857215061916e-05,
      "epoch": 0.5819477434679335,
      "step": 2450
    },
    {
      "loss": 0.2431,
      "grad_norm": 2.3345274925231934,
      "learning_rate": 7.481678038918373e-05,
      "epoch": 0.5938242280285035,
      "step": 2500
    },
    {
      "loss": 0.2757,
      "grad_norm": 1.9939379692077637,
      "learning_rate": 7.41849886277483e-05,
      "epoch": 0.6057007125890737,
      "step": 2550
    },
    {
      "loss": 0.2642,
      "grad_norm": 3.1895430088043213,
      "learning_rate": 7.355319686631286e-05,
      "epoch": 0.6175771971496437,
      "step": 2600
    },
    {
      "loss": 0.2937,
      "grad_norm": 1.3561785221099854,
      "learning_rate": 7.292140510487743e-05,
      "epoch": 0.6294536817102138,
      "step": 2650
    },
    {
      "loss": 0.2372,
      "grad_norm": 0.7656920552253723,
      "learning_rate": 7.2289613343442e-05,
      "epoch": 0.6413301662707839,
      "step": 2700
    },
    {
      "loss": 0.302,
      "grad_norm": 4.06281042098999,
      "learning_rate": 7.165782158200658e-05,
      "epoch": 0.6532066508313539,
      "step": 2750
    },
    {
      "loss": 0.2699,
      "grad_norm": 2.6481361389160156,
      "learning_rate": 7.102602982057114e-05,
      "epoch": 0.665083135391924,
      "step": 2800
    },
    {
      "loss": 0.261,
      "grad_norm": 2.2579078674316406,
      "learning_rate": 7.039423805913571e-05,
      "epoch": 0.6769596199524941,
      "step": 2850
    },
    {
      "loss": 0.2468,
      "grad_norm": 2.1161959171295166,
      "learning_rate": 6.976244629770028e-05,
      "epoch": 0.6888361045130641,
      "step": 2900
    },
    {
      "loss": 0.2916,
      "grad_norm": 4.339254856109619,
      "learning_rate": 6.913065453626485e-05,
      "epoch": 0.7007125890736342,
      "step": 2950
    },
    {
      "loss": 0.2502,
      "grad_norm": 1.1989561319351196,
      "learning_rate": 6.849886277482942e-05,
      "epoch": 0.7125890736342043,
      "step": 3000
    },
    {
      "loss": 0.2578,
      "grad_norm": 1.296831727027893,
      "learning_rate": 6.7867071013394e-05,
      "epoch": 0.7244655581947743,
      "step": 3050
    },
    {
      "loss": 0.2424,
      "grad_norm": 4.138736724853516,
      "learning_rate": 6.723527925195856e-05,
      "epoch": 0.7363420427553444,
      "step": 3100
    },
    {
      "loss": 0.2845,
      "grad_norm": 1.6633412837982178,
      "learning_rate": 6.660348749052313e-05,
      "epoch": 0.7482185273159145,
      "step": 3150
    },
    {
      "loss": 0.2754,
      "grad_norm": 0.9847149848937988,
      "learning_rate": 6.59716957290877e-05,
      "epoch": 0.7600950118764845,
      "step": 3200
    },
    {
      "loss": 0.2271,
      "grad_norm": 2.7561233043670654,
      "learning_rate": 6.533990396765226e-05,
      "epoch": 0.7719714964370546,
      "step": 3250
    },
    {
      "loss": 0.2484,
      "grad_norm": 4.974383354187012,
      "learning_rate": 6.470811220621683e-05,
      "epoch": 0.7838479809976246,
      "step": 3300
    },
    {
      "loss": 0.2429,
      "grad_norm": 5.695943355560303,
      "learning_rate": 6.40763204447814e-05,
      "epoch": 0.7957244655581948,
      "step": 3350
    },
    {
      "loss": 0.2768,
      "grad_norm": 3.077216148376465,
      "learning_rate": 6.344452868334597e-05,
      "epoch": 0.8076009501187649,
      "step": 3400
    },
    {
      "loss": 0.2956,
      "grad_norm": 1.8104034662246704,
      "learning_rate": 6.281273692191055e-05,
      "epoch": 0.8194774346793349,
      "step": 3450
    },
    {
      "loss": 0.2407,
      "grad_norm": 3.427250385284424,
      "learning_rate": 6.218094516047512e-05,
      "epoch": 0.831353919239905,
      "step": 3500
    },
    {
      "loss": 0.2498,
      "grad_norm": 2.1083409786224365,
      "learning_rate": 6.154915339903969e-05,
      "epoch": 0.8432304038004751,
      "step": 3550
    },
    {
      "loss": 0.2294,
      "grad_norm": 2.7716877460479736,
      "learning_rate": 6.0917361637604255e-05,
      "epoch": 0.8551068883610451,
      "step": 3600
    },
    {
      "loss": 0.237,
      "grad_norm": 1.1511729955673218,
      "learning_rate": 6.028556987616881e-05,
      "epoch": 0.8669833729216152,
      "step": 3650
    },
    {
      "loss": 0.2427,
      "grad_norm": 0.9137362837791443,
      "learning_rate": 5.9653778114733385e-05,
      "epoch": 0.8788598574821853,
      "step": 3700
    },
    {
      "loss": 0.2576,
      "grad_norm": 2.414078712463379,
      "learning_rate": 5.902198635329795e-05,
      "epoch": 0.8907363420427553,
      "step": 3750
    },
    {
      "loss": 0.2625,
      "grad_norm": 2.3877577781677246,
      "learning_rate": 5.839019459186252e-05,
      "epoch": 0.9026128266033254,
      "step": 3800
    },
    {
      "loss": 0.2336,
      "grad_norm": 3.0930986404418945,
      "learning_rate": 5.7758402830427095e-05,
      "epoch": 0.9144893111638955,
      "step": 3850
    },
    {
      "loss": 0.2024,
      "grad_norm": 0.9355810880661011,
      "learning_rate": 5.712661106899167e-05,
      "epoch": 0.9263657957244655,
      "step": 3900
    },
    {
      "loss": 0.2489,
      "grad_norm": 1.8076703548431396,
      "learning_rate": 5.649481930755623e-05,
      "epoch": 0.9382422802850356,
      "step": 3950
    },
    {
      "loss": 0.2406,
      "grad_norm": 1.8584661483764648,
      "learning_rate": 5.5863027546120804e-05,
      "epoch": 0.9501187648456056,
      "step": 4000
    },
    {
      "loss": 0.2338,
      "grad_norm": 1.1374468803405762,
      "learning_rate": 5.5231235784685376e-05,
      "epoch": 0.9619952494061758,
      "step": 4050
    },
    {
      "loss": 0.2183,
      "grad_norm": 1.7706670761108398,
      "learning_rate": 5.4599444023249934e-05,
      "epoch": 0.9738717339667459,
      "step": 4100
    },
    {
      "loss": 0.2439,
      "grad_norm": 2.02590274810791,
      "learning_rate": 5.3967652261814506e-05,
      "epoch": 0.9857482185273159,
      "step": 4150
    },
    {
      "loss": 0.2595,
      "grad_norm": 1.8265208005905151,
      "learning_rate": 5.333586050037908e-05,
      "epoch": 0.997624703087886,
      "step": 4200
    },
    {
      "eval_loss": 0.2375202476978302,
      "eval_accuracy": 0.9128440366972477,
      "eval_runtime": 1.4015,
      "eval_samples_per_second": 622.18,
      "eval_steps_per_second": 9.989,
      "epoch": 1.0,
      "step": 4210
    },
    {
      "loss": 0.2621,
      "grad_norm": 1.6244534254074097,
      "learning_rate": 5.2704068738943644e-05,
      "epoch": 1.009501187648456,
      "step": 4250
    },
    {
      "loss": 0.2376,
      "grad_norm": 3.1392147541046143,
      "learning_rate": 5.2072276977508216e-05,
      "epoch": 1.0213776722090262,
      "step": 4300
    },
    {
      "loss": 0.2355,
      "grad_norm": 2.763162612915039,
      "learning_rate": 5.144048521607279e-05,
      "epoch": 1.0332541567695963,
      "step": 4350
    },
    {
      "loss": 0.2675,
      "grad_norm": 2.9985527992248535,
      "learning_rate": 5.080869345463736e-05,
      "epoch": 1.0451306413301662,
      "step": 4400
    },
    {
      "loss": 0.225,
      "grad_norm": 4.455100059509277,
      "learning_rate": 5.0176901693201925e-05,
      "epoch": 1.0570071258907363,
      "step": 4450
    },
    {
      "loss": 0.2186,
      "grad_norm": 2.1119773387908936,
      "learning_rate": 4.954510993176649e-05,
      "epoch": 1.0688836104513064,
      "step": 4500
    },
    {
      "loss": 0.2379,
      "grad_norm": 2.718451976776123,
      "learning_rate": 4.891331817033106e-05,
      "epoch": 1.0807600950118765,
      "step": 4550
    },
    {
      "loss": 0.2428,
      "grad_norm": 2.956195592880249,
      "learning_rate": 4.828152640889563e-05,
      "epoch": 1.0926365795724466,
      "step": 4600
    },
    {
      "loss": 0.2306,
      "grad_norm": 2.859586477279663,
      "learning_rate": 4.76497346474602e-05,
      "epoch": 1.1045130641330165,
      "step": 4650
    },
    {
      "loss": 0.2055,
      "grad_norm": 2.8577802181243896,
      "learning_rate": 4.701794288602477e-05,
      "epoch": 1.1163895486935866,
      "step": 4700
    },
    {
      "loss": 0.2456,
      "grad_norm": 2.9942493438720703,
      "learning_rate": 4.638615112458934e-05,
      "epoch": 1.1282660332541568,
      "step": 4750
    },
    {
      "loss": 0.2141,
      "grad_norm": 2.3612494468688965,
      "learning_rate": 4.575435936315391e-05,
      "epoch": 1.1401425178147269,
      "step": 4800
    },
    {
      "loss": 0.2533,
      "grad_norm": 2.5780751705169678,
      "learning_rate": 4.5122567601718474e-05,
      "epoch": 1.152019002375297,
      "step": 4850
    },
    {
      "loss": 0.2518,
      "grad_norm": 2.6305735111236572,
      "learning_rate": 4.4490775840283046e-05,
      "epoch": 1.1638954869358669,
      "step": 4900
    },
    {
      "loss": 0.2426,
      "grad_norm": 1.0084294080734253,
      "learning_rate": 4.385898407884762e-05,
      "epoch": 1.175771971496437,
      "step": 4950
    },
    {
      "loss": 0.2345,
      "grad_norm": 1.4040495157241821,
      "learning_rate": 4.322719231741218e-05,
      "epoch": 1.187648456057007,
      "step": 5000
    },
    {
      "loss": 0.2476,
      "grad_norm": 2.9656174182891846,
      "learning_rate": 4.259540055597675e-05,
      "epoch": 1.1995249406175772,
      "step": 5050
    },
    {
      "loss": 0.2491,
      "grad_norm": 2.1830086708068848,
      "learning_rate": 4.196360879454132e-05,
      "epoch": 1.2114014251781473,
      "step": 5100
    },
    {
      "loss": 0.2108,
      "grad_norm": 2.1803934574127197,
      "learning_rate": 4.133181703310589e-05,
      "epoch": 1.2232779097387174,
      "step": 5150
    },
    {
      "loss": 0.2517,
      "grad_norm": 1.8496261835098267,
      "learning_rate": 4.070002527167046e-05,
      "epoch": 1.2351543942992875,
      "step": 5200
    },
    {
      "loss": 0.2434,
      "grad_norm": 4.004733562469482,
      "learning_rate": 4.006823351023502e-05,
      "epoch": 1.2470308788598574,
      "step": 5250
    },
    {
      "loss": 0.2438,
      "grad_norm": 3.747288942337036,
      "learning_rate": 3.9436441748799595e-05,
      "epoch": 1.2589073634204275,
      "step": 5300
    },
    {
      "loss": 0.2237,
      "grad_norm": 2.4294934272766113,
      "learning_rate": 3.880464998736417e-05,
      "epoch": 1.2707838479809976,
      "step": 5350
    },
    {
      "loss": 0.2515,
      "grad_norm": 2.6833512783050537,
      "learning_rate": 3.817285822592874e-05,
      "epoch": 1.2826603325415677,
      "step": 5400
    },
    {
      "loss": 0.2182,
      "grad_norm": 2.430415391921997,
      "learning_rate": 3.7541066464493304e-05,
      "epoch": 1.2945368171021379,
      "step": 5450
    },
    {
      "loss": 0.2542,
      "grad_norm": 2.9502336978912354,
      "learning_rate": 3.690927470305787e-05,
      "epoch": 1.3064133016627077,
      "step": 5500
    },
    {
      "loss": 0.2512,
      "grad_norm": 1.504012942314148,
      "learning_rate": 3.627748294162244e-05,
      "epoch": 1.3182897862232779,
      "step": 5550
    },
    {
      "loss": 0.2246,
      "grad_norm": 3.226247787475586,
      "learning_rate": 3.5645691180187014e-05,
      "epoch": 1.330166270783848,
      "step": 5600
    },
    {
      "loss": 0.2217,
      "grad_norm": 2.5615310668945312,
      "learning_rate": 3.5013899418751586e-05,
      "epoch": 1.342042755344418,
      "step": 5650
    },
    {
      "loss": 0.2033,
      "grad_norm": 1.6753661632537842,
      "learning_rate": 3.438210765731615e-05,
      "epoch": 1.3539192399049882,
      "step": 5700
    },
    {
      "loss": 0.2154,
      "grad_norm": 2.1501379013061523,
      "learning_rate": 3.3750315895880716e-05,
      "epoch": 1.365795724465558,
      "step": 5750
    },
    {
      "loss": 0.1797,
      "grad_norm": 3.0520057678222656,
      "learning_rate": 3.311852413444529e-05,
      "epoch": 1.3776722090261282,
      "step": 5800
    },
    {
      "loss": 0.2405,
      "grad_norm": 2.021944999694824,
      "learning_rate": 3.248673237300986e-05,
      "epoch": 1.3895486935866983,
      "step": 5850
    },
    {
      "loss": 0.2422,
      "grad_norm": 2.055760622024536,
      "learning_rate": 3.1854940611574425e-05,
      "epoch": 1.4014251781472684,
      "step": 5900
    },
    {
      "loss": 0.2345,
      "grad_norm": 2.478822708129883,
      "learning_rate": 3.1223148850139e-05,
      "epoch": 1.4133016627078385,
      "step": 5950
    },
    {
      "loss": 0.2049,
      "grad_norm": 2.143181800842285,
      "learning_rate": 3.059135708870356e-05,
      "epoch": 1.4251781472684084,
      "step": 6000
    },
    {
      "loss": 0.2237,
      "grad_norm": 2.009521722793579,
      "learning_rate": 2.9959565327268135e-05,
      "epoch": 1.4370546318289787,
      "step": 6050
    },
    {
      "loss": 0.2321,
      "grad_norm": 2.907785415649414,
      "learning_rate": 2.93277735658327e-05,
      "epoch": 1.4489311163895486,
      "step": 6100
    },
    {
      "loss": 0.2236,
      "grad_norm": 0.6880680322647095,
      "learning_rate": 2.8695981804397272e-05,
      "epoch": 1.4608076009501187,
      "step": 6150
    },
    {
      "loss": 0.1845,
      "grad_norm": 3.0946617126464844,
      "learning_rate": 2.806419004296184e-05,
      "epoch": 1.4726840855106889,
      "step": 6200
    },
    {
      "loss": 0.2618,
      "grad_norm": 4.067305564880371,
      "learning_rate": 2.7432398281526412e-05,
      "epoch": 1.484560570071259,
      "step": 6250
    },
    {
      "loss": 0.2026,
      "grad_norm": 3.230731248855591,
      "learning_rate": 2.680060652009098e-05,
      "epoch": 1.496437054631829,
      "step": 6300
    },
    {
      "loss": 0.2093,
      "grad_norm": 1.3271459341049194,
      "learning_rate": 2.6168814758655546e-05,
      "epoch": 1.508313539192399,
      "step": 6350
    },
    {
      "loss": 0.2267,
      "grad_norm": 5.763126850128174,
      "learning_rate": 2.553702299722012e-05,
      "epoch": 1.520190023752969,
      "step": 6400
    },
    {
      "loss": 0.2167,
      "grad_norm": 2.8380048274993896,
      "learning_rate": 2.4905231235784687e-05,
      "epoch": 1.5320665083135392,
      "step": 6450
    },
    {
      "loss": 0.2788,
      "grad_norm": 1.7981882095336914,
      "learning_rate": 2.4273439474349256e-05,
      "epoch": 1.5439429928741093,
      "step": 6500
    },
    {
      "loss": 0.2105,
      "grad_norm": 2.8142786026000977,
      "learning_rate": 2.3641647712913824e-05,
      "epoch": 1.5558194774346794,
      "step": 6550
    },
    {
      "loss": 0.2028,
      "grad_norm": 2.9409008026123047,
      "learning_rate": 2.3009855951478393e-05,
      "epoch": 1.5676959619952493,
      "step": 6600
    },
    {
      "loss": 0.211,
      "grad_norm": 1.2875834703445435,
      "learning_rate": 2.2378064190042965e-05,
      "epoch": 1.5795724465558196,
      "step": 6650
    },
    {
      "loss": 0.2205,
      "grad_norm": 0.7648037672042847,
      "learning_rate": 2.174627242860753e-05,
      "epoch": 1.5914489311163895,
      "step": 6700
    },
    {
      "loss": 0.1976,
      "grad_norm": 2.5246264934539795,
      "learning_rate": 2.1114480667172102e-05,
      "epoch": 1.6033254156769596,
      "step": 6750
    },
    {
      "loss": 0.2446,
      "grad_norm": 5.888637542724609,
      "learning_rate": 2.0482688905736667e-05,
      "epoch": 1.6152019002375297,
      "step": 6800
    },
    {
      "loss": 0.2252,
      "grad_norm": 2.6938722133636475,
      "learning_rate": 1.985089714430124e-05,
      "epoch": 1.6270783847980996,
      "step": 6850
    },
    {
      "loss": 0.2784,
      "grad_norm": 2.532315492630005,
      "learning_rate": 1.9219105382865808e-05,
      "epoch": 1.63895486935867,
      "step": 6900
    },
    {
      "loss": 0.1985,
      "grad_norm": 1.7890970706939697,
      "learning_rate": 1.8587313621430377e-05,
      "epoch": 1.6508313539192399,
      "step": 6950
    },
    {
      "loss": 0.2413,
      "grad_norm": 1.4564425945281982,
      "learning_rate": 1.795552185999495e-05,
      "epoch": 1.66270783847981,
      "step": 7000
    },
    {
      "loss": 0.1761,
      "grad_norm": 1.236835241317749,
      "learning_rate": 1.7323730098559514e-05,
      "epoch": 1.67458432304038,
      "step": 7050
    },
    {
      "loss": 0.1872,
      "grad_norm": 1.4580155611038208,
      "learning_rate": 1.6691938337124086e-05,
      "epoch": 1.68646080760095,
      "step": 7100
    },
    {
      "loss": 0.2347,
      "grad_norm": 0.9040394425392151,
      "learning_rate": 1.6060146575688655e-05,
      "epoch": 1.6983372921615203,
      "step": 7150
    },
    {
      "loss": 0.2294,
      "grad_norm": 1.9492896795272827,
      "learning_rate": 1.5428354814253223e-05,
      "epoch": 1.7102137767220902,
      "step": 7200
    },
    {
      "loss": 0.2577,
      "grad_norm": 0.5641096234321594,
      "learning_rate": 1.4796563052817792e-05,
      "epoch": 1.7220902612826603,
      "step": 7250
    },
    {
      "loss": 0.2272,
      "grad_norm": 1.744774580001831,
      "learning_rate": 1.4164771291382362e-05,
      "epoch": 1.7339667458432304,
      "step": 7300
    },
    {
      "loss": 0.2174,
      "grad_norm": 0.8004424571990967,
      "learning_rate": 1.3532979529946929e-05,
      "epoch": 1.7458432304038005,
      "step": 7350
    },
    {
      "loss": 0.2173,
      "grad_norm": 1.1339695453643799,
      "learning_rate": 1.29011877685115e-05,
      "epoch": 1.7577197149643706,
      "step": 7400
    },
    {
      "loss": 0.2207,
      "grad_norm": 2.4462687969207764,
      "learning_rate": 1.2269396007076068e-05,
      "epoch": 1.7695961995249405,
      "step": 7450
    },
    {
      "loss": 0.2303,
      "grad_norm": 2.1693015098571777,
      "learning_rate": 1.1637604245640638e-05,
      "epoch": 1.7814726840855108,
      "step": 7500
    },
    {
      "loss": 0.2485,
      "grad_norm": 3.476472854614258,
      "learning_rate": 1.1005812484205207e-05,
      "epoch": 1.7933491686460807,
      "step": 7550
    },
    {
      "loss": 0.2042,
      "grad_norm": 1.7744616270065308,
      "learning_rate": 1.0374020722769776e-05,
      "epoch": 1.8052256532066508,
      "step": 7600
    },
    {
      "loss": 0.2292,
      "grad_norm": 2.7680675983428955,
      "learning_rate": 9.742228961334344e-06,
      "epoch": 1.817102137767221,
      "step": 7650
    },
    {
      "loss": 0.2407,
      "grad_norm": 0.963364839553833,
      "learning_rate": 9.110437199898913e-06,
      "epoch": 1.8289786223277908,
      "step": 7700
    },
    {
      "loss": 0.2162,
      "grad_norm": 0.8501291275024414,
      "learning_rate": 8.478645438463483e-06,
      "epoch": 1.8408551068883612,
      "step": 7750
    },
    {
      "loss": 0.1868,
      "grad_norm": 0.872247040271759,
      "learning_rate": 7.846853677028052e-06,
      "epoch": 1.852731591448931,
      "step": 7800
    },
    {
      "loss": 0.2105,
      "grad_norm": 2.468102216720581,
      "learning_rate": 7.2150619155926204e-06,
      "epoch": 1.8646080760095012,
      "step": 7850
    },
    {
      "loss": 0.2236,
      "grad_norm": 1.397261619567871,
      "learning_rate": 6.58327015415719e-06,
      "epoch": 1.8764845605700713,
      "step": 7900
    },
    {
      "loss": 0.2446,
      "grad_norm": 2.448396921157837,
      "learning_rate": 5.951478392721759e-06,
      "epoch": 1.8883610451306412,
      "step": 7950
    },
    {
      "loss": 0.2089,
      "grad_norm": 3.0933282375335693,
      "learning_rate": 5.319686631286328e-06,
      "epoch": 1.9002375296912115,
      "step": 8000
    },
    {
      "loss": 0.2203,
      "grad_norm": 2.063605785369873,
      "learning_rate": 4.6878948698508975e-06,
      "epoch": 1.9121140142517814,
      "step": 8050
    },
    {
      "loss": 0.2364,
      "grad_norm": 1.0039204359054565,
      "learning_rate": 4.056103108415466e-06,
      "epoch": 1.9239904988123515,
      "step": 8100
    },
    {
      "loss": 0.2135,
      "grad_norm": 0.9303463697433472,
      "learning_rate": 3.424311346980036e-06,
      "epoch": 1.9358669833729216,
      "step": 8150
    },
    {
      "loss": 0.2053,
      "grad_norm": 3.7675390243530273,
      "learning_rate": 2.7925195855446046e-06,
      "epoch": 1.9477434679334917,
      "step": 8200
    },
    {
      "loss": 0.2179,
      "grad_norm": 0.9910412430763245,
      "learning_rate": 2.1607278241091737e-06,
      "epoch": 1.9596199524940618,
      "step": 8250
    },
    {
      "loss": 0.2171,
      "grad_norm": 2.3047726154327393,
      "learning_rate": 1.5289360626737428e-06,
      "epoch": 1.9714964370546317,
      "step": 8300
    },
    {
      "loss": 0.2432,
      "grad_norm": 3.8978707790374756,
      "learning_rate": 8.971443012383118e-07,
      "epoch": 1.9833729216152018,
      "step": 8350
    },
    {
      "loss": 0.1851,
      "grad_norm": 1.932503581047058,
      "learning_rate": 2.65352539802881e-07,
      "epoch": 1.995249406175772,
      "step": 8400
    },
    {
      "eval_loss": 0.2464117407798767,
      "eval_accuracy": 0.9071100917431193,
      "eval_runtime": 1.3972,
      "eval_samples_per_second": 624.092,
      "eval_steps_per_second": 10.02,
      "epoch": 2.0,
      "step": 8420
    },
    {
      "train_runtime": 517.489,
      "train_samples_per_second": 260.291,
      "train_steps_per_second": 16.271,
      "total_flos": 8921149384621056.0,
      "train_loss": 0.2659071228566476,
      "epoch": 2.0,
      "step": 8420
    },
    {
      "eval_loss": 0.2464117407798767,
      "eval_accuracy": 0.9071100917431193,
      "eval_runtime": 1.3967,
      "eval_samples_per_second": 624.31,
      "eval_steps_per_second": 10.023,
      "epoch": 2.0,
      "step": 8420
    }
  ]
}