{
  "mode": "lora",
  "model": "bert-base-uncased",
  "metrics": {
    "eval_loss": 0.25861912965774536,
    "eval_accuracy": 0.9059633027522935,
    "eval_runtime": 1.3927,
    "eval_samples_per_second": 626.136,
    "eval_steps_per_second": 10.053,
    "epoch": 2.0
  },
  "params": {
    "total_parameters": 109778690,
    "trainable_parameters": 296450,
    "trainable_percentage": 0.27004330257539055
  },
  "elapsed_sec": 514.5472369194031,
  "config": {
    "mode": "lora",
    "model_name": "bert-base-uncased",
    "max_length": 128,
    "epochs": 2,
    "lr": 0.0001,
    "train_batch_size": 16,
    "eval_batch_size": 64,
    "warmup_ratio": 0.06,
    "r": 8,
    "alpha": 16.0,
    "lora_dropout": 0.0,
    "output_dir": "outputs/runs",
    "results_path": "/content/drive/MyDrive/lora-tuning/results/lora_r_8.json"
  },
  "log_history": [
    {
      "loss": 0.6885,
      "grad_norm": 1.860275149345398,
      "learning_rate": 9.683794466403162e-06,
      "epoch": 0.011876484560570071,
      "step": 50
    },
    {
      "loss": 0.6935,
      "grad_norm": 3.2744908332824707,
      "learning_rate": 1.956521739130435e-05,
      "epoch": 0.023752969121140142,
      "step": 100
    },
    {
      "loss": 0.6832,
      "grad_norm": 1.1910113096237183,
      "learning_rate": 2.9446640316205537e-05,
      "epoch": 0.035629453681710214,
      "step": 150
    },
    {
      "loss": 0.6798,
      "grad_norm": 2.513166904449463,
      "learning_rate": 3.932806324110672e-05,
      "epoch": 0.047505938242280284,
      "step": 200
    },
    {
      "loss": 0.673,
      "grad_norm": 2.150963544845581,
      "learning_rate": 4.9209486166007906e-05,
      "epoch": 0.05938242280285035,
      "step": 250
    },
    {
      "loss": 0.6344,
      "grad_norm": 1.7881964445114136,
      "learning_rate": 5.90909090909091e-05,
      "epoch": 0.07125890736342043,
      "step": 300
    },
    {
      "loss": 0.5001,
      "grad_norm": 2.680629253387451,
      "learning_rate": 6.897233201581029e-05,
      "epoch": 0.0831353919239905,
      "step": 350
    },
    {
      "loss": 0.3641,
      "grad_norm": 1.840009331703186,
      "learning_rate": 7.885375494071147e-05,
      "epoch": 0.09501187648456057,
      "step": 400
    },
    {
      "loss": 0.3541,
      "grad_norm": 4.271941184997559,
      "learning_rate": 8.873517786561266e-05,
      "epoch": 0.10688836104513064,
      "step": 450
    },
    {
      "loss": 0.3468,
      "grad_norm": 5.279821395874023,
      "learning_rate": 9.861660079051383e-05,
      "epoch": 0.1187648456057007,
      "step": 500
    },
    {
      "loss": 0.3397,
      "grad_norm": 1.6729127168655396,
      "learning_rate": 9.945665908516553e-05,
      "epoch": 0.13064133016627077,
      "step": 550
    },
    {
      "loss": 0.3773,
      "grad_norm": 2.1982533931732178,
      "learning_rate": 9.88248673237301e-05,
      "epoch": 0.14251781472684086,
      "step": 600
    },
    {
      "loss": 0.3204,
      "grad_norm": 2.177456855773926,
      "learning_rate": 9.819307556229466e-05,
      "epoch": 0.1543942992874109,
      "step": 650
    },
    {
      "loss": 0.2957,
      "grad_norm": 4.511367321014404,
      "learning_rate": 9.756128380085923e-05,
      "epoch": 0.166270783847981,
      "step": 700
    },
    {
      "loss": 0.3243,
      "grad_norm": 3.697742223739624,
      "learning_rate": 9.69294920394238e-05,
      "epoch": 0.17814726840855108,
      "step": 750
    },
    {
      "loss": 0.3226,
      "grad_norm": 3.2245097160339355,
      "learning_rate": 9.629770027798838e-05,
      "epoch": 0.19002375296912113,
      "step": 800
    },
    {
      "loss": 0.3332,
      "grad_norm": 3.0435664653778076,
      "learning_rate": 9.566590851655295e-05,
      "epoch": 0.20190023752969122,
      "step": 850
    },
    {
      "loss": 0.3179,
      "grad_norm": 4.317493438720703,
      "learning_rate": 9.503411675511752e-05,
      "epoch": 0.21377672209026127,
      "step": 900
    },
    {
      "loss": 0.2959,
      "grad_norm": 6.607493877410889,
      "learning_rate": 9.44023249936821e-05,
      "epoch": 0.22565320665083136,
      "step": 950
    },
    {
      "loss": 0.2959,
      "grad_norm": 2.0061686038970947,
      "learning_rate": 9.377053323224667e-05,
      "epoch": 0.2375296912114014,
      "step": 1000
    },
    {
      "loss": 0.2801,
      "grad_norm": 4.587066650390625,
      "learning_rate": 9.313874147081122e-05,
      "epoch": 0.2494061757719715,
      "step": 1050
    },
    {
      "loss": 0.289,
      "grad_norm": 3.5865869522094727,
      "learning_rate": 9.25069497093758e-05,
      "epoch": 0.26128266033254155,
      "step": 1100
    },
    {
      "loss": 0.2734,
      "grad_norm": 5.357723712921143,
      "learning_rate": 9.187515794794035e-05,
      "epoch": 0.27315914489311166,
      "step": 1150
    },
    {
      "loss": 0.2613,
      "grad_norm": 3.011899709701538,
      "learning_rate": 9.124336618650493e-05,
      "epoch": 0.2850356294536817,
      "step": 1200
    },
    {
      "loss": 0.3017,
      "grad_norm": 2.0737357139587402,
      "learning_rate": 9.06115744250695e-05,
      "epoch": 0.29691211401425177,
      "step": 1250
    },
    {
      "loss": 0.2959,
      "grad_norm": 2.3339357376098633,
      "learning_rate": 8.997978266363407e-05,
      "epoch": 0.3087885985748218,
      "step": 1300
    },
    {
      "loss": 0.2792,
      "grad_norm": 1.5445228815078735,
      "learning_rate": 8.934799090219864e-05,
      "epoch": 0.32066508313539194,
      "step": 1350
    },
    {
      "loss": 0.2734,
      "grad_norm": 2.6939475536346436,
      "learning_rate": 8.871619914076321e-05,
      "epoch": 0.332541567695962,
      "step": 1400
    },
    {
      "loss": 0.262,
      "grad_norm": 4.9301629066467285,
      "learning_rate": 8.808440737932779e-05,
      "epoch": 0.34441805225653205,
      "step": 1450
    },
    {
      "loss": 0.2902,
      "grad_norm": 4.143551826477051,
      "learning_rate": 8.745261561789235e-05,
      "epoch": 0.35629453681710216,
      "step": 1500
    },
    {
      "loss": 0.3032,
      "grad_norm": 2.4666993618011475,
      "learning_rate": 8.682082385645692e-05,
      "epoch": 0.3681710213776722,
      "step": 1550
    },
    {
      "loss": 0.2404,
      "grad_norm": 1.2829530239105225,
      "learning_rate": 8.618903209502148e-05,
      "epoch": 0.38004750593824227,
      "step": 1600
    },
    {
      "loss": 0.3019,
      "grad_norm": 2.5290629863739014,
      "learning_rate": 8.555724033358605e-05,
      "epoch": 0.3919239904988123,
      "step": 1650
    },
    {
      "loss": 0.2708,
      "grad_norm": 4.062686443328857,
      "learning_rate": 8.492544857215062e-05,
      "epoch": 0.40380047505938244,
      "step": 1700
    },
    {
      "loss": 0.2687,
      "grad_norm": 7.42488956451416,
      "learning_rate": 8.429365681071519e-05,
      "epoch": 0.4156769596199525,
      "step": 1750
    },
    {
      "loss": 0.2836,
      "grad_norm": 3.0240540504455566,
      "learning_rate": 8.366186504927976e-05,
      "epoch": 0.42755344418052255,
      "step": 1800
    },
    {
      "loss": 0.2853,
      "grad_norm": 4.618505001068115,
      "learning_rate": 8.303007328784434e-05,
      "epoch": 0.43942992874109266,
      "step": 1850
    },
    {
      "loss": 0.2729,
      "grad_norm": 1.430936574935913,
      "learning_rate": 8.239828152640891e-05,
      "epoch": 0.4513064133016627,
      "step": 1900
    },
    {
      "loss": 0.2917,
      "grad_norm": 5.135326862335205,
      "learning_rate": 8.176648976497347e-05,
      "epoch": 0.46318289786223277,
      "step": 1950
    },
    {
      "loss": 0.264,
      "grad_norm": 4.5126729011535645,
      "learning_rate": 8.113469800353804e-05,
      "epoch": 0.4750593824228028,
      "step": 2000
    },
    {
      "loss": 0.3278,
      "grad_norm": 1.7002480030059814,
      "learning_rate": 8.050290624210261e-05,
      "epoch": 0.48693586698337293,
      "step": 2050
    },
    {
      "loss": 0.2477,
      "grad_norm": 3.1547670364379883,
      "learning_rate": 7.987111448066717e-05,
      "epoch": 0.498812351543943,
      "step": 2100
    },
    {
      "loss": 0.2557,
      "grad_norm": 1.5772912502288818,
      "learning_rate": 7.923932271923174e-05,
      "epoch": 0.5106888361045131,
      "step": 2150
    },
    {
      "loss": 0.2698,
      "grad_norm": 1.562321424484253,
      "learning_rate": 7.860753095779631e-05,
      "epoch": 0.5225653206650831,
      "step": 2200
    },
    {
      "loss": 0.2449,
      "grad_norm": 4.050527572631836,
      "learning_rate": 7.797573919636088e-05,
      "epoch": 0.5344418052256532,
      "step": 2250
    },
    {
      "loss": 0.2525,
      "grad_norm": 1.7043168544769287,
      "learning_rate": 7.734394743492546e-05,
      "epoch": 0.5463182897862233,
      "step": 2300
    },
    {
      "loss": 0.2532,
      "grad_norm": 2.8915531635284424,
      "learning_rate": 7.671215567349002e-05,
      "epoch": 0.5581947743467933,
      "step": 2350
    },
    {
      "loss": 0.2356,
      "grad_norm": 3.5977108478546143,
      "learning_rate": 7.608036391205459e-05,
      "epoch": 0.5700712589073634,
      "step": 2400
    },
    {
      "loss": 0.2839,
      "grad_norm": 1.5414901971817017,
      "learning_rate": 7.544857215061916e-05,
      "epoch": 0.5819477434679335,
      "step": 2450
    },
    {
      "loss": 0.2406,
      "grad_norm": 2.6888444423675537,
      "learning_rate": 7.481678038918373e-05,
      "epoch": 0.5938242280285035,
      "step": 2500
    },
    {
      "loss": 0.2702,
      "grad_norm": 3.0893797874450684,
      "learning_rate": 7.41849886277483e-05,
      "epoch": 0.6057007125890737,
      "step": 2550
    },
    {
      "loss": 0.2669,
      "grad_norm": 4.170047760009766,
      "learning_rate": 7.355319686631286e-05,
      "epoch": 0.6175771971496437,
      "step": 2600
    },
    {
      "loss": 0.2964,
      "grad_norm": 1.2954624891281128,
      "learning_rate": 7.292140510487743e-05,
      "epoch": 0.6294536817102138,
      "step": 2650
    },
    {
      "loss": 0.2356,
      "grad_norm": 0.9274739623069763,
      "learning_rate": 7.2289613343442e-05,
      "epoch": 0.6413301662707839,
      "step": 2700
    },
    {
      "loss": 0.302,
      "grad_norm": 4.432612419128418,
      "learning_rate": 7.165782158200658e-05,
      "epoch": 0.6532066508313539,
      "step": 2750
    },
    {
      "loss": 0.2615,
      "grad_norm": 3.378126382827759,
      "learning_rate": 7.102602982057114e-05,
      "epoch": 0.665083135391924,
      "step": 2800
    },
    {
      "loss": 0.2627,
      "grad_norm": 2.605076313018799,
      "learning_rate": 7.039423805913571e-05,
      "epoch": 0.6769596199524941,
      "step": 2850
    },
    {
      "loss": 0.2412,
      "grad_norm": 2.5665128231048584,
      "learning_rate": 6.976244629770028e-05,
      "epoch": 0.6888361045130641,
      "step": 2900
    },
    {
      "loss": 0.3007,
      "grad_norm": 4.671572685241699,
      "learning_rate": 6.913065453626485e-05,
      "epoch": 0.7007125890736342,
      "step": 2950
    },
    {
      "loss": 0.2545,
      "grad_norm": 1.6119304895401,
      "learning_rate": 6.849886277482942e-05,
      "epoch": 0.7125890736342043,
      "step": 3000
    },
    {
      "loss": 0.2553,
      "grad_norm": 1.547829031944275,
      "learning_rate": 6.7867071013394e-05,
      "epoch": 0.7244655581947743,
      "step": 3050
    },
    {
      "loss": 0.2488,
      "grad_norm": 5.070233345031738,
      "learning_rate": 6.723527925195856e-05,
      "epoch": 0.7363420427553444,
      "step": 3100
    },
    {
      "loss": 0.285,
      "grad_norm": 2.17900013923645,
      "learning_rate": 6.660348749052313e-05,
      "epoch": 0.7482185273159145,
      "step": 3150
    },
    {
      "loss": 0.2772,
      "grad_norm": 1.588167667388916,
      "learning_rate": 6.59716957290877e-05,
      "epoch": 0.7600950118764845,
      "step": 3200
    },
    {
      "loss": 0.2294,
      "grad_norm": 3.8762738704681396,
      "learning_rate": 6.533990396765226e-05,
      "epoch": 0.7719714964370546,
      "step": 3250
    },
    {
      "loss": 0.2395,
      "grad_norm": 4.775186538696289,
      "learning_rate": 6.470811220621683e-05,
      "epoch": 0.7838479809976246,
      "step": 3300
    },
    {
      "loss": 0.2504,
      "grad_norm": 6.399891376495361,
      "learning_rate": 6.40763204447814e-05,
      "epoch": 0.7957244655581948,
      "step": 3350
    },
    {
      "loss": 0.2757,
      "grad_norm": 3.764227867126465,
      "learning_rate": 6.344452868334597e-05,
      "epoch": 0.8076009501187649,
      "step": 3400
    },
    {
      "loss": 0.2877,
      "grad_norm": 2.484851837158203,
      "learning_rate": 6.281273692191055e-05,
      "epoch": 0.8194774346793349,
      "step": 3450
    },
    {
      "loss": 0.2406,
      "grad_norm": 4.234954833984375,
      "learning_rate": 6.218094516047512e-05,
      "epoch": 0.831353919239905,
      "step": 3500
    },
    {
      "loss": 0.2512,
      "grad_norm": 3.213008403778076,
      "learning_rate": 6.154915339903969e-05,
      "epoch": 0.8432304038004751,
      "step": 3550
    },
    {
      "loss": 0.2278,
      "grad_norm": 3.9998528957366943,
      "learning_rate": 6.0917361637604255e-05,
      "epoch": 0.8551068883610451,
      "step": 3600
    },
    {
      "loss": 0.2485,
      "grad_norm": 1.0263426303863525,
      "learning_rate": 6.028556987616881e-05,
      "epoch": 0.8669833729216152,
      "step": 3650
    },
    {
      "loss": 0.2505,
      "grad_norm": 1.3880823850631714,
      "learning_rate": 5.9653778114733385e-05,
      "epoch": 0.8788598574821853,
      "step": 3700
    },
    {
      "loss": 0.2591,
      "grad_norm": 3.5777409076690674,
      "learning_rate": 5.902198635329795e-05,
      "epoch": 0.8907363420427553,
      "step": 3750
    },
    {
      "loss": 0.2594,
      "grad_norm": 3.105102777481079,
      "learning_rate": 5.839019459186252e-05,
      "epoch": 0.9026128266033254,
      "step": 3800
    },
    {
      "loss": 0.2392,
      "grad_norm": 3.53513765335083,
      "learning_rate": 5.7758402830427095e-05,
      "epoch": 0.9144893111638955,
      "step": 3850
    },
    {
      "loss": 0.1978,
      "grad_norm": 1.0509830713272095,
      "learning_rate": 5.712661106899167e-05,
      "epoch": 0.9263657957244655,
      "step": 3900
    },
    {
      "loss": 0.2585,
      "grad_norm": 2.260744571685791,
      "learning_rate": 5.649481930755623e-05,
      "epoch": 0.9382422802850356,
      "step": 3950
    },
    {
      "loss": 0.2422,
      "grad_norm": 2.329374313354492,
      "learning_rate": 5.5863027546120804e-05,
      "epoch": 0.9501187648456056,
      "step": 4000
    },
    {
      "loss": 0.2268,
      "grad_norm": 0.9866108298301697,
      "learning_rate": 5.5231235784685376e-05,
      "epoch": 0.9619952494061758,
      "step": 4050
    },
    {
      "loss": 0.2229,
      "grad_norm": 2.8818740844726562,
      "learning_rate": 5.4599444023249934e-05,
      "epoch": 0.9738717339667459,
      "step": 4100
    },
    {
      "loss": 0.2453,
      "grad_norm": 3.4327216148376465,
      "learning_rate": 5.3967652261814506e-05,
      "epoch": 0.9857482185273159,
      "step": 4150
    },
    {
      "loss": 0.2731,
      "grad_norm": 2.83534574508667,
      "learning_rate": 5.333586050037908e-05,
      "epoch": 0.997624703087886,
      "step": 4200
    },
    {
      "eval_loss": 0.24690477550029755,
      "eval_accuracy": 0.9094036697247706,
      "eval_runtime": 1.3868,
      "eval_samples_per_second": 628.78,
      "eval_steps_per_second": 10.095,
      "epoch": 1.0,
      "step": 4210
    },
    {
      "loss": 0.2666,
      "grad_norm": 1.7240121364593506,
      "learning_rate": 5.2704068738943644e-05,
      "epoch": 1.009501187648456,
      "step": 4250
    },
    {
      "loss": 0.2417,
      "grad_norm": 4.419806480407715,
      "learning_rate": 5.2072276977508216e-05,
      "epoch": 1.0213776722090262,
      "step": 4300
    },
    {
      "loss": 0.2372,
      "grad_norm": 2.9032254219055176,
      "learning_rate": 5.144048521607279e-05,
      "epoch": 1.0332541567695963,
      "step": 4350
    },
    {
      "loss": 0.2748,
      "grad_norm": 3.947787046432495,
      "learning_rate": 5.080869345463736e-05,
      "epoch": 1.0451306413301662,
      "step": 4400
    },
    {
      "loss": 0.2316,
      "grad_norm": 5.460066795349121,
      "learning_rate": 5.0176901693201925e-05,
      "epoch": 1.0570071258907363,
      "step": 4450
    },
    {
      "loss": 0.2245,
      "grad_norm": 2.8437366485595703,
      "learning_rate": 4.954510993176649e-05,
      "epoch": 1.0688836104513064,
      "step": 4500
    },
    {
      "loss": 0.2328,
      "grad_norm": 3.3241794109344482,
      "learning_rate": 4.891331817033106e-05,
      "epoch": 1.0807600950118765,
      "step": 4550
    },
    {
      "loss": 0.2345,
      "grad_norm": 3.4052557945251465,
      "learning_rate": 4.828152640889563e-05,
      "epoch": 1.0926365795724466,
      "step": 4600
    },
    {
      "loss": 0.2385,
      "grad_norm": 2.9514100551605225,
      "learning_rate": 4.76497346474602e-05,
      "epoch": 1.1045130641330165,
      "step": 4650
    },
    {
      "loss": 0.2041,
      "grad_norm": 3.4184980392456055,
      "learning_rate": 4.701794288602477e-05,
      "epoch": 1.1163895486935866,
      "step": 4700
    },
    {
      "loss": 0.2456,
      "grad_norm": 3.5394909381866455,
      "learning_rate": 4.638615112458934e-05,
      "epoch": 1.1282660332541568,
      "step": 4750
    },
    {
      "loss": 0.2151,
      "grad_norm": 2.6095004081726074,
      "learning_rate": 4.575435936315391e-05,
      "epoch": 1.1401425178147269,
      "step": 4800
    },
    {
      "loss": 0.2493,
      "grad_norm": 3.740044116973877,
      "learning_rate": 4.5122567601718474e-05,
      "epoch": 1.152019002375297,
      "step": 4850
    },
    {
      "loss": 0.2508,
      "grad_norm": 3.809720993041992,
      "learning_rate": 4.4490775840283046e-05,
      "epoch": 1.1638954869358669,
      "step": 4900
    },
    {
      "loss": 0.2532,
      "grad_norm": 0.8961341977119446,
      "learning_rate": 4.385898407884762e-05,
      "epoch": 1.175771971496437,
      "step": 4950
    },
    {
      "loss": 0.2282,
      "grad_norm": 1.936872959136963,
      "learning_rate": 4.322719231741218e-05,
      "epoch": 1.187648456057007,
      "step": 5000
    },
    {
      "loss": 0.2508,
      "grad_norm": 4.019416332244873,
      "learning_rate": 4.259540055597675e-05,
      "epoch": 1.1995249406175772,
      "step": 5050
    },
    {
      "loss": 0.2468,
      "grad_norm": 3.3408901691436768,
      "learning_rate": 4.196360879454132e-05,
      "epoch": 1.2114014251781473,
      "step": 5100
    },
    {
      "loss": 0.214,
      "grad_norm": 3.8993101119995117,
      "learning_rate": 4.133181703310589e-05,
      "epoch": 1.2232779097387174,
      "step": 5150
    },
    {
      "loss": 0.2489,
      "grad_norm": 1.7682888507843018,
      "learning_rate": 4.070002527167046e-05,
      "epoch": 1.2351543942992875,
      "step": 5200
    },
    {
      "loss": 0.251,
      "grad_norm": 5.326185703277588,
      "learning_rate": 4.006823351023502e-05,
      "epoch": 1.2470308788598574,
      "step": 5250
    },
    {
      "loss": 0.2434,
      "grad_norm": 5.440422058105469,
      "learning_rate": 3.9436441748799595e-05,
      "epoch": 1.2589073634204275,
      "step": 5300
    },
    {
      "loss": 0.2351,
      "grad_norm": 2.8321685791015625,
      "learning_rate": 3.880464998736417e-05,
      "epoch": 1.2707838479809976,
      "step": 5350
    },
    {
      "loss": 0.2531,
      "grad_norm": 3.116140127182007,
      "learning_rate": 3.817285822592874e-05,
      "epoch": 1.2826603325415677,
      "step": 5400
    },
    {
      "loss": 0.215,
      "grad_norm": 3.9242143630981445,
      "learning_rate": 3.7541066464493304e-05,
      "epoch": 1.2945368171021379,
      "step": 5450
    },
    {
      "loss": 0.2584,
      "grad_norm": 3.5070548057556152,
      "learning_rate": 3.690927470305787e-05,
      "epoch": 1.3064133016627077,
      "step": 5500
    },
    {
      "loss": 0.2481,
      "grad_norm": 2.103259563446045,
      "learning_rate": 3.627748294162244e-05,
      "epoch": 1.3182897862232779,
      "step": 5550
    },
    {
      "loss": 0.2329,
      "grad_norm": 3.9358859062194824,
      "learning_rate": 3.5645691180187014e-05,
      "epoch": 1.330166270783848,
      "step": 5600
    },
    {
      "loss": 0.2232,
      "grad_norm": 3.3012959957122803,
      "learning_rate": 3.5013899418751586e-05,
      "epoch": 1.342042755344418,
      "step": 5650
    },
    {
      "loss": 0.2081,
      "grad_norm": 3.2444658279418945,
      "learning_rate": 3.438210765731615e-05,
      "epoch": 1.3539192399049882,
      "step": 5700
    },
    {
      "loss": 0.2206,
      "grad_norm": 3.9240593910217285,
      "learning_rate": 3.3750315895880716e-05,
      "epoch": 1.365795724465558,
      "step": 5750
    },
    {
      "loss": 0.1809,
      "grad_norm": 2.8472650051116943,
      "learning_rate": 3.311852413444529e-05,
      "epoch": 1.3776722090261282,
      "step": 5800
    },
    {
      "loss": 0.2402,
      "grad_norm": 3.196178913116455,
      "learning_rate": 3.248673237300986e-05,
      "epoch": 1.3895486935866983,
      "step": 5850
    },
    {
      "loss": 0.2336,
      "grad_norm": 0.7476234436035156,
      "learning_rate": 3.1854940611574425e-05,
      "epoch": 1.4014251781472684,
      "step": 5900
    },
    {
      "loss": 0.2318,
      "grad_norm": 3.00638484954834,
      "learning_rate": 3.1223148850139e-05,
      "epoch": 1.4133016627078385,
      "step": 5950
    },
    {
      "loss": 0.2009,
      "grad_norm": 2.8924412727355957,
      "learning_rate": 3.059135708870356e-05,
      "epoch": 1.4251781472684084,
      "step": 6000
    },
    {
      "loss": 0.2192,
      "grad_norm": 2.15508770942688,
      "learning_rate": 2.9959565327268135e-05,
      "epoch": 1.4370546318289787,
      "step": 6050
    },
    {
      "loss": 0.2449,
      "grad_norm": 3.8139989376068115,
      "learning_rate": 2.93277735658327e-05,
      "epoch": 1.4489311163895486,
      "step": 6100
    },
    {
      "loss": 0.2261,
      "grad_norm": 1.8233857154846191,
      "learning_rate": 2.8695981804397272e-05,
      "epoch": 1.4608076009501187,
      "step": 6150
    },
    {
      "loss": 0.187,
      "grad_norm": 3.3205394744873047,
      "learning_rate": 2.806419004296184e-05,
      "epoch": 1.4726840855106889,
      "step": 6200
    },
    {
      "loss": 0.2504,
      "grad_norm": 4.9174346923828125,
      "learning_rate": 2.7432398281526412e-05,
      "epoch": 1.484560570071259,
      "step": 6250
    },
    {
      "loss": 0.2135,
      "grad_norm": 5.5376973152160645,
      "learning_rate": 2.680060652009098e-05,
      "epoch": 1.496437054631829,
      "step": 6300
    },
    {
      "loss": 0.2112,
      "grad_norm": 1.667665719985962,
      "learning_rate": 2.6168814758655546e-05,
      "epoch": 1.508313539192399,
      "step": 6350
    },
    {
      "loss": 0.2255,
      "grad_norm": 7.34193754196167,
      "learning_rate": 2.553702299722012e-05,
      "epoch": 1.520190023752969,
      "step": 6400
    },
    {
      "loss": 0.2161,
      "grad_norm": 3.0654985904693604,
      "learning_rate": 2.4905231235784687e-05,
      "epoch": 1.5320665083135392,
      "step": 6450
    },
    {
      "loss": 0.2881,
      "grad_norm": 2.4482691287994385,
      "learning_rate": 2.4273439474349256e-05,
      "epoch": 1.5439429928741093,
      "step": 6500
    },
    {
      "loss": 0.2137,
      "grad_norm": 3.9154446125030518,
      "learning_rate": 2.3641647712913824e-05,
      "epoch": 1.5558194774346794,
      "step": 6550
    },
    {
      "loss": 0.2068,
      "grad_norm": 3.407777786254883,
      "learning_rate": 2.3009855951478393e-05,
      "epoch": 1.5676959619952493,
      "step": 6600
    },
    {
      "loss": 0.2207,
      "grad_norm": 1.5727486610412598,
      "learning_rate": 2.2378064190042965e-05,
      "epoch": 1.5795724465558196,
      "step": 6650
    },
    {
      "loss": 0.2237,
      "grad_norm": 0.8994205594062805,
      "learning_rate": 2.174627242860753e-05,
      "epoch": 1.5914489311163895,
      "step": 6700
    },
    {
      "loss": 0.2065,
      "grad_norm": 3.313035488128662,
      "learning_rate": 2.1114480667172102e-05,
      "epoch": 1.6033254156769596,
      "step": 6750
    },
    {
      "loss": 0.2443,
      "grad_norm": 8.679614067077637,
      "learning_rate": 2.0482688905736667e-05,
      "epoch": 1.6152019002375297,
      "step": 6800
    },
    {
      "loss": 0.2257,
      "grad_norm": 3.3405253887176514,
      "learning_rate": 1.985089714430124e-05,
      "epoch": 1.6270783847980996,
      "step": 6850
    },
    {
      "loss": 0.2768,
      "grad_norm": 2.6189091205596924,
      "learning_rate": 1.9219105382865808e-05,
      "epoch": 1.63895486935867,
      "step": 6900
    },
    {
      "loss": 0.1971,
      "grad_norm": 1.8605315685272217,
      "learning_rate": 1.8587313621430377e-05,
      "epoch": 1.6508313539192399,
      "step": 6950
    },
    {
      "loss": 0.242,
      "grad_norm": 1.8326106071472168,
      "learning_rate": 1.795552185999495e-05,
      "epoch": 1.66270783847981,
      "step": 7000
    },
    {
      "loss": 0.1816,
      "grad_norm": 1.4058870077133179,
      "learning_rate": 1.7323730098559514e-05,
      "epoch": 1.67458432304038,
      "step": 7050
    },
    {
      "loss": 0.1914,
      "grad_norm": 1.9199916124343872,
      "learning_rate": 1.6691938337124086e-05,
      "epoch": 1.68646080760095,
      "step": 7100
    },
    {
      "loss": 0.2364,
      "grad_norm": 1.1077836751937866,
      "learning_rate": 1.6060146575688655e-05,
      "epoch": 1.6983372921615203,
      "step": 7150
    },
    {
      "loss": 0.2346,
      "grad_norm": 2.6806342601776123,
      "learning_rate": 1.5428354814253223e-05,
      "epoch": 1.7102137767220902,
      "step": 7200
    },
    {
      "loss": 0.2555,
      "grad_norm": 0.5951938033103943,
      "learning_rate": 1.4796563052817792e-05,
      "epoch": 1.7220902612826603,
      "step": 7250
    },
    {
      "loss": 0.228,
      "grad_norm": 2.4482548236846924,
      "learning_rate": 1.4164771291382362e-05,
      "epoch": 1.7339667458432304,
      "step": 7300
    },
    {
      "loss": 0.2082,
      "grad_norm": 0.909457266330719,
      "learning_rate": 1.3532979529946929e-05,
      "epoch": 1.7458432304038005,
      "step": 7350
    },
    {
      "loss": 0.2267,
      "grad_norm": 1.5601446628570557,
      "learning_rate": 1.29011877685115e-05,
      "epoch": 1.7577197149643706,
      "step": 7400
    },
    {
      "loss": 0.2203,
      "grad_norm": 3.275071144104004,
      "learning_rate": 1.2269396007076068e-05,
      "epoch": 1.7695961995249405,
      "step": 7450
    },
    {
      "loss": 0.2267,
      "grad_norm": 2.3305282592773438,
      "learning_rate": 1.1637604245640638e-05,
      "epoch": 1.7814726840855108,
      "step": 7500
    },
    {
      "loss": 0.2482,
      "grad_norm": 4.761826992034912,
      "learning_rate": 1.1005812484205207e-05,
      "epoch": 1.7933491686460807,
      "step": 7550
    },
    {
      "loss": 0.2066,
      "grad_norm": 1.978684902191162,
      "learning_rate": 1.0374020722769776e-05,
      "epoch": 1.8052256532066508,
      "step": 7600
    },
    {
      "loss": 0.2386,
      "grad_norm": 4.645361423492432,
      "learning_rate": 9.742228961334344e-06,
      "epoch": 1.817102137767221,
      "step": 7650
    },
    {
      "loss": 0.2416,
      "grad_norm": 1.6930121183395386,
      "learning_rate": 9.110437199898913e-06,
      "epoch": 1.8289786223277908,
      "step": 7700
    },
    {
      "loss": 0.2166,
      "grad_norm": 1.664767861366272,
      "learning_rate": 8.478645438463483e-06,
      "epoch": 1.8408551068883612,
      "step": 7750
    },
    {
      "loss": 0.1874,
      "grad_norm": 1.0744696855545044,
      "learning_rate": 7.846853677028052e-06,
      "epoch": 1.852731591448931,
      "step": 7800
    },
    {
      "loss": 0.2124,
      "grad_norm": 1.7044833898544312,
      "learning_rate": 7.2150619155926204e-06,
      "epoch": 1.8646080760095012,
      "step": 7850
    },
    {
      "loss": 0.2235,
      "grad_norm": 2.182147741317749,
      "learning_rate": 6.58327015415719e-06,
      "epoch": 1.8764845605700713,
      "step": 7900
    },
    {
      "loss": 0.2564,
      "grad_norm": 4.053849220275879,
      "learning_rate": 5.951478392721759e-06,
      "epoch": 1.8883610451306412,
      "step": 7950
    },
    {
      "loss": 0.2131,
      "grad_norm": 4.464817523956299,
      "learning_rate": 5.319686631286328e-06,
      "epoch": 1.9002375296912115,
      "step": 8000
    },
    {
      "loss": 0.2223,
      "grad_norm": 2.6660656929016113,
      "learning_rate": 4.6878948698508975e-06,
      "epoch": 1.9121140142517814,
      "step": 8050
    },
    {
      "loss": 0.2444,
      "grad_norm": 1.5457509756088257,
      "learning_rate": 4.056103108415466e-06,
      "epoch": 1.9239904988123515,
      "step": 8100
    },
    {
      "loss": 0.217,
      "grad_norm": 1.2446798086166382,
      "learning_rate": 3.424311346980036e-06,
      "epoch": 1.9358669833729216,
      "step": 8150
    },
    {
      "loss": 0.211,
      "grad_norm": 5.091553688049316,
      "learning_rate": 2.7925195855446046e-06,
      "epoch": 1.9477434679334917,
      "step": 8200
    },
    {
      "loss": 0.2251,
      "grad_norm": 1.5188238620758057,
      "learning_rate": 2.1607278241091737e-06,
      "epoch": 1.9596199524940618,
      "step": 8250
    },
    {
      "loss": 0.2211,
      "grad_norm": 2.643890142440796,
      "learning_rate": 1.5289360626737428e-06,
      "epoch": 1.9714964370546317,
      "step": 8300
    },
    {
      "loss": 0.2512,
      "grad_norm": 5.379008769989014,
      "learning_rate": 8.971443012383118e-07,
      "epoch": 1.9833729216152018,
      "step": 8350
    },
    {
      "loss": 0.1875,
      "grad_norm": 2.963855743408203,
      "learning_rate": 2.65352539802881e-07,
      "epoch": 1.995249406175772,
      "step": 8400
    },
    {
      "eval_loss": 0.25861912965774536,
      "eval_accuracy": 0.9059633027522935,
      "eval_runtime": 1.3925,
      "eval_samples_per_second": 626.192,
      "eval_steps_per_second": 10.054,
      "epoch": 2.0,
      "step": 8420
    },
    {
      "train_runtime": 512.8091,
      "train_samples_per_second": 262.667,
      "train_steps_per_second": 16.419,
      "total_flos": 8890641309170688.0,
      "train_loss": 0.2676507979277477,
      "epoch": 2.0,
      "step": 8420
    },
    {
      "eval_loss": 0.25861912965774536,
      "eval_accuracy": 0.9059633027522935,
      "eval_runtime": 1.3927,
      "eval_samples_per_second": 626.136,
      "eval_steps_per_second": 10.053,
      "epoch": 2.0,
      "step": 8420
    }
  ]
}