{
  "mode": "lora",
  "model": "bert-base-uncased",
  "metrics": {
    "eval_loss": 0.25967714190483093,
    "eval_accuracy": 0.9036697247706422,
    "eval_runtime": 1.3792,
    "eval_samples_per_second": 632.254,
    "eval_steps_per_second": 10.151,
    "epoch": 2.0
  },
  "params": {
    "total_parameters": 109520642,
    "trainable_parameters": 38402,
    "trainable_percentage": 0.03506370972514935
  },
  "elapsed_sec": 506.58036065101624,
  "config": {
    "mode": "lora",
    "model_name": "bert-base-uncased",
    "max_length": 128,
    "epochs": 2,
    "lr": 0.0001,
    "train_batch_size": 16,
    "eval_batch_size": 64,
    "warmup_ratio": 0.06,
    "r": 1,
    "alpha": 16.0,
    "lora_dropout": 0.0,
    "output_dir": "outputs/runs",
    "results_path": "/content/drive/MyDrive/lora-tuning/results/lora_r_1.json"
  },
  "log_history": [
    {
      "loss": 0.7703,
      "grad_norm": 6.3590779304504395,
      "learning_rate": 9.683794466403162e-06,
      "epoch": 0.011876484560570071,
      "step": 50
    },
    {
      "loss": 0.7292,
      "grad_norm": 1.5105570554733276,
      "learning_rate": 1.956521739130435e-05,
      "epoch": 0.023752969121140142,
      "step": 100
    },
    {
      "loss": 0.6999,
      "grad_norm": 1.6759058237075806,
      "learning_rate": 2.9446640316205537e-05,
      "epoch": 0.035629453681710214,
      "step": 150
    },
    {
      "loss": 0.6867,
      "grad_norm": 2.6089725494384766,
      "learning_rate": 3.932806324110672e-05,
      "epoch": 0.047505938242280284,
      "step": 200
    },
    {
      "loss": 0.6759,
      "grad_norm": 2.1342356204986572,
      "learning_rate": 4.9209486166007906e-05,
      "epoch": 0.05938242280285035,
      "step": 250
    },
    {
      "loss": 0.6554,
      "grad_norm": 2.0855960845947266,
      "learning_rate": 5.90909090909091e-05,
      "epoch": 0.07125890736342043,
      "step": 300
    },
    {
      "loss": 0.5393,
      "grad_norm": 5.956079483032227,
      "learning_rate": 6.897233201581029e-05,
      "epoch": 0.0831353919239905,
      "step": 350
    },
    {
      "loss": 0.3685,
      "grad_norm": 5.478416919708252,
      "learning_rate": 7.885375494071147e-05,
      "epoch": 0.09501187648456057,
      "step": 400
    },
    {
      "loss": 0.3567,
      "grad_norm": 11.808086395263672,
      "learning_rate": 8.873517786561266e-05,
      "epoch": 0.10688836104513064,
      "step": 450
    },
    {
      "loss": 0.355,
      "grad_norm": 8.773882865905762,
      "learning_rate": 9.861660079051383e-05,
      "epoch": 0.1187648456057007,
      "step": 500
    },
    {
      "loss": 0.3403,
      "grad_norm": 4.228700637817383,
      "learning_rate": 9.945665908516553e-05,
      "epoch": 0.13064133016627077,
      "step": 550
    },
    {
      "loss": 0.3814,
      "grad_norm": 4.7476067543029785,
      "learning_rate": 9.88248673237301e-05,
      "epoch": 0.14251781472684086,
      "step": 600
    },
    {
      "loss": 0.3287,
      "grad_norm": 4.613703727722168,
      "learning_rate": 9.819307556229466e-05,
      "epoch": 0.1543942992874109,
      "step": 650
    },
    {
      "loss": 0.3047,
      "grad_norm": 7.203335285186768,
      "learning_rate": 9.756128380085923e-05,
      "epoch": 0.166270783847981,
      "step": 700
    },
    {
      "loss": 0.328,
      "grad_norm": 8.938944816589355,
      "learning_rate": 9.69294920394238e-05,
      "epoch": 0.17814726840855108,
      "step": 750
    },
    {
      "loss": 0.3287,
      "grad_norm": 6.360251426696777,
      "learning_rate": 9.629770027798838e-05,
      "epoch": 0.19002375296912113,
      "step": 800
    },
    {
      "loss": 0.3506,
      "grad_norm": 9.195812225341797,
      "learning_rate": 9.566590851655295e-05,
      "epoch": 0.20190023752969122,
      "step": 850
    },
    {
      "loss": 0.3174,
      "grad_norm": 13.896330833435059,
      "learning_rate": 9.503411675511752e-05,
      "epoch": 0.21377672209026127,
      "step": 900
    },
    {
      "loss": 0.3024,
      "grad_norm": 20.263235092163086,
      "learning_rate": 9.44023249936821e-05,
      "epoch": 0.22565320665083136,
      "step": 950
    },
    {
      "loss": 0.296,
      "grad_norm": 6.1806721687316895,
      "learning_rate": 9.377053323224667e-05,
      "epoch": 0.2375296912114014,
      "step": 1000
    },
    {
      "loss": 0.2976,
      "grad_norm": 7.4636712074279785,
      "learning_rate": 9.313874147081122e-05,
      "epoch": 0.2494061757719715,
      "step": 1050
    },
    {
      "loss": 0.2949,
      "grad_norm": 8.436609268188477,
      "learning_rate": 9.25069497093758e-05,
      "epoch": 0.26128266033254155,
      "step": 1100
    },
    {
      "loss": 0.2904,
      "grad_norm": 13.636497497558594,
      "learning_rate": 9.187515794794035e-05,
      "epoch": 0.27315914489311166,
      "step": 1150
    },
    {
      "loss": 0.2608,
      "grad_norm": 8.056229591369629,
      "learning_rate": 9.124336618650493e-05,
      "epoch": 0.2850356294536817,
      "step": 1200
    },
    {
      "loss": 0.3044,
      "grad_norm": 5.038724422454834,
      "learning_rate": 9.06115744250695e-05,
      "epoch": 0.29691211401425177,
      "step": 1250
    },
    {
      "loss": 0.3151,
      "grad_norm": 5.125465393066406,
      "learning_rate": 8.997978266363407e-05,
      "epoch": 0.3087885985748218,
      "step": 1300
    },
    {
      "loss": 0.2869,
      "grad_norm": 1.9393184185028076,
      "learning_rate": 8.934799090219864e-05,
      "epoch": 0.32066508313539194,
      "step": 1350
    },
    {
      "loss": 0.2757,
      "grad_norm": 8.895585060119629,
      "learning_rate": 8.871619914076321e-05,
      "epoch": 0.332541567695962,
      "step": 1400
    },
    {
      "loss": 0.2755,
      "grad_norm": 12.515958786010742,
      "learning_rate": 8.808440737932779e-05,
      "epoch": 0.34441805225653205,
      "step": 1450
    },
    {
      "loss": 0.3098,
      "grad_norm": 12.044729232788086,
      "learning_rate": 8.745261561789235e-05,
      "epoch": 0.35629453681710216,
      "step": 1500
    },
    {
      "loss": 0.3044,
      "grad_norm": 5.837901592254639,
      "learning_rate": 8.682082385645692e-05,
      "epoch": 0.3681710213776722,
      "step": 1550
    },
    {
      "loss": 0.2427,
      "grad_norm": 4.1028056144714355,
      "learning_rate": 8.618903209502148e-05,
      "epoch": 0.38004750593824227,
      "step": 1600
    },
    {
      "loss": 0.3058,
      "grad_norm": 6.038217067718506,
      "learning_rate": 8.555724033358605e-05,
      "epoch": 0.3919239904988123,
      "step": 1650
    },
    {
      "loss": 0.2775,
      "grad_norm": 10.52032470703125,
      "learning_rate": 8.492544857215062e-05,
      "epoch": 0.40380047505938244,
      "step": 1700
    },
    {
      "loss": 0.2646,
      "grad_norm": 21.171049118041992,
      "learning_rate": 8.429365681071519e-05,
      "epoch": 0.4156769596199525,
      "step": 1750
    },
    {
      "loss": 0.2869,
      "grad_norm": 8.442617416381836,
      "learning_rate": 8.366186504927976e-05,
      "epoch": 0.42755344418052255,
      "step": 1800
    },
    {
      "loss": 0.2938,
      "grad_norm": 11.308034896850586,
      "learning_rate": 8.303007328784434e-05,
      "epoch": 0.43942992874109266,
      "step": 1850
    },
    {
      "loss": 0.2753,
      "grad_norm": 3.085198402404785,
      "learning_rate": 8.239828152640891e-05,
      "epoch": 0.4513064133016627,
      "step": 1900
    },
    {
      "loss": 0.2928,
      "grad_norm": 10.951176643371582,
      "learning_rate": 8.176648976497347e-05,
      "epoch": 0.46318289786223277,
      "step": 1950
    },
    {
      "loss": 0.274,
      "grad_norm": 8.647429466247559,
      "learning_rate": 8.113469800353804e-05,
      "epoch": 0.4750593824228028,
      "step": 2000
    },
    {
      "loss": 0.3347,
      "grad_norm": 3.882711887359619,
      "learning_rate": 8.050290624210261e-05,
      "epoch": 0.48693586698337293,
      "step": 2050
    },
    {
      "loss": 0.2403,
      "grad_norm": 8.086838722229004,
      "learning_rate": 7.987111448066717e-05,
      "epoch": 0.498812351543943,
      "step": 2100
    },
    {
      "loss": 0.2573,
      "grad_norm": 5.387690544128418,
      "learning_rate": 7.923932271923174e-05,
      "epoch": 0.5106888361045131,
      "step": 2150
    },
    {
      "loss": 0.2785,
      "grad_norm": 4.591947555541992,
      "learning_rate": 7.860753095779631e-05,
      "epoch": 0.5225653206650831,
      "step": 2200
    },
    {
      "loss": 0.2473,
      "grad_norm": 6.73822546005249,
      "learning_rate": 7.797573919636088e-05,
      "epoch": 0.5344418052256532,
      "step": 2250
    },
    {
      "loss": 0.2659,
      "grad_norm": 5.296472072601318,
      "learning_rate": 7.734394743492546e-05,
      "epoch": 0.5463182897862233,
      "step": 2300
    },
    {
      "loss": 0.277,
      "grad_norm": 5.998429298400879,
      "learning_rate": 7.671215567349002e-05,
      "epoch": 0.5581947743467933,
      "step": 2350
    },
    {
      "loss": 0.2293,
      "grad_norm": 7.443140983581543,
      "learning_rate": 7.608036391205459e-05,
      "epoch": 0.5700712589073634,
      "step": 2400
    },
    {
      "loss": 0.2864,
      "grad_norm": 4.991769313812256,
      "learning_rate": 7.544857215061916e-05,
      "epoch": 0.5819477434679335,
      "step": 2450
    },
    {
      "loss": 0.2531,
      "grad_norm": 8.289926528930664,
      "learning_rate": 7.481678038918373e-05,
      "epoch": 0.5938242280285035,
      "step": 2500
    },
    {
      "loss": 0.287,
      "grad_norm": 4.644847393035889,
      "learning_rate": 7.41849886277483e-05,
      "epoch": 0.6057007125890737,
      "step": 2550
    },
    {
      "loss": 0.2672,
      "grad_norm": 8.209882736206055,
      "learning_rate": 7.355319686631286e-05,
      "epoch": 0.6175771971496437,
      "step": 2600
    },
    {
      "loss": 0.2963,
      "grad_norm": 3.4555869102478027,
      "learning_rate": 7.292140510487743e-05,
      "epoch": 0.6294536817102138,
      "step": 2650
    },
    {
      "loss": 0.2406,
      "grad_norm": 2.797734022140503,
      "learning_rate": 7.2289613343442e-05,
      "epoch": 0.6413301662707839,
      "step": 2700
    },
    {
      "loss": 0.299,
      "grad_norm": 16.07206153869629,
      "learning_rate": 7.165782158200658e-05,
      "epoch": 0.6532066508313539,
      "step": 2750
    },
    {
      "loss": 0.2719,
      "grad_norm": 8.914072036743164,
      "learning_rate": 7.102602982057114e-05,
      "epoch": 0.665083135391924,
      "step": 2800
    },
    {
      "loss": 0.2774,
      "grad_norm": 4.497160911560059,
      "learning_rate": 7.039423805913571e-05,
      "epoch": 0.6769596199524941,
      "step": 2850
    },
    {
      "loss": 0.2496,
      "grad_norm": 3.3820881843566895,
      "learning_rate": 6.976244629770028e-05,
      "epoch": 0.6888361045130641,
      "step": 2900
    },
    {
      "loss": 0.314,
      "grad_norm": 10.65402603149414,
      "learning_rate": 6.913065453626485e-05,
      "epoch": 0.7007125890736342,
      "step": 2950
    },
    {
      "loss": 0.2656,
      "grad_norm": 4.614280700683594,
      "learning_rate": 6.849886277482942e-05,
      "epoch": 0.7125890736342043,
      "step": 3000
    },
    {
      "loss": 0.2694,
      "grad_norm": 3.9027624130249023,
      "learning_rate": 6.7867071013394e-05,
      "epoch": 0.7244655581947743,
      "step": 3050
    },
    {
      "loss": 0.2383,
      "grad_norm": 11.487700462341309,
      "learning_rate": 6.723527925195856e-05,
      "epoch": 0.7363420427553444,
      "step": 3100
    },
    {
      "loss": 0.293,
      "grad_norm": 3.827946186065674,
      "learning_rate": 6.660348749052313e-05,
      "epoch": 0.7482185273159145,
      "step": 3150
    },
    {
      "loss": 0.2767,
      "grad_norm": 3.217627763748169,
      "learning_rate": 6.59716957290877e-05,
      "epoch": 0.7600950118764845,
      "step": 3200
    },
    {
      "loss": 0.2351,
      "grad_norm": 6.509360313415527,
      "learning_rate": 6.533990396765226e-05,
      "epoch": 0.7719714964370546,
      "step": 3250
    },
    {
      "loss": 0.242,
      "grad_norm": 15.296655654907227,
      "learning_rate": 6.470811220621683e-05,
      "epoch": 0.7838479809976246,
      "step": 3300
    },
    {
      "loss": 0.2593,
      "grad_norm": 15.074389457702637,
      "learning_rate": 6.40763204447814e-05,
      "epoch": 0.7957244655581948,
      "step": 3350
    },
    {
      "loss": 0.2695,
      "grad_norm": 19.153488159179688,
      "learning_rate": 6.344452868334597e-05,
      "epoch": 0.8076009501187649,
      "step": 3400
    },
    {
      "loss": 0.2986,
      "grad_norm": 3.5036723613739014,
      "learning_rate": 6.281273692191055e-05,
      "epoch": 0.8194774346793349,
      "step": 3450
    },
    {
      "loss": 0.2517,
      "grad_norm": 10.204497337341309,
      "learning_rate": 6.218094516047512e-05,
      "epoch": 0.831353919239905,
      "step": 3500
    },
    {
      "loss": 0.2527,
      "grad_norm": 5.0433478355407715,
      "learning_rate": 6.154915339903969e-05,
      "epoch": 0.8432304038004751,
      "step": 3550
    },
    {
      "loss": 0.2439,
      "grad_norm": 7.816468715667725,
      "learning_rate": 6.0917361637604255e-05,
      "epoch": 0.8551068883610451,
      "step": 3600
    },
    {
      "loss": 0.2492,
      "grad_norm": 4.665108680725098,
      "learning_rate": 6.028556987616881e-05,
      "epoch": 0.8669833729216152,
      "step": 3650
    },
    {
      "loss": 0.2426,
      "grad_norm": 2.7921528816223145,
      "learning_rate": 5.9653778114733385e-05,
      "epoch": 0.8788598574821853,
      "step": 3700
    },
    {
      "loss": 0.2565,
      "grad_norm": 9.545090675354004,
      "learning_rate": 5.902198635329795e-05,
      "epoch": 0.8907363420427553,
      "step": 3750
    },
    {
      "loss": 0.2678,
      "grad_norm": 8.581771850585938,
      "learning_rate": 5.839019459186252e-05,
      "epoch": 0.9026128266033254,
      "step": 3800
    },
    {
      "loss": 0.255,
      "grad_norm": 9.809080123901367,
      "learning_rate": 5.7758402830427095e-05,
      "epoch": 0.9144893111638955,
      "step": 3850
    },
    {
      "loss": 0.2108,
      "grad_norm": 5.181829929351807,
      "learning_rate": 5.712661106899167e-05,
      "epoch": 0.9263657957244655,
      "step": 3900
    },
    {
      "loss": 0.2668,
      "grad_norm": 5.315124034881592,
      "learning_rate": 5.649481930755623e-05,
      "epoch": 0.9382422802850356,
      "step": 3950
    },
    {
      "loss": 0.2471,
      "grad_norm": 6.96140718460083,
      "learning_rate": 5.5863027546120804e-05,
      "epoch": 0.9501187648456056,
      "step": 4000
    },
    {
      "loss": 0.238,
      "grad_norm": 1.3456311225891113,
      "learning_rate": 5.5231235784685376e-05,
      "epoch": 0.9619952494061758,
      "step": 4050
    },
    {
      "loss": 0.2227,
      "grad_norm": 9.076988220214844,
      "learning_rate": 5.4599444023249934e-05,
      "epoch": 0.9738717339667459,
      "step": 4100
    },
    {
      "loss": 0.2498,
      "grad_norm": 9.112259864807129,
      "learning_rate": 5.3967652261814506e-05,
      "epoch": 0.9857482185273159,
      "step": 4150
    },
    {
      "loss": 0.282,
      "grad_norm": 6.642319679260254,
      "learning_rate": 5.333586050037908e-05,
      "epoch": 0.997624703087886,
      "step": 4200
    },
    {
      "eval_loss": 0.24998782575130463,
      "eval_accuracy": 0.9013761467889908,
      "eval_runtime": 1.3855,
      "eval_samples_per_second": 629.386,
      "eval_steps_per_second": 10.105,
      "epoch": 1.0,
      "step": 4210
    },
    {
      "loss": 0.2607,
      "grad_norm": 3.645156145095825,
      "learning_rate": 5.2704068738943644e-05,
      "epoch": 1.009501187648456,
      "step": 4250
    },
    {
      "loss": 0.2488,
      "grad_norm": 8.404263496398926,
      "learning_rate": 5.2072276977508216e-05,
      "epoch": 1.0213776722090262,
      "step": 4300
    },
    {
      "loss": 0.2415,
      "grad_norm": 9.18254566192627,
      "learning_rate": 5.144048521607279e-05,
      "epoch": 1.0332541567695963,
      "step": 4350
    },
    {
      "loss": 0.2778,
      "grad_norm": 7.348111152648926,
      "learning_rate": 5.080869345463736e-05,
      "epoch": 1.0451306413301662,
      "step": 4400
    },
    {
      "loss": 0.2415,
      "grad_norm": 11.304896354675293,
      "learning_rate": 5.0176901693201925e-05,
      "epoch": 1.0570071258907363,
      "step": 4450
    },
    {
      "loss": 0.232,
      "grad_norm": 4.939112663269043,
      "learning_rate": 4.954510993176649e-05,
      "epoch": 1.0688836104513064,
      "step": 4500
    },
    {
      "loss": 0.2322,
      "grad_norm": 7.539237022399902,
      "learning_rate": 4.891331817033106e-05,
      "epoch": 1.0807600950118765,
      "step": 4550
    },
    {
      "loss": 0.2554,
      "grad_norm": 8.050922393798828,
      "learning_rate": 4.828152640889563e-05,
      "epoch": 1.0926365795724466,
      "step": 4600
    },
    {
      "loss": 0.2502,
      "grad_norm": 8.637200355529785,
      "learning_rate": 4.76497346474602e-05,
      "epoch": 1.1045130641330165,
      "step": 4650
    },
    {
      "loss": 0.2223,
      "grad_norm": 9.919831275939941,
      "learning_rate": 4.701794288602477e-05,
      "epoch": 1.1163895486935866,
      "step": 4700
    },
    {
      "loss": 0.2564,
      "grad_norm": 7.067854881286621,
      "learning_rate": 4.638615112458934e-05,
      "epoch": 1.1282660332541568,
      "step": 4750
    },
    {
      "loss": 0.2217,
      "grad_norm": 7.744994640350342,
      "learning_rate": 4.575435936315391e-05,
      "epoch": 1.1401425178147269,
      "step": 4800
    },
    {
      "loss": 0.2608,
      "grad_norm": 12.176483154296875,
      "learning_rate": 4.5122567601718474e-05,
      "epoch": 1.152019002375297,
      "step": 4850
    },
    {
      "loss": 0.2519,
      "grad_norm": 6.8405609130859375,
      "learning_rate": 4.4490775840283046e-05,
      "epoch": 1.1638954869358669,
      "step": 4900
    },
    {
      "loss": 0.2548,
      "grad_norm": 1.893871545791626,
      "learning_rate": 4.385898407884762e-05,
      "epoch": 1.175771971496437,
      "step": 4950
    },
    {
      "loss": 0.2413,
      "grad_norm": 4.91469669342041,
      "learning_rate": 4.322719231741218e-05,
      "epoch": 1.187648456057007,
      "step": 5000
    },
    {
      "loss": 0.2589,
      "grad_norm": 8.342903137207031,
      "learning_rate": 4.259540055597675e-05,
      "epoch": 1.1995249406175772,
      "step": 5050
    },
    {
      "loss": 0.2579,
      "grad_norm": 8.451610565185547,
      "learning_rate": 4.196360879454132e-05,
      "epoch": 1.2114014251781473,
      "step": 5100
    },
    {
      "loss": 0.2215,
      "grad_norm": 6.099582672119141,
      "learning_rate": 4.133181703310589e-05,
      "epoch": 1.2232779097387174,
      "step": 5150
    },
    {
      "loss": 0.2701,
      "grad_norm": 6.641089916229248,
      "learning_rate": 4.070002527167046e-05,
      "epoch": 1.2351543942992875,
      "step": 5200
    },
    {
      "loss": 0.2454,
      "grad_norm": 10.187644958496094,
      "learning_rate": 4.006823351023502e-05,
      "epoch": 1.2470308788598574,
      "step": 5250
    },
    {
      "loss": 0.2648,
      "grad_norm": 11.399707794189453,
      "learning_rate": 3.9436441748799595e-05,
      "epoch": 1.2589073634204275,
      "step": 5300
    },
    {
      "loss": 0.2479,
      "grad_norm": 7.453289985656738,
      "learning_rate": 3.880464998736417e-05,
      "epoch": 1.2707838479809976,
      "step": 5350
    },
    {
      "loss": 0.2542,
      "grad_norm": 9.916462898254395,
      "learning_rate": 3.817285822592874e-05,
      "epoch": 1.2826603325415677,
      "step": 5400
    },
    {
      "loss": 0.2228,
      "grad_norm": 13.858386993408203,
      "learning_rate": 3.7541066464493304e-05,
      "epoch": 1.2945368171021379,
      "step": 5450
    },
    {
      "loss": 0.265,
      "grad_norm": 11.2605619430542,
      "learning_rate": 3.690927470305787e-05,
      "epoch": 1.3064133016627077,
      "step": 5500
    },
    {
      "loss": 0.2616,
      "grad_norm": 2.845146417617798,
      "learning_rate": 3.627748294162244e-05,
      "epoch": 1.3182897862232779,
      "step": 5550
    },
    {
      "loss": 0.2262,
      "grad_norm": 7.913608074188232,
      "learning_rate": 3.5645691180187014e-05,
      "epoch": 1.330166270783848,
      "step": 5600
    },
    {
      "loss": 0.2338,
      "grad_norm": 6.949974536895752,
      "learning_rate": 3.5013899418751586e-05,
      "epoch": 1.342042755344418,
      "step": 5650
    },
    {
      "loss": 0.218,
      "grad_norm": 8.286713600158691,
      "learning_rate": 3.438210765731615e-05,
      "epoch": 1.3539192399049882,
      "step": 5700
    },
    {
      "loss": 0.221,
      "grad_norm": 11.597225189208984,
      "learning_rate": 3.3750315895880716e-05,
      "epoch": 1.365795724465558,
      "step": 5750
    },
    {
      "loss": 0.1896,
      "grad_norm": 10.424646377563477,
      "learning_rate": 3.311852413444529e-05,
      "epoch": 1.3776722090261282,
      "step": 5800
    },
    {
      "loss": 0.2549,
      "grad_norm": 7.1930646896362305,
      "learning_rate": 3.248673237300986e-05,
      "epoch": 1.3895486935866983,
      "step": 5850
    },
    {
      "loss": 0.2575,
      "grad_norm": 2.338658571243286,
      "learning_rate": 3.1854940611574425e-05,
      "epoch": 1.4014251781472684,
      "step": 5900
    },
    {
      "loss": 0.2621,
      "grad_norm": 5.749720573425293,
      "learning_rate": 3.1223148850139e-05,
      "epoch": 1.4133016627078385,
      "step": 5950
    },
    {
      "loss": 0.2209,
      "grad_norm": 6.5624799728393555,
      "learning_rate": 3.059135708870356e-05,
      "epoch": 1.4251781472684084,
      "step": 6000
    },
    {
      "loss": 0.2171,
      "grad_norm": 4.878602981567383,
      "learning_rate": 2.9959565327268135e-05,
      "epoch": 1.4370546318289787,
      "step": 6050
    },
    {
      "loss": 0.2576,
      "grad_norm": 8.28125,
      "learning_rate": 2.93277735658327e-05,
      "epoch": 1.4489311163895486,
      "step": 6100
    },
    {
      "loss": 0.2238,
      "grad_norm": 2.8769125938415527,
      "learning_rate": 2.8695981804397272e-05,
      "epoch": 1.4608076009501187,
      "step": 6150
    },
    {
      "loss": 0.2008,
      "grad_norm": 19.820940017700195,
      "learning_rate": 2.806419004296184e-05,
      "epoch": 1.4726840855106889,
      "step": 6200
    },
    {
      "loss": 0.2602,
      "grad_norm": 14.268671035766602,
      "learning_rate": 2.7432398281526412e-05,
      "epoch": 1.484560570071259,
      "step": 6250
    },
    {
      "loss": 0.2202,
      "grad_norm": 11.153281211853027,
      "learning_rate": 2.680060652009098e-05,
      "epoch": 1.496437054631829,
      "step": 6300
    },
    {
      "loss": 0.223,
      "grad_norm": 4.746884822845459,
      "learning_rate": 2.6168814758655546e-05,
      "epoch": 1.508313539192399,
      "step": 6350
    },
    {
      "loss": 0.2426,
      "grad_norm": 16.904821395874023,
      "learning_rate": 2.553702299722012e-05,
      "epoch": 1.520190023752969,
      "step": 6400
    },
    {
      "loss": 0.2168,
      "grad_norm": 6.556800365447998,
      "learning_rate": 2.4905231235784687e-05,
      "epoch": 1.5320665083135392,
      "step": 6450
    },
    {
      "loss": 0.3002,
      "grad_norm": 5.989536762237549,
      "learning_rate": 2.4273439474349256e-05,
      "epoch": 1.5439429928741093,
      "step": 6500
    },
    {
      "loss": 0.2241,
      "grad_norm": 10.927992820739746,
      "learning_rate": 2.3641647712913824e-05,
      "epoch": 1.5558194774346794,
      "step": 6550
    },
    {
      "loss": 0.2187,
      "grad_norm": 6.371531963348389,
      "learning_rate": 2.3009855951478393e-05,
      "epoch": 1.5676959619952493,
      "step": 6600
    },
    {
      "loss": 0.2328,
      "grad_norm": 5.680890083312988,
      "learning_rate": 2.2378064190042965e-05,
      "epoch": 1.5795724465558196,
      "step": 6650
    },
    {
      "loss": 0.2358,
      "grad_norm": 4.825839042663574,
      "learning_rate": 2.174627242860753e-05,
      "epoch": 1.5914489311163895,
      "step": 6700
    },
    {
      "loss": 0.2265,
      "grad_norm": 6.397421360015869,
      "learning_rate": 2.1114480667172102e-05,
      "epoch": 1.6033254156769596,
      "step": 6750
    },
    {
      "loss": 0.2607,
      "grad_norm": 21.196338653564453,
      "learning_rate": 2.0482688905736667e-05,
      "epoch": 1.6152019002375297,
      "step": 6800
    },
    {
      "loss": 0.2244,
      "grad_norm": 5.126216888427734,
      "learning_rate": 1.985089714430124e-05,
      "epoch": 1.6270783847980996,
      "step": 6850
    },
    {
      "loss": 0.2974,
      "grad_norm": 7.851003646850586,
      "learning_rate": 1.9219105382865808e-05,
      "epoch": 1.63895486935867,
      "step": 6900
    },
    {
      "loss": 0.2094,
      "grad_norm": 4.192049980163574,
      "learning_rate": 1.8587313621430377e-05,
      "epoch": 1.6508313539192399,
      "step": 6950
    },
    {
      "loss": 0.2469,
      "grad_norm": 4.060888767242432,
      "learning_rate": 1.795552185999495e-05,
      "epoch": 1.66270783847981,
      "step": 7000
    },
    {
      "loss": 0.1968,
      "grad_norm": 2.822942018508911,
      "learning_rate": 1.7323730098559514e-05,
      "epoch": 1.67458432304038,
      "step": 7050
    },
    {
      "loss": 0.2011,
      "grad_norm": 7.751654148101807,
      "learning_rate": 1.6691938337124086e-05,
      "epoch": 1.68646080760095,
      "step": 7100
    },
    {
      "loss": 0.2411,
      "grad_norm": 2.7512662410736084,
      "learning_rate": 1.6060146575688655e-05,
      "epoch": 1.6983372921615203,
      "step": 7150
    },
    {
      "loss": 0.2398,
      "grad_norm": 7.139206886291504,
      "learning_rate": 1.5428354814253223e-05,
      "epoch": 1.7102137767220902,
      "step": 7200
    },
    {
      "loss": 0.2757,
      "grad_norm": 1.527242660522461,
      "learning_rate": 1.4796563052817792e-05,
      "epoch": 1.7220902612826603,
      "step": 7250
    },
    {
      "loss": 0.2338,
      "grad_norm": 3.9316673278808594,
      "learning_rate": 1.4164771291382362e-05,
      "epoch": 1.7339667458432304,
      "step": 7300
    },
    {
      "loss": 0.2282,
      "grad_norm": 2.470362663269043,
      "learning_rate": 1.3532979529946929e-05,
      "epoch": 1.7458432304038005,
      "step": 7350
    },
    {
      "loss": 0.2336,
      "grad_norm": 2.368358850479126,
      "learning_rate": 1.29011877685115e-05,
      "epoch": 1.7577197149643706,
      "step": 7400
    },
    {
      "loss": 0.2314,
      "grad_norm": 9.872535705566406,
      "learning_rate": 1.2269396007076068e-05,
      "epoch": 1.7695961995249405,
      "step": 7450
    },
    {
      "loss": 0.249,
      "grad_norm": 8.811849594116211,
      "learning_rate": 1.1637604245640638e-05,
      "epoch": 1.7814726840855108,
      "step": 7500
    },
    {
      "loss": 0.2625,
      "grad_norm": 9.931602478027344,
      "learning_rate": 1.1005812484205207e-05,
      "epoch": 1.7933491686460807,
      "step": 7550
    },
    {
      "loss": 0.2157,
      "grad_norm": 4.0144572257995605,
      "learning_rate": 1.0374020722769776e-05,
      "epoch": 1.8052256532066508,
      "step": 7600
    },
    {
      "loss": 0.2356,
      "grad_norm": 10.347013473510742,
      "learning_rate": 9.742228961334344e-06,
      "epoch": 1.817102137767221,
      "step": 7650
    },
    {
      "loss": 0.2547,
      "grad_norm": 4.9409661293029785,
      "learning_rate": 9.110437199898913e-06,
      "epoch": 1.8289786223277908,
      "step": 7700
    },
    {
      "loss": 0.2225,
      "grad_norm": 1.766343355178833,
      "learning_rate": 8.478645438463483e-06,
      "epoch": 1.8408551068883612,
      "step": 7750
    },
    {
      "loss": 0.1986,
      "grad_norm": 1.5057015419006348,
      "learning_rate": 7.846853677028052e-06,
      "epoch": 1.852731591448931,
      "step": 7800
    },
    {
      "loss": 0.2178,
      "grad_norm": 9.096631050109863,
      "learning_rate": 7.2150619155926204e-06,
      "epoch": 1.8646080760095012,
      "step": 7850
    },
    {
      "loss": 0.2292,
      "grad_norm": 13.512194633483887,
      "learning_rate": 6.58327015415719e-06,
      "epoch": 1.8764845605700713,
      "step": 7900
    },
    {
      "loss": 0.2555,
      "grad_norm": 11.094843864440918,
      "learning_rate": 5.951478392721759e-06,
      "epoch": 1.8883610451306412,
      "step": 7950
    },
    {
      "loss": 0.2196,
      "grad_norm": 8.317170143127441,
      "learning_rate": 5.319686631286328e-06,
      "epoch": 1.9002375296912115,
      "step": 8000
    },
    {
      "loss": 0.2453,
      "grad_norm": 5.236673355102539,
      "learning_rate": 4.6878948698508975e-06,
      "epoch": 1.9121140142517814,
      "step": 8050
    },
    {
      "loss": 0.2451,
      "grad_norm": 4.9830756187438965,
      "learning_rate": 4.056103108415466e-06,
      "epoch": 1.9239904988123515,
      "step": 8100
    },
    {
      "loss": 0.2244,
      "grad_norm": 2.3186497688293457,
      "learning_rate": 3.424311346980036e-06,
      "epoch": 1.9358669833729216,
      "step": 8150
    },
    {
      "loss": 0.2174,
      "grad_norm": 10.924956321716309,
      "learning_rate": 2.7925195855446046e-06,
      "epoch": 1.9477434679334917,
      "step": 8200
    },
    {
      "loss": 0.2304,
      "grad_norm": 4.4058661460876465,
      "learning_rate": 2.1607278241091737e-06,
      "epoch": 1.9596199524940618,
      "step": 8250
    },
    {
      "loss": 0.2294,
      "grad_norm": 10.126534461975098,
      "learning_rate": 1.5289360626737428e-06,
      "epoch": 1.9714964370546317,
      "step": 8300
    },
    {
      "loss": 0.2536,
      "grad_norm": 14.32347583770752,
      "learning_rate": 8.971443012383118e-07,
      "epoch": 1.9833729216152018,
      "step": 8350
    },
    {
      "loss": 0.1892,
      "grad_norm": 7.230283737182617,
      "learning_rate": 2.65352539802881e-07,
      "epoch": 1.995249406175772,
      "step": 8400
    },
    {
      "eval_loss": 0.25967714190483093,
      "eval_accuracy": 0.9036697247706422,
      "eval_runtime": 1.3808,
      "eval_samples_per_second": 631.516,
      "eval_steps_per_second": 10.139,
      "epoch": 2.0,
      "step": 8420
    },
    {
      "train_runtime": 504.8724,
      "train_samples_per_second": 266.796,
      "train_steps_per_second": 16.677,
      "total_flos": 8863946743151616.0,
      "train_loss": 0.27632257309775454,
      "epoch": 2.0,
      "step": 8420
    },
    {
      "eval_loss": 0.25967714190483093,
      "eval_accuracy": 0.9036697247706422,
      "eval_runtime": 1.3792,
      "eval_samples_per_second": 632.254,
      "eval_steps_per_second": 10.151,
      "epoch": 2.0,
      "step": 8420
    }
  ]
}