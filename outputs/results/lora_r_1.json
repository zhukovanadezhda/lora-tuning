{
  "mode": "lora",
  "model": "bert-base-uncased",
  "metrics": {
    "eval_loss": 0.24972061812877655,
    "eval_accuracy": 0.9151376146788991,
    "eval_runtime": 1.3743,
    "eval_samples_per_second": 634.518,
    "eval_steps_per_second": 10.187,
    "epoch": 2.0
  },
  "params": {
    "total_parameters": 109520642,
    "trainable_parameters": 38402,
    "trainable_percentage": 0.03506370972514935
  },
  "elapsed_sec": 506.2711489200592,
  "config": {
    "mode": "lora",
    "model_name": "bert-base-uncased",
    "max_length": 128,
    "epochs": 2.0,
    "lr": 0.0001,
    "train_batch_size": 16,
    "eval_batch_size": 64,
    "warmup_ratio": 0.06,
    "r": 1,
    "alpha": 16.0,
    "lora_dropout": 0.0,
    "output_dir": "outputs/runs",
    "results_path": "/content/drive/MyDrive/lora-tuning/results/lora_r_1.json"
  },
  "log_history": [
    {
      "loss": 0.7262,
      "grad_norm": 5.415074348449707,
      "learning_rate": 9.683794466403162e-06,
      "epoch": 0.011876484560570071,
      "step": 50
    },
    {
      "loss": 0.7026,
      "grad_norm": 1.573723316192627,
      "learning_rate": 1.956521739130435e-05,
      "epoch": 0.023752969121140142,
      "step": 100
    },
    {
      "loss": 0.6941,
      "grad_norm": 1.3941597938537598,
      "learning_rate": 2.9446640316205537e-05,
      "epoch": 0.035629453681710214,
      "step": 150
    },
    {
      "loss": 0.6868,
      "grad_norm": 2.9593136310577393,
      "learning_rate": 3.932806324110672e-05,
      "epoch": 0.047505938242280284,
      "step": 200
    },
    {
      "loss": 0.6745,
      "grad_norm": 2.2737836837768555,
      "learning_rate": 4.9209486166007906e-05,
      "epoch": 0.05938242280285035,
      "step": 250
    },
    {
      "loss": 0.6666,
      "grad_norm": 2.199435234069824,
      "learning_rate": 5.90909090909091e-05,
      "epoch": 0.07125890736342043,
      "step": 300
    },
    {
      "loss": 0.6,
      "grad_norm": 4.5370893478393555,
      "learning_rate": 6.897233201581029e-05,
      "epoch": 0.0831353919239905,
      "step": 350
    },
    {
      "loss": 0.4718,
      "grad_norm": 3.793548107147217,
      "learning_rate": 7.885375494071147e-05,
      "epoch": 0.09501187648456057,
      "step": 400
    },
    {
      "loss": 0.3778,
      "grad_norm": 11.726125717163086,
      "learning_rate": 8.873517786561266e-05,
      "epoch": 0.10688836104513064,
      "step": 450
    },
    {
      "loss": 0.3504,
      "grad_norm": 10.869778633117676,
      "learning_rate": 9.861660079051383e-05,
      "epoch": 0.1187648456057007,
      "step": 500
    },
    {
      "loss": 0.3344,
      "grad_norm": 4.260447978973389,
      "learning_rate": 9.945665908516553e-05,
      "epoch": 0.13064133016627077,
      "step": 550
    },
    {
      "loss": 0.3827,
      "grad_norm": 4.940931797027588,
      "learning_rate": 9.88248673237301e-05,
      "epoch": 0.14251781472684086,
      "step": 600
    },
    {
      "loss": 0.3456,
      "grad_norm": 3.501427173614502,
      "learning_rate": 9.819307556229466e-05,
      "epoch": 0.1543942992874109,
      "step": 650
    },
    {
      "loss": 0.302,
      "grad_norm": 6.722283840179443,
      "learning_rate": 9.756128380085923e-05,
      "epoch": 0.166270783847981,
      "step": 700
    },
    {
      "loss": 0.3268,
      "grad_norm": 14.471863746643066,
      "learning_rate": 9.69294920394238e-05,
      "epoch": 0.17814726840855108,
      "step": 750
    },
    {
      "loss": 0.3408,
      "grad_norm": 6.19169807434082,
      "learning_rate": 9.629770027798838e-05,
      "epoch": 0.19002375296912113,
      "step": 800
    },
    {
      "loss": 0.3513,
      "grad_norm": 7.144522666931152,
      "learning_rate": 9.566590851655295e-05,
      "epoch": 0.20190023752969122,
      "step": 850
    },
    {
      "loss": 0.3273,
      "grad_norm": 21.104537963867188,
      "learning_rate": 9.503411675511752e-05,
      "epoch": 0.21377672209026127,
      "step": 900
    },
    {
      "loss": 0.3132,
      "grad_norm": 13.335492134094238,
      "learning_rate": 9.44023249936821e-05,
      "epoch": 0.22565320665083136,
      "step": 950
    },
    {
      "loss": 0.2984,
      "grad_norm": 12.783384323120117,
      "learning_rate": 9.377053323224667e-05,
      "epoch": 0.2375296912114014,
      "step": 1000
    },
    {
      "loss": 0.2974,
      "grad_norm": 9.448486328125,
      "learning_rate": 9.313874147081122e-05,
      "epoch": 0.2494061757719715,
      "step": 1050
    },
    {
      "loss": 0.2918,
      "grad_norm": 7.8790740966796875,
      "learning_rate": 9.25069497093758e-05,
      "epoch": 0.26128266033254155,
      "step": 1100
    },
    {
      "loss": 0.2805,
      "grad_norm": 10.275768280029297,
      "learning_rate": 9.187515794794035e-05,
      "epoch": 0.27315914489311166,
      "step": 1150
    },
    {
      "loss": 0.2591,
      "grad_norm": 6.543538570404053,
      "learning_rate": 9.124336618650493e-05,
      "epoch": 0.2850356294536817,
      "step": 1200
    },
    {
      "loss": 0.3129,
      "grad_norm": 5.203407287597656,
      "learning_rate": 9.06115744250695e-05,
      "epoch": 0.29691211401425177,
      "step": 1250
    },
    {
      "loss": 0.3202,
      "grad_norm": 5.161981582641602,
      "learning_rate": 8.997978266363407e-05,
      "epoch": 0.3087885985748218,
      "step": 1300
    },
    {
      "loss": 0.2958,
      "grad_norm": 2.306837320327759,
      "learning_rate": 8.934799090219864e-05,
      "epoch": 0.32066508313539194,
      "step": 1350
    },
    {
      "loss": 0.2702,
      "grad_norm": 10.095636367797852,
      "learning_rate": 8.871619914076321e-05,
      "epoch": 0.332541567695962,
      "step": 1400
    },
    {
      "loss": 0.2756,
      "grad_norm": 14.25475025177002,
      "learning_rate": 8.808440737932779e-05,
      "epoch": 0.34441805225653205,
      "step": 1450
    },
    {
      "loss": 0.3096,
      "grad_norm": 10.427043914794922,
      "learning_rate": 8.745261561789235e-05,
      "epoch": 0.35629453681710216,
      "step": 1500
    },
    {
      "loss": 0.3069,
      "grad_norm": 6.2749786376953125,
      "learning_rate": 8.682082385645692e-05,
      "epoch": 0.3681710213776722,
      "step": 1550
    },
    {
      "loss": 0.2469,
      "grad_norm": 3.3791329860687256,
      "learning_rate": 8.618903209502148e-05,
      "epoch": 0.38004750593824227,
      "step": 1600
    },
    {
      "loss": 0.3108,
      "grad_norm": 4.207893371582031,
      "learning_rate": 8.555724033358605e-05,
      "epoch": 0.3919239904988123,
      "step": 1650
    },
    {
      "loss": 0.2883,
      "grad_norm": 11.209739685058594,
      "learning_rate": 8.492544857215062e-05,
      "epoch": 0.40380047505938244,
      "step": 1700
    },
    {
      "loss": 0.2714,
      "grad_norm": 24.18623924255371,
      "learning_rate": 8.429365681071519e-05,
      "epoch": 0.4156769596199525,
      "step": 1750
    },
    {
      "loss": 0.292,
      "grad_norm": 9.267054557800293,
      "learning_rate": 8.366186504927976e-05,
      "epoch": 0.42755344418052255,
      "step": 1800
    },
    {
      "loss": 0.2996,
      "grad_norm": 11.871349334716797,
      "learning_rate": 8.303007328784434e-05,
      "epoch": 0.43942992874109266,
      "step": 1850
    },
    {
      "loss": 0.2804,
      "grad_norm": 5.626101016998291,
      "learning_rate": 8.239828152640891e-05,
      "epoch": 0.4513064133016627,
      "step": 1900
    },
    {
      "loss": 0.2944,
      "grad_norm": 12.304039001464844,
      "learning_rate": 8.176648976497347e-05,
      "epoch": 0.46318289786223277,
      "step": 1950
    },
    {
      "loss": 0.275,
      "grad_norm": 8.425914764404297,
      "learning_rate": 8.113469800353804e-05,
      "epoch": 0.4750593824228028,
      "step": 2000
    },
    {
      "loss": 0.341,
      "grad_norm": 4.180530071258545,
      "learning_rate": 8.050290624210261e-05,
      "epoch": 0.48693586698337293,
      "step": 2050
    },
    {
      "loss": 0.2596,
      "grad_norm": 9.188102722167969,
      "learning_rate": 7.987111448066717e-05,
      "epoch": 0.498812351543943,
      "step": 2100
    },
    {
      "loss": 0.2628,
      "grad_norm": 3.6186187267303467,
      "learning_rate": 7.923932271923174e-05,
      "epoch": 0.5106888361045131,
      "step": 2150
    },
    {
      "loss": 0.2766,
      "grad_norm": 6.9730706214904785,
      "learning_rate": 7.860753095779631e-05,
      "epoch": 0.5225653206650831,
      "step": 2200
    },
    {
      "loss": 0.2625,
      "grad_norm": 8.879332542419434,
      "learning_rate": 7.797573919636088e-05,
      "epoch": 0.5344418052256532,
      "step": 2250
    },
    {
      "loss": 0.2618,
      "grad_norm": 3.548884391784668,
      "learning_rate": 7.734394743492546e-05,
      "epoch": 0.5463182897862233,
      "step": 2300
    },
    {
      "loss": 0.2616,
      "grad_norm": 5.849452972412109,
      "learning_rate": 7.671215567349002e-05,
      "epoch": 0.5581947743467933,
      "step": 2350
    },
    {
      "loss": 0.2499,
      "grad_norm": 8.049407958984375,
      "learning_rate": 7.608036391205459e-05,
      "epoch": 0.5700712589073634,
      "step": 2400
    },
    {
      "loss": 0.2856,
      "grad_norm": 4.7359395027160645,
      "learning_rate": 7.544857215061916e-05,
      "epoch": 0.5819477434679335,
      "step": 2450
    },
    {
      "loss": 0.2437,
      "grad_norm": 7.503268718719482,
      "learning_rate": 7.481678038918373e-05,
      "epoch": 0.5938242280285035,
      "step": 2500
    },
    {
      "loss": 0.2854,
      "grad_norm": 5.430603504180908,
      "learning_rate": 7.41849886277483e-05,
      "epoch": 0.6057007125890737,
      "step": 2550
    },
    {
      "loss": 0.2631,
      "grad_norm": 11.982463836669922,
      "learning_rate": 7.355319686631286e-05,
      "epoch": 0.6175771971496437,
      "step": 2600
    },
    {
      "loss": 0.2972,
      "grad_norm": 5.347902774810791,
      "learning_rate": 7.292140510487743e-05,
      "epoch": 0.6294536817102138,
      "step": 2650
    },
    {
      "loss": 0.2359,
      "grad_norm": 1.682288646697998,
      "learning_rate": 7.2289613343442e-05,
      "epoch": 0.6413301662707839,
      "step": 2700
    },
    {
      "loss": 0.3024,
      "grad_norm": 10.578454971313477,
      "learning_rate": 7.165782158200658e-05,
      "epoch": 0.6532066508313539,
      "step": 2750
    },
    {
      "loss": 0.2687,
      "grad_norm": 6.757104873657227,
      "learning_rate": 7.102602982057114e-05,
      "epoch": 0.665083135391924,
      "step": 2800
    },
    {
      "loss": 0.2579,
      "grad_norm": 5.477760314941406,
      "learning_rate": 7.039423805913571e-05,
      "epoch": 0.6769596199524941,
      "step": 2850
    },
    {
      "loss": 0.2594,
      "grad_norm": 3.9662117958068848,
      "learning_rate": 6.976244629770028e-05,
      "epoch": 0.6888361045130641,
      "step": 2900
    },
    {
      "loss": 0.3096,
      "grad_norm": 11.65992546081543,
      "learning_rate": 6.913065453626485e-05,
      "epoch": 0.7007125890736342,
      "step": 2950
    },
    {
      "loss": 0.2551,
      "grad_norm": 6.008570671081543,
      "learning_rate": 6.849886277482942e-05,
      "epoch": 0.7125890736342043,
      "step": 3000
    },
    {
      "loss": 0.2812,
      "grad_norm": 3.795206069946289,
      "learning_rate": 6.7867071013394e-05,
      "epoch": 0.7244655581947743,
      "step": 3050
    },
    {
      "loss": 0.2539,
      "grad_norm": 11.787659645080566,
      "learning_rate": 6.723527925195856e-05,
      "epoch": 0.7363420427553444,
      "step": 3100
    },
    {
      "loss": 0.2949,
      "grad_norm": 3.709296226501465,
      "learning_rate": 6.660348749052313e-05,
      "epoch": 0.7482185273159145,
      "step": 3150
    },
    {
      "loss": 0.2874,
      "grad_norm": 3.193965196609497,
      "learning_rate": 6.59716957290877e-05,
      "epoch": 0.7600950118764845,
      "step": 3200
    },
    {
      "loss": 0.2384,
      "grad_norm": 7.075561046600342,
      "learning_rate": 6.533990396765226e-05,
      "epoch": 0.7719714964370546,
      "step": 3250
    },
    {
      "loss": 0.2588,
      "grad_norm": 10.158759117126465,
      "learning_rate": 6.470811220621683e-05,
      "epoch": 0.7838479809976246,
      "step": 3300
    },
    {
      "loss": 0.2511,
      "grad_norm": 18.611507415771484,
      "learning_rate": 6.40763204447814e-05,
      "epoch": 0.7957244655581948,
      "step": 3350
    },
    {
      "loss": 0.2858,
      "grad_norm": 15.69448184967041,
      "learning_rate": 6.344452868334597e-05,
      "epoch": 0.8076009501187649,
      "step": 3400
    },
    {
      "loss": 0.2935,
      "grad_norm": 3.9659438133239746,
      "learning_rate": 6.281273692191055e-05,
      "epoch": 0.8194774346793349,
      "step": 3450
    },
    {
      "loss": 0.2434,
      "grad_norm": 12.829364776611328,
      "learning_rate": 6.218094516047512e-05,
      "epoch": 0.831353919239905,
      "step": 3500
    },
    {
      "loss": 0.2538,
      "grad_norm": 4.367405414581299,
      "learning_rate": 6.154915339903969e-05,
      "epoch": 0.8432304038004751,
      "step": 3550
    },
    {
      "loss": 0.2331,
      "grad_norm": 9.230647087097168,
      "learning_rate": 6.0917361637604255e-05,
      "epoch": 0.8551068883610451,
      "step": 3600
    },
    {
      "loss": 0.2509,
      "grad_norm": 2.550229072570801,
      "learning_rate": 6.028556987616881e-05,
      "epoch": 0.8669833729216152,
      "step": 3650
    },
    {
      "loss": 0.2331,
      "grad_norm": 3.758990526199341,
      "learning_rate": 5.9653778114733385e-05,
      "epoch": 0.8788598574821853,
      "step": 3700
    },
    {
      "loss": 0.2638,
      "grad_norm": 11.829588890075684,
      "learning_rate": 5.902198635329795e-05,
      "epoch": 0.8907363420427553,
      "step": 3750
    },
    {
      "loss": 0.2718,
      "grad_norm": 7.851248264312744,
      "learning_rate": 5.839019459186252e-05,
      "epoch": 0.9026128266033254,
      "step": 3800
    },
    {
      "loss": 0.2479,
      "grad_norm": 11.939021110534668,
      "learning_rate": 5.7758402830427095e-05,
      "epoch": 0.9144893111638955,
      "step": 3850
    },
    {
      "loss": 0.209,
      "grad_norm": 2.1098506450653076,
      "learning_rate": 5.712661106899167e-05,
      "epoch": 0.9263657957244655,
      "step": 3900
    },
    {
      "loss": 0.2653,
      "grad_norm": 6.571756362915039,
      "learning_rate": 5.649481930755623e-05,
      "epoch": 0.9382422802850356,
      "step": 3950
    },
    {
      "loss": 0.2432,
      "grad_norm": 7.8673176765441895,
      "learning_rate": 5.5863027546120804e-05,
      "epoch": 0.9501187648456056,
      "step": 4000
    },
    {
      "loss": 0.2374,
      "grad_norm": 2.688767433166504,
      "learning_rate": 5.5231235784685376e-05,
      "epoch": 0.9619952494061758,
      "step": 4050
    },
    {
      "loss": 0.2392,
      "grad_norm": 15.437909126281738,
      "learning_rate": 5.4599444023249934e-05,
      "epoch": 0.9738717339667459,
      "step": 4100
    },
    {
      "loss": 0.2435,
      "grad_norm": 9.052546501159668,
      "learning_rate": 5.3967652261814506e-05,
      "epoch": 0.9857482185273159,
      "step": 4150
    },
    {
      "loss": 0.2778,
      "grad_norm": 7.292760372161865,
      "learning_rate": 5.333586050037908e-05,
      "epoch": 0.997624703087886,
      "step": 4200
    },
    {
      "eval_loss": 0.24977850914001465,
      "eval_accuracy": 0.9071100917431193,
      "eval_runtime": 1.3801,
      "eval_samples_per_second": 631.857,
      "eval_steps_per_second": 10.145,
      "epoch": 1.0,
      "step": 4210
    },
    {
      "loss": 0.2793,
      "grad_norm": 3.5074689388275146,
      "learning_rate": 5.2704068738943644e-05,
      "epoch": 1.009501187648456,
      "step": 4250
    },
    {
      "loss": 0.2488,
      "grad_norm": 8.657672882080078,
      "learning_rate": 5.2072276977508216e-05,
      "epoch": 1.0213776722090262,
      "step": 4300
    },
    {
      "loss": 0.2459,
      "grad_norm": 10.16732120513916,
      "learning_rate": 5.144048521607279e-05,
      "epoch": 1.0332541567695963,
      "step": 4350
    },
    {
      "loss": 0.28,
      "grad_norm": 9.317205429077148,
      "learning_rate": 5.080869345463736e-05,
      "epoch": 1.0451306413301662,
      "step": 4400
    },
    {
      "loss": 0.2439,
      "grad_norm": 12.005644798278809,
      "learning_rate": 5.0176901693201925e-05,
      "epoch": 1.0570071258907363,
      "step": 4450
    },
    {
      "loss": 0.2303,
      "grad_norm": 4.484363079071045,
      "learning_rate": 4.954510993176649e-05,
      "epoch": 1.0688836104513064,
      "step": 4500
    },
    {
      "loss": 0.2432,
      "grad_norm": 6.6866302490234375,
      "learning_rate": 4.891331817033106e-05,
      "epoch": 1.0807600950118765,
      "step": 4550
    },
    {
      "loss": 0.2469,
      "grad_norm": 8.333261489868164,
      "learning_rate": 4.828152640889563e-05,
      "epoch": 1.0926365795724466,
      "step": 4600
    },
    {
      "loss": 0.2526,
      "grad_norm": 8.623998641967773,
      "learning_rate": 4.76497346474602e-05,
      "epoch": 1.1045130641330165,
      "step": 4650
    },
    {
      "loss": 0.2048,
      "grad_norm": 6.4939284324646,
      "learning_rate": 4.701794288602477e-05,
      "epoch": 1.1163895486935866,
      "step": 4700
    },
    {
      "loss": 0.2498,
      "grad_norm": 7.312931537628174,
      "learning_rate": 4.638615112458934e-05,
      "epoch": 1.1282660332541568,
      "step": 4750
    },
    {
      "loss": 0.2273,
      "grad_norm": 14.595254898071289,
      "learning_rate": 4.575435936315391e-05,
      "epoch": 1.1401425178147269,
      "step": 4800
    },
    {
      "loss": 0.2711,
      "grad_norm": 9.263936996459961,
      "learning_rate": 4.5122567601718474e-05,
      "epoch": 1.152019002375297,
      "step": 4850
    },
    {
      "loss": 0.2631,
      "grad_norm": 9.440935134887695,
      "learning_rate": 4.4490775840283046e-05,
      "epoch": 1.1638954869358669,
      "step": 4900
    },
    {
      "loss": 0.249,
      "grad_norm": 1.5825862884521484,
      "learning_rate": 4.385898407884762e-05,
      "epoch": 1.175771971496437,
      "step": 4950
    },
    {
      "loss": 0.2428,
      "grad_norm": 4.079434871673584,
      "learning_rate": 4.322719231741218e-05,
      "epoch": 1.187648456057007,
      "step": 5000
    },
    {
      "loss": 0.26,
      "grad_norm": 8.373604774475098,
      "learning_rate": 4.259540055597675e-05,
      "epoch": 1.1995249406175772,
      "step": 5050
    },
    {
      "loss": 0.263,
      "grad_norm": 7.390406608581543,
      "learning_rate": 4.196360879454132e-05,
      "epoch": 1.2114014251781473,
      "step": 5100
    },
    {
      "loss": 0.217,
      "grad_norm": 10.348708152770996,
      "learning_rate": 4.133181703310589e-05,
      "epoch": 1.2232779097387174,
      "step": 5150
    },
    {
      "loss": 0.259,
      "grad_norm": 5.789032936096191,
      "learning_rate": 4.070002527167046e-05,
      "epoch": 1.2351543942992875,
      "step": 5200
    },
    {
      "loss": 0.2518,
      "grad_norm": 13.902642250061035,
      "learning_rate": 4.006823351023502e-05,
      "epoch": 1.2470308788598574,
      "step": 5250
    },
    {
      "loss": 0.2517,
      "grad_norm": 13.317447662353516,
      "learning_rate": 3.9436441748799595e-05,
      "epoch": 1.2589073634204275,
      "step": 5300
    },
    {
      "loss": 0.2437,
      "grad_norm": 5.445858001708984,
      "learning_rate": 3.880464998736417e-05,
      "epoch": 1.2707838479809976,
      "step": 5350
    },
    {
      "loss": 0.2561,
      "grad_norm": 4.893813610076904,
      "learning_rate": 3.817285822592874e-05,
      "epoch": 1.2826603325415677,
      "step": 5400
    },
    {
      "loss": 0.2331,
      "grad_norm": 9.36598014831543,
      "learning_rate": 3.7541066464493304e-05,
      "epoch": 1.2945368171021379,
      "step": 5450
    },
    {
      "loss": 0.2621,
      "grad_norm": 9.96438217163086,
      "learning_rate": 3.690927470305787e-05,
      "epoch": 1.3064133016627077,
      "step": 5500
    },
    {
      "loss": 0.2648,
      "grad_norm": 3.3866612911224365,
      "learning_rate": 3.627748294162244e-05,
      "epoch": 1.3182897862232779,
      "step": 5550
    },
    {
      "loss": 0.2326,
      "grad_norm": 9.28629207611084,
      "learning_rate": 3.5645691180187014e-05,
      "epoch": 1.330166270783848,
      "step": 5600
    },
    {
      "loss": 0.2289,
      "grad_norm": 9.118672370910645,
      "learning_rate": 3.5013899418751586e-05,
      "epoch": 1.342042755344418,
      "step": 5650
    },
    {
      "loss": 0.2167,
      "grad_norm": 4.213340759277344,
      "learning_rate": 3.438210765731615e-05,
      "epoch": 1.3539192399049882,
      "step": 5700
    },
    {
      "loss": 0.2319,
      "grad_norm": 15.284947395324707,
      "learning_rate": 3.3750315895880716e-05,
      "epoch": 1.365795724465558,
      "step": 5750
    },
    {
      "loss": 0.1915,
      "grad_norm": 7.314389705657959,
      "learning_rate": 3.311852413444529e-05,
      "epoch": 1.3776722090261282,
      "step": 5800
    },
    {
      "loss": 0.254,
      "grad_norm": 5.021046161651611,
      "learning_rate": 3.248673237300986e-05,
      "epoch": 1.3895486935866983,
      "step": 5850
    },
    {
      "loss": 0.2443,
      "grad_norm": 4.154745578765869,
      "learning_rate": 3.1854940611574425e-05,
      "epoch": 1.4014251781472684,
      "step": 5900
    },
    {
      "loss": 0.2603,
      "grad_norm": 5.91229248046875,
      "learning_rate": 3.1223148850139e-05,
      "epoch": 1.4133016627078385,
      "step": 5950
    },
    {
      "loss": 0.2104,
      "grad_norm": 6.324121475219727,
      "learning_rate": 3.059135708870356e-05,
      "epoch": 1.4251781472684084,
      "step": 6000
    },
    {
      "loss": 0.2349,
      "grad_norm": 5.423326015472412,
      "learning_rate": 2.9959565327268135e-05,
      "epoch": 1.4370546318289787,
      "step": 6050
    },
    {
      "loss": 0.2407,
      "grad_norm": 8.16305160522461,
      "learning_rate": 2.93277735658327e-05,
      "epoch": 1.4489311163895486,
      "step": 6100
    },
    {
      "loss": 0.2348,
      "grad_norm": 3.368269443511963,
      "learning_rate": 2.8695981804397272e-05,
      "epoch": 1.4608076009501187,
      "step": 6150
    },
    {
      "loss": 0.2077,
      "grad_norm": 19.819347381591797,
      "learning_rate": 2.806419004296184e-05,
      "epoch": 1.4726840855106889,
      "step": 6200
    },
    {
      "loss": 0.2547,
      "grad_norm": 13.336566925048828,
      "learning_rate": 2.7432398281526412e-05,
      "epoch": 1.484560570071259,
      "step": 6250
    },
    {
      "loss": 0.2088,
      "grad_norm": 9.900541305541992,
      "learning_rate": 2.680060652009098e-05,
      "epoch": 1.496437054631829,
      "step": 6300
    },
    {
      "loss": 0.2279,
      "grad_norm": 5.6479291915893555,
      "learning_rate": 2.6168814758655546e-05,
      "epoch": 1.508313539192399,
      "step": 6350
    },
    {
      "loss": 0.2403,
      "grad_norm": 20.03798484802246,
      "learning_rate": 2.553702299722012e-05,
      "epoch": 1.520190023752969,
      "step": 6400
    },
    {
      "loss": 0.2318,
      "grad_norm": 10.237272262573242,
      "learning_rate": 2.4905231235784687e-05,
      "epoch": 1.5320665083135392,
      "step": 6450
    },
    {
      "loss": 0.2971,
      "grad_norm": 6.478417873382568,
      "learning_rate": 2.4273439474349256e-05,
      "epoch": 1.5439429928741093,
      "step": 6500
    },
    {
      "loss": 0.2249,
      "grad_norm": 11.124136924743652,
      "learning_rate": 2.3641647712913824e-05,
      "epoch": 1.5558194774346794,
      "step": 6550
    },
    {
      "loss": 0.2084,
      "grad_norm": 7.088167190551758,
      "learning_rate": 2.3009855951478393e-05,
      "epoch": 1.5676959619952493,
      "step": 6600
    },
    {
      "loss": 0.2179,
      "grad_norm": 3.0622775554656982,
      "learning_rate": 2.2378064190042965e-05,
      "epoch": 1.5795724465558196,
      "step": 6650
    },
    {
      "loss": 0.2213,
      "grad_norm": 2.1230688095092773,
      "learning_rate": 2.174627242860753e-05,
      "epoch": 1.5914489311163895,
      "step": 6700
    },
    {
      "loss": 0.2211,
      "grad_norm": 15.680950164794922,
      "learning_rate": 2.1114480667172102e-05,
      "epoch": 1.6033254156769596,
      "step": 6750
    },
    {
      "loss": 0.2642,
      "grad_norm": 20.540000915527344,
      "learning_rate": 2.0482688905736667e-05,
      "epoch": 1.6152019002375297,
      "step": 6800
    },
    {
      "loss": 0.2214,
      "grad_norm": 6.104178428649902,
      "learning_rate": 1.985089714430124e-05,
      "epoch": 1.6270783847980996,
      "step": 6850
    },
    {
      "loss": 0.2862,
      "grad_norm": 7.6438727378845215,
      "learning_rate": 1.9219105382865808e-05,
      "epoch": 1.63895486935867,
      "step": 6900
    },
    {
      "loss": 0.2062,
      "grad_norm": 5.405247688293457,
      "learning_rate": 1.8587313621430377e-05,
      "epoch": 1.6508313539192399,
      "step": 6950
    },
    {
      "loss": 0.2453,
      "grad_norm": 4.084713935852051,
      "learning_rate": 1.795552185999495e-05,
      "epoch": 1.66270783847981,
      "step": 7000
    },
    {
      "loss": 0.1951,
      "grad_norm": 8.357427597045898,
      "learning_rate": 1.7323730098559514e-05,
      "epoch": 1.67458432304038,
      "step": 7050
    },
    {
      "loss": 0.1923,
      "grad_norm": 5.633657932281494,
      "learning_rate": 1.6691938337124086e-05,
      "epoch": 1.68646080760095,
      "step": 7100
    },
    {
      "loss": 0.2393,
      "grad_norm": 2.7573161125183105,
      "learning_rate": 1.6060146575688655e-05,
      "epoch": 1.6983372921615203,
      "step": 7150
    },
    {
      "loss": 0.2354,
      "grad_norm": 8.883429527282715,
      "learning_rate": 1.5428354814253223e-05,
      "epoch": 1.7102137767220902,
      "step": 7200
    },
    {
      "loss": 0.2594,
      "grad_norm": 1.305437445640564,
      "learning_rate": 1.4796563052817792e-05,
      "epoch": 1.7220902612826603,
      "step": 7250
    },
    {
      "loss": 0.24,
      "grad_norm": 5.473291873931885,
      "learning_rate": 1.4164771291382362e-05,
      "epoch": 1.7339667458432304,
      "step": 7300
    },
    {
      "loss": 0.2185,
      "grad_norm": 2.264061212539673,
      "learning_rate": 1.3532979529946929e-05,
      "epoch": 1.7458432304038005,
      "step": 7350
    },
    {
      "loss": 0.2406,
      "grad_norm": 3.959871530532837,
      "learning_rate": 1.29011877685115e-05,
      "epoch": 1.7577197149643706,
      "step": 7400
    },
    {
      "loss": 0.2183,
      "grad_norm": 7.643068790435791,
      "learning_rate": 1.2269396007076068e-05,
      "epoch": 1.7695961995249405,
      "step": 7450
    },
    {
      "loss": 0.2517,
      "grad_norm": 8.107527732849121,
      "learning_rate": 1.1637604245640638e-05,
      "epoch": 1.7814726840855108,
      "step": 7500
    },
    {
      "loss": 0.2524,
      "grad_norm": 9.464693069458008,
      "learning_rate": 1.1005812484205207e-05,
      "epoch": 1.7933491686460807,
      "step": 7550
    },
    {
      "loss": 0.212,
      "grad_norm": 4.829797744750977,
      "learning_rate": 1.0374020722769776e-05,
      "epoch": 1.8052256532066508,
      "step": 7600
    },
    {
      "loss": 0.2359,
      "grad_norm": 9.424102783203125,
      "learning_rate": 9.742228961334344e-06,
      "epoch": 1.817102137767221,
      "step": 7650
    },
    {
      "loss": 0.2559,
      "grad_norm": 1.25026535987854,
      "learning_rate": 9.110437199898913e-06,
      "epoch": 1.8289786223277908,
      "step": 7700
    },
    {
      "loss": 0.2224,
      "grad_norm": 1.6212742328643799,
      "learning_rate": 8.478645438463483e-06,
      "epoch": 1.8408551068883612,
      "step": 7750
    },
    {
      "loss": 0.1967,
      "grad_norm": 3.3129677772521973,
      "learning_rate": 7.846853677028052e-06,
      "epoch": 1.852731591448931,
      "step": 7800
    },
    {
      "loss": 0.2157,
      "grad_norm": 9.211844444274902,
      "learning_rate": 7.2150619155926204e-06,
      "epoch": 1.8646080760095012,
      "step": 7850
    },
    {
      "loss": 0.24,
      "grad_norm": 8.769883155822754,
      "learning_rate": 6.58327015415719e-06,
      "epoch": 1.8764845605700713,
      "step": 7900
    },
    {
      "loss": 0.26,
      "grad_norm": 9.975980758666992,
      "learning_rate": 5.951478392721759e-06,
      "epoch": 1.8883610451306412,
      "step": 7950
    },
    {
      "loss": 0.2222,
      "grad_norm": 8.760686874389648,
      "learning_rate": 5.319686631286328e-06,
      "epoch": 1.9002375296912115,
      "step": 8000
    },
    {
      "loss": 0.2272,
      "grad_norm": 4.993241310119629,
      "learning_rate": 4.6878948698508975e-06,
      "epoch": 1.9121140142517814,
      "step": 8050
    },
    {
      "loss": 0.2401,
      "grad_norm": 5.894038677215576,
      "learning_rate": 4.056103108415466e-06,
      "epoch": 1.9239904988123515,
      "step": 8100
    },
    {
      "loss": 0.2229,
      "grad_norm": 2.9311349391937256,
      "learning_rate": 3.424311346980036e-06,
      "epoch": 1.9358669833729216,
      "step": 8150
    },
    {
      "loss": 0.2149,
      "grad_norm": 10.361861228942871,
      "learning_rate": 2.7925195855446046e-06,
      "epoch": 1.9477434679334917,
      "step": 8200
    },
    {
      "loss": 0.223,
      "grad_norm": 2.5188634395599365,
      "learning_rate": 2.1607278241091737e-06,
      "epoch": 1.9596199524940618,
      "step": 8250
    },
    {
      "loss": 0.2173,
      "grad_norm": 9.180610656738281,
      "learning_rate": 1.5289360626737428e-06,
      "epoch": 1.9714964370546317,
      "step": 8300
    },
    {
      "loss": 0.2379,
      "grad_norm": 12.50586986541748,
      "learning_rate": 8.971443012383118e-07,
      "epoch": 1.9833729216152018,
      "step": 8350
    },
    {
      "loss": 0.2032,
      "grad_norm": 8.903207778930664,
      "learning_rate": 2.65352539802881e-07,
      "epoch": 1.995249406175772,
      "step": 8400
    },
    {
      "eval_loss": 0.24972061812877655,
      "eval_accuracy": 0.9151376146788991,
      "eval_runtime": 1.3789,
      "eval_samples_per_second": 632.382,
      "eval_steps_per_second": 10.153,
      "epoch": 2.0,
      "step": 8420
    },
    {
      "train_runtime": 504.5722,
      "train_samples_per_second": 266.955,
      "train_steps_per_second": 16.687,
      "total_flos": 8863946743151616.0,
      "train_loss": 0.27707401669789944,
      "epoch": 2.0,
      "step": 8420
    },
    {
      "eval_loss": 0.24972061812877655,
      "eval_accuracy": 0.9151376146788991,
      "eval_runtime": 1.3743,
      "eval_samples_per_second": 634.518,
      "eval_steps_per_second": 10.187,
      "epoch": 2.0,
      "step": 8420
    }
  ]
}