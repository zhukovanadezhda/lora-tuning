{
  "mode": "adapter",
  "model": "bert-base-uncased",
  "metrics": {
    "eval_loss": 0.30401694774627686,
    "eval_accuracy": 0.8761467889908257,
    "eval_runtime": 1.3865,
    "eval_samples_per_second": 628.91,
    "eval_steps_per_second": 10.097,
    "epoch": 2.0
  },
  "params": {
    "total_parameters": 109549828,
    "trainable_parameters": 66050,
    "trainable_percentage": 0.06029219872440147
  },
  "elapsed_sec": 533.2650561332703,
  "config": {
    "mode": "adapter",
    "model_name": "bert-base-uncased",
    "max_length": 128,
    "epochs": 2,
    "lr": 0.0001,
    "train_batch_size": 16,
    "eval_batch_size": 64,
    "warmup_ratio": 0.06,
    "r": 4,
    "alpha": 16.0,
    "lora_dropout": 0.0,
    "output_dir": "outputs/runs",
    "results_path": "/content/drive/MyDrive/lora-tuning/results/adapter.json"
  },
  "log_history": [
    {
      "loss": 0.6995,
      "grad_norm": 1.6140203475952148,
      "learning_rate": 9.683794466403162e-06,
      "epoch": 0.011876484560570071,
      "step": 50
    },
    {
      "loss": 0.6987,
      "grad_norm": 2.7689638137817383,
      "learning_rate": 1.956521739130435e-05,
      "epoch": 0.023752969121140142,
      "step": 100
    },
    {
      "loss": 0.6924,
      "grad_norm": 1.3570061922073364,
      "learning_rate": 2.9446640316205537e-05,
      "epoch": 0.035629453681710214,
      "step": 150
    },
    {
      "loss": 0.6983,
      "grad_norm": 2.634185791015625,
      "learning_rate": 3.932806324110672e-05,
      "epoch": 0.047505938242280284,
      "step": 200
    },
    {
      "loss": 0.687,
      "grad_norm": 1.7081670761108398,
      "learning_rate": 4.9209486166007906e-05,
      "epoch": 0.05938242280285035,
      "step": 250
    },
    {
      "loss": 0.6909,
      "grad_norm": 1.127826452255249,
      "learning_rate": 5.90909090909091e-05,
      "epoch": 0.07125890736342043,
      "step": 300
    },
    {
      "loss": 0.685,
      "grad_norm": 1.0226800441741943,
      "learning_rate": 6.897233201581029e-05,
      "epoch": 0.0831353919239905,
      "step": 350
    },
    {
      "loss": 0.6835,
      "grad_norm": 2.0720086097717285,
      "learning_rate": 7.885375494071147e-05,
      "epoch": 0.09501187648456057,
      "step": 400
    },
    {
      "loss": 0.6773,
      "grad_norm": 5.404873847961426,
      "learning_rate": 8.873517786561266e-05,
      "epoch": 0.10688836104513064,
      "step": 450
    },
    {
      "loss": 0.6792,
      "grad_norm": 2.643604278564453,
      "learning_rate": 9.861660079051383e-05,
      "epoch": 0.1187648456057007,
      "step": 500
    },
    {
      "loss": 0.6754,
      "grad_norm": 2.967968702316284,
      "learning_rate": 9.945665908516553e-05,
      "epoch": 0.13064133016627077,
      "step": 550
    },
    {
      "loss": 0.6812,
      "grad_norm": 2.015451669692993,
      "learning_rate": 9.88248673237301e-05,
      "epoch": 0.14251781472684086,
      "step": 600
    },
    {
      "loss": 0.6703,
      "grad_norm": 2.4476633071899414,
      "learning_rate": 9.819307556229466e-05,
      "epoch": 0.1543942992874109,
      "step": 650
    },
    {
      "loss": 0.6636,
      "grad_norm": 1.5831258296966553,
      "learning_rate": 9.756128380085923e-05,
      "epoch": 0.166270783847981,
      "step": 700
    },
    {
      "loss": 0.6657,
      "grad_norm": 1.1517624855041504,
      "learning_rate": 9.69294920394238e-05,
      "epoch": 0.17814726840855108,
      "step": 750
    },
    {
      "loss": 0.6608,
      "grad_norm": 1.6383851766586304,
      "learning_rate": 9.629770027798838e-05,
      "epoch": 0.19002375296912113,
      "step": 800
    },
    {
      "loss": 0.6465,
      "grad_norm": 1.9625630378723145,
      "learning_rate": 9.566590851655295e-05,
      "epoch": 0.20190023752969122,
      "step": 850
    },
    {
      "loss": 0.6452,
      "grad_norm": 4.413792133331299,
      "learning_rate": 9.503411675511752e-05,
      "epoch": 0.21377672209026127,
      "step": 900
    },
    {
      "loss": 0.632,
      "grad_norm": 1.3597650527954102,
      "learning_rate": 9.44023249936821e-05,
      "epoch": 0.22565320665083136,
      "step": 950
    },
    {
      "loss": 0.6183,
      "grad_norm": 2.4573495388031006,
      "learning_rate": 9.377053323224667e-05,
      "epoch": 0.2375296912114014,
      "step": 1000
    },
    {
      "loss": 0.6263,
      "grad_norm": 1.365953803062439,
      "learning_rate": 9.313874147081122e-05,
      "epoch": 0.2494061757719715,
      "step": 1050
    },
    {
      "loss": 0.6118,
      "grad_norm": 1.5976970195770264,
      "learning_rate": 9.25069497093758e-05,
      "epoch": 0.26128266033254155,
      "step": 1100
    },
    {
      "loss": 0.5969,
      "grad_norm": 3.157090902328491,
      "learning_rate": 9.187515794794035e-05,
      "epoch": 0.27315914489311166,
      "step": 1150
    },
    {
      "loss": 0.582,
      "grad_norm": 3.315711498260498,
      "learning_rate": 9.124336618650493e-05,
      "epoch": 0.2850356294536817,
      "step": 1200
    },
    {
      "loss": 0.5858,
      "grad_norm": 2.4470856189727783,
      "learning_rate": 9.06115744250695e-05,
      "epoch": 0.29691211401425177,
      "step": 1250
    },
    {
      "loss": 0.5616,
      "grad_norm": 1.9498974084854126,
      "learning_rate": 8.997978266363407e-05,
      "epoch": 0.3087885985748218,
      "step": 1300
    },
    {
      "loss": 0.5647,
      "grad_norm": 1.3872085809707642,
      "learning_rate": 8.934799090219864e-05,
      "epoch": 0.32066508313539194,
      "step": 1350
    },
    {
      "loss": 0.5234,
      "grad_norm": 1.7237434387207031,
      "learning_rate": 8.871619914076321e-05,
      "epoch": 0.332541567695962,
      "step": 1400
    },
    {
      "loss": 0.5235,
      "grad_norm": 1.2864081859588623,
      "learning_rate": 8.808440737932779e-05,
      "epoch": 0.34441805225653205,
      "step": 1450
    },
    {
      "loss": 0.5473,
      "grad_norm": 3.716921091079712,
      "learning_rate": 8.745261561789235e-05,
      "epoch": 0.35629453681710216,
      "step": 1500
    },
    {
      "loss": 0.5144,
      "grad_norm": 1.0656408071517944,
      "learning_rate": 8.682082385645692e-05,
      "epoch": 0.3681710213776722,
      "step": 1550
    },
    {
      "loss": 0.4946,
      "grad_norm": 2.047990322113037,
      "learning_rate": 8.618903209502148e-05,
      "epoch": 0.38004750593824227,
      "step": 1600
    },
    {
      "loss": 0.5133,
      "grad_norm": 2.9978842735290527,
      "learning_rate": 8.555724033358605e-05,
      "epoch": 0.3919239904988123,
      "step": 1650
    },
    {
      "loss": 0.4977,
      "grad_norm": 1.0395241975784302,
      "learning_rate": 8.492544857215062e-05,
      "epoch": 0.40380047505938244,
      "step": 1700
    },
    {
      "loss": 0.47,
      "grad_norm": 1.6386300325393677,
      "learning_rate": 8.429365681071519e-05,
      "epoch": 0.4156769596199525,
      "step": 1750
    },
    {
      "loss": 0.4741,
      "grad_norm": 1.3815672397613525,
      "learning_rate": 8.366186504927976e-05,
      "epoch": 0.42755344418052255,
      "step": 1800
    },
    {
      "loss": 0.4703,
      "grad_norm": 2.1851370334625244,
      "learning_rate": 8.303007328784434e-05,
      "epoch": 0.43942992874109266,
      "step": 1850
    },
    {
      "loss": 0.4505,
      "grad_norm": 1.4960402250289917,
      "learning_rate": 8.239828152640891e-05,
      "epoch": 0.4513064133016627,
      "step": 1900
    },
    {
      "loss": 0.4433,
      "grad_norm": 2.1550612449645996,
      "learning_rate": 8.176648976497347e-05,
      "epoch": 0.46318289786223277,
      "step": 1950
    },
    {
      "loss": 0.4376,
      "grad_norm": 2.2520205974578857,
      "learning_rate": 8.113469800353804e-05,
      "epoch": 0.4750593824228028,
      "step": 2000
    },
    {
      "loss": 0.4803,
      "grad_norm": 1.7361301183700562,
      "learning_rate": 8.050290624210261e-05,
      "epoch": 0.48693586698337293,
      "step": 2050
    },
    {
      "loss": 0.4295,
      "grad_norm": 2.296088218688965,
      "learning_rate": 7.987111448066717e-05,
      "epoch": 0.498812351543943,
      "step": 2100
    },
    {
      "loss": 0.4011,
      "grad_norm": 1.1934655904769897,
      "learning_rate": 7.923932271923174e-05,
      "epoch": 0.5106888361045131,
      "step": 2150
    },
    {
      "loss": 0.4122,
      "grad_norm": 1.1407650709152222,
      "learning_rate": 7.860753095779631e-05,
      "epoch": 0.5225653206650831,
      "step": 2200
    },
    {
      "loss": 0.3903,
      "grad_norm": 1.1345441341400146,
      "learning_rate": 7.797573919636088e-05,
      "epoch": 0.5344418052256532,
      "step": 2250
    },
    {
      "loss": 0.3992,
      "grad_norm": 1.089791178703308,
      "learning_rate": 7.734394743492546e-05,
      "epoch": 0.5463182897862233,
      "step": 2300
    },
    {
      "loss": 0.3931,
      "grad_norm": 1.974364161491394,
      "learning_rate": 7.671215567349002e-05,
      "epoch": 0.5581947743467933,
      "step": 2350
    },
    {
      "loss": 0.3821,
      "grad_norm": 2.5324699878692627,
      "learning_rate": 7.608036391205459e-05,
      "epoch": 0.5700712589073634,
      "step": 2400
    },
    {
      "loss": 0.3872,
      "grad_norm": 0.6265027523040771,
      "learning_rate": 7.544857215061916e-05,
      "epoch": 0.5819477434679335,
      "step": 2450
    },
    {
      "loss": 0.3612,
      "grad_norm": 2.054816961288452,
      "learning_rate": 7.481678038918373e-05,
      "epoch": 0.5938242280285035,
      "step": 2500
    },
    {
      "loss": 0.403,
      "grad_norm": 0.6449903845787048,
      "learning_rate": 7.41849886277483e-05,
      "epoch": 0.6057007125890737,
      "step": 2550
    },
    {
      "loss": 0.3845,
      "grad_norm": 1.7938344478607178,
      "learning_rate": 7.355319686631286e-05,
      "epoch": 0.6175771971496437,
      "step": 2600
    },
    {
      "loss": 0.4036,
      "grad_norm": 0.8020720481872559,
      "learning_rate": 7.292140510487743e-05,
      "epoch": 0.6294536817102138,
      "step": 2650
    },
    {
      "loss": 0.3755,
      "grad_norm": 1.24032461643219,
      "learning_rate": 7.2289613343442e-05,
      "epoch": 0.6413301662707839,
      "step": 2700
    },
    {
      "loss": 0.3892,
      "grad_norm": 1.5194556713104248,
      "learning_rate": 7.165782158200658e-05,
      "epoch": 0.6532066508313539,
      "step": 2750
    },
    {
      "loss": 0.3665,
      "grad_norm": 2.911919116973877,
      "learning_rate": 7.102602982057114e-05,
      "epoch": 0.665083135391924,
      "step": 2800
    },
    {
      "loss": 0.3729,
      "grad_norm": 1.0279481410980225,
      "learning_rate": 7.039423805913571e-05,
      "epoch": 0.6769596199524941,
      "step": 2850
    },
    {
      "loss": 0.3308,
      "grad_norm": 0.937877893447876,
      "learning_rate": 6.976244629770028e-05,
      "epoch": 0.6888361045130641,
      "step": 2900
    },
    {
      "loss": 0.3834,
      "grad_norm": 1.6396528482437134,
      "learning_rate": 6.913065453626485e-05,
      "epoch": 0.7007125890736342,
      "step": 2950
    },
    {
      "loss": 0.3556,
      "grad_norm": 1.2717161178588867,
      "learning_rate": 6.849886277482942e-05,
      "epoch": 0.7125890736342043,
      "step": 3000
    },
    {
      "loss": 0.3536,
      "grad_norm": 1.3737516403198242,
      "learning_rate": 6.7867071013394e-05,
      "epoch": 0.7244655581947743,
      "step": 3050
    },
    {
      "loss": 0.3478,
      "grad_norm": 1.2137717008590698,
      "learning_rate": 6.723527925195856e-05,
      "epoch": 0.7363420427553444,
      "step": 3100
    },
    {
      "loss": 0.3873,
      "grad_norm": 0.6961869597434998,
      "learning_rate": 6.660348749052313e-05,
      "epoch": 0.7482185273159145,
      "step": 3150
    },
    {
      "loss": 0.3863,
      "grad_norm": 1.0144892930984497,
      "learning_rate": 6.59716957290877e-05,
      "epoch": 0.7600950118764845,
      "step": 3200
    },
    {
      "loss": 0.3333,
      "grad_norm": 0.9733514189720154,
      "learning_rate": 6.533990396765226e-05,
      "epoch": 0.7719714964370546,
      "step": 3250
    },
    {
      "loss": 0.3445,
      "grad_norm": 1.3856366872787476,
      "learning_rate": 6.470811220621683e-05,
      "epoch": 0.7838479809976246,
      "step": 3300
    },
    {
      "loss": 0.3485,
      "grad_norm": 4.767081260681152,
      "learning_rate": 6.40763204447814e-05,
      "epoch": 0.7957244655581948,
      "step": 3350
    },
    {
      "loss": 0.3681,
      "grad_norm": 3.349936008453369,
      "learning_rate": 6.344452868334597e-05,
      "epoch": 0.8076009501187649,
      "step": 3400
    },
    {
      "loss": 0.3766,
      "grad_norm": 2.6020898818969727,
      "learning_rate": 6.281273692191055e-05,
      "epoch": 0.8194774346793349,
      "step": 3450
    },
    {
      "loss": 0.3346,
      "grad_norm": 1.1600041389465332,
      "learning_rate": 6.218094516047512e-05,
      "epoch": 0.831353919239905,
      "step": 3500
    },
    {
      "loss": 0.3536,
      "grad_norm": 0.6592464447021484,
      "learning_rate": 6.154915339903969e-05,
      "epoch": 0.8432304038004751,
      "step": 3550
    },
    {
      "loss": 0.3297,
      "grad_norm": 1.0593355894088745,
      "learning_rate": 6.0917361637604255e-05,
      "epoch": 0.8551068883610451,
      "step": 3600
    },
    {
      "loss": 0.3476,
      "grad_norm": 2.4931232929229736,
      "learning_rate": 6.028556987616881e-05,
      "epoch": 0.8669833729216152,
      "step": 3650
    },
    {
      "loss": 0.3115,
      "grad_norm": 1.3661543130874634,
      "learning_rate": 5.9653778114733385e-05,
      "epoch": 0.8788598574821853,
      "step": 3700
    },
    {
      "loss": 0.3296,
      "grad_norm": 1.3196337223052979,
      "learning_rate": 5.902198635329795e-05,
      "epoch": 0.8907363420427553,
      "step": 3750
    },
    {
      "loss": 0.337,
      "grad_norm": 1.0568147897720337,
      "learning_rate": 5.839019459186252e-05,
      "epoch": 0.9026128266033254,
      "step": 3800
    },
    {
      "loss": 0.3238,
      "grad_norm": 2.213338851928711,
      "learning_rate": 5.7758402830427095e-05,
      "epoch": 0.9144893111638955,
      "step": 3850
    },
    {
      "loss": 0.3177,
      "grad_norm": 1.7652173042297363,
      "learning_rate": 5.712661106899167e-05,
      "epoch": 0.9263657957244655,
      "step": 3900
    },
    {
      "loss": 0.3502,
      "grad_norm": 1.0367710590362549,
      "learning_rate": 5.649481930755623e-05,
      "epoch": 0.9382422802850356,
      "step": 3950
    },
    {
      "loss": 0.32,
      "grad_norm": 1.5203438997268677,
      "learning_rate": 5.5863027546120804e-05,
      "epoch": 0.9501187648456056,
      "step": 4000
    },
    {
      "loss": 0.3387,
      "grad_norm": 2.144108533859253,
      "learning_rate": 5.5231235784685376e-05,
      "epoch": 0.9619952494061758,
      "step": 4050
    },
    {
      "loss": 0.3255,
      "grad_norm": 1.6688817739486694,
      "learning_rate": 5.4599444023249934e-05,
      "epoch": 0.9738717339667459,
      "step": 4100
    },
    {
      "loss": 0.3136,
      "grad_norm": 0.589383602142334,
      "learning_rate": 5.3967652261814506e-05,
      "epoch": 0.9857482185273159,
      "step": 4150
    },
    {
      "loss": 0.3538,
      "grad_norm": 1.2284042835235596,
      "learning_rate": 5.333586050037908e-05,
      "epoch": 0.997624703087886,
      "step": 4200
    },
    {
      "eval_loss": 0.3118390440940857,
      "eval_accuracy": 0.8658256880733946,
      "eval_runtime": 1.3924,
      "eval_samples_per_second": 626.263,
      "eval_steps_per_second": 10.055,
      "epoch": 1.0,
      "step": 4210
    },
    {
      "loss": 0.3608,
      "grad_norm": 2.00846004486084,
      "learning_rate": 5.2704068738943644e-05,
      "epoch": 1.009501187648456,
      "step": 4250
    },
    {
      "loss": 0.3555,
      "grad_norm": 3.116053819656372,
      "learning_rate": 5.2072276977508216e-05,
      "epoch": 1.0213776722090262,
      "step": 4300
    },
    {
      "loss": 0.3454,
      "grad_norm": 2.91015625,
      "learning_rate": 5.144048521607279e-05,
      "epoch": 1.0332541567695963,
      "step": 4350
    },
    {
      "loss": 0.3741,
      "grad_norm": 1.5361195802688599,
      "learning_rate": 5.080869345463736e-05,
      "epoch": 1.0451306413301662,
      "step": 4400
    },
    {
      "loss": 0.3324,
      "grad_norm": 2.56884503364563,
      "learning_rate": 5.0176901693201925e-05,
      "epoch": 1.0570071258907363,
      "step": 4450
    },
    {
      "loss": 0.3208,
      "grad_norm": 2.495698928833008,
      "learning_rate": 4.954510993176649e-05,
      "epoch": 1.0688836104513064,
      "step": 4500
    },
    {
      "loss": 0.3241,
      "grad_norm": 3.7538669109344482,
      "learning_rate": 4.891331817033106e-05,
      "epoch": 1.0807600950118765,
      "step": 4550
    },
    {
      "loss": 0.341,
      "grad_norm": 2.7018818855285645,
      "learning_rate": 4.828152640889563e-05,
      "epoch": 1.0926365795724466,
      "step": 4600
    },
    {
      "loss": 0.3328,
      "grad_norm": 1.7312184572219849,
      "learning_rate": 4.76497346474602e-05,
      "epoch": 1.1045130641330165,
      "step": 4650
    },
    {
      "loss": 0.314,
      "grad_norm": 0.8181819319725037,
      "learning_rate": 4.701794288602477e-05,
      "epoch": 1.1163895486935866,
      "step": 4700
    },
    {
      "loss": 0.3289,
      "grad_norm": 2.2561047077178955,
      "learning_rate": 4.638615112458934e-05,
      "epoch": 1.1282660332541568,
      "step": 4750
    },
    {
      "loss": 0.3192,
      "grad_norm": 0.9276163578033447,
      "learning_rate": 4.575435936315391e-05,
      "epoch": 1.1401425178147269,
      "step": 4800
    },
    {
      "loss": 0.3484,
      "grad_norm": 2.7922170162200928,
      "learning_rate": 4.5122567601718474e-05,
      "epoch": 1.152019002375297,
      "step": 4850
    },
    {
      "loss": 0.355,
      "grad_norm": 2.232255458831787,
      "learning_rate": 4.4490775840283046e-05,
      "epoch": 1.1638954869358669,
      "step": 4900
    },
    {
      "loss": 0.329,
      "grad_norm": 1.009089469909668,
      "learning_rate": 4.385898407884762e-05,
      "epoch": 1.175771971496437,
      "step": 4950
    },
    {
      "loss": 0.3596,
      "grad_norm": 1.6965758800506592,
      "learning_rate": 4.322719231741218e-05,
      "epoch": 1.187648456057007,
      "step": 5000
    },
    {
      "loss": 0.3675,
      "grad_norm": 1.8136664628982544,
      "learning_rate": 4.259540055597675e-05,
      "epoch": 1.1995249406175772,
      "step": 5050
    },
    {
      "loss": 0.3629,
      "grad_norm": 1.8374590873718262,
      "learning_rate": 4.196360879454132e-05,
      "epoch": 1.2114014251781473,
      "step": 5100
    },
    {
      "loss": 0.2969,
      "grad_norm": 2.689436674118042,
      "learning_rate": 4.133181703310589e-05,
      "epoch": 1.2232779097387174,
      "step": 5150
    },
    {
      "loss": 0.399,
      "grad_norm": 1.358868956565857,
      "learning_rate": 4.070002527167046e-05,
      "epoch": 1.2351543942992875,
      "step": 5200
    },
    {
      "loss": 0.3236,
      "grad_norm": 2.5279693603515625,
      "learning_rate": 4.006823351023502e-05,
      "epoch": 1.2470308788598574,
      "step": 5250
    },
    {
      "loss": 0.3444,
      "grad_norm": 1.3923957347869873,
      "learning_rate": 3.9436441748799595e-05,
      "epoch": 1.2589073634204275,
      "step": 5300
    },
    {
      "loss": 0.3214,
      "grad_norm": 2.4469048976898193,
      "learning_rate": 3.880464998736417e-05,
      "epoch": 1.2707838479809976,
      "step": 5350
    },
    {
      "loss": 0.3347,
      "grad_norm": 1.5711398124694824,
      "learning_rate": 3.817285822592874e-05,
      "epoch": 1.2826603325415677,
      "step": 5400
    },
    {
      "loss": 0.3428,
      "grad_norm": 2.8132073879241943,
      "learning_rate": 3.7541066464493304e-05,
      "epoch": 1.2945368171021379,
      "step": 5450
    },
    {
      "loss": 0.3554,
      "grad_norm": 1.071155309677124,
      "learning_rate": 3.690927470305787e-05,
      "epoch": 1.3064133016627077,
      "step": 5500
    },
    {
      "loss": 0.3479,
      "grad_norm": 1.524154543876648,
      "learning_rate": 3.627748294162244e-05,
      "epoch": 1.3182897862232779,
      "step": 5550
    },
    {
      "loss": 0.3051,
      "grad_norm": 1.004974603652954,
      "learning_rate": 3.5645691180187014e-05,
      "epoch": 1.330166270783848,
      "step": 5600
    },
    {
      "loss": 0.3285,
      "grad_norm": 1.6421834230422974,
      "learning_rate": 3.5013899418751586e-05,
      "epoch": 1.342042755344418,
      "step": 5650
    },
    {
      "loss": 0.3197,
      "grad_norm": 2.055999279022217,
      "learning_rate": 3.438210765731615e-05,
      "epoch": 1.3539192399049882,
      "step": 5700
    },
    {
      "loss": 0.3013,
      "grad_norm": 2.223276376724243,
      "learning_rate": 3.3750315895880716e-05,
      "epoch": 1.365795724465558,
      "step": 5750
    },
    {
      "loss": 0.3003,
      "grad_norm": 4.665347099304199,
      "learning_rate": 3.311852413444529e-05,
      "epoch": 1.3776722090261282,
      "step": 5800
    },
    {
      "loss": 0.3224,
      "grad_norm": 0.8355333209037781,
      "learning_rate": 3.248673237300986e-05,
      "epoch": 1.3895486935866983,
      "step": 5850
    },
    {
      "loss": 0.3588,
      "grad_norm": 1.3425654172897339,
      "learning_rate": 3.1854940611574425e-05,
      "epoch": 1.4014251781472684,
      "step": 5900
    },
    {
      "loss": 0.3155,
      "grad_norm": 1.5719980001449585,
      "learning_rate": 3.1223148850139e-05,
      "epoch": 1.4133016627078385,
      "step": 5950
    },
    {
      "loss": 0.2976,
      "grad_norm": 2.2865142822265625,
      "learning_rate": 3.059135708870356e-05,
      "epoch": 1.4251781472684084,
      "step": 6000
    },
    {
      "loss": 0.3304,
      "grad_norm": 0.8162716627120972,
      "learning_rate": 2.9959565327268135e-05,
      "epoch": 1.4370546318289787,
      "step": 6050
    },
    {
      "loss": 0.3443,
      "grad_norm": 1.3210628032684326,
      "learning_rate": 2.93277735658327e-05,
      "epoch": 1.4489311163895486,
      "step": 6100
    },
    {
      "loss": 0.3238,
      "grad_norm": 0.6148361563682556,
      "learning_rate": 2.8695981804397272e-05,
      "epoch": 1.4608076009501187,
      "step": 6150
    },
    {
      "loss": 0.2966,
      "grad_norm": 1.4238107204437256,
      "learning_rate": 2.806419004296184e-05,
      "epoch": 1.4726840855106889,
      "step": 6200
    },
    {
      "loss": 0.3315,
      "grad_norm": 2.9092464447021484,
      "learning_rate": 2.7432398281526412e-05,
      "epoch": 1.484560570071259,
      "step": 6250
    },
    {
      "loss": 0.3163,
      "grad_norm": 2.494527816772461,
      "learning_rate": 2.680060652009098e-05,
      "epoch": 1.496437054631829,
      "step": 6300
    },
    {
      "loss": 0.3336,
      "grad_norm": 1.179021954536438,
      "learning_rate": 2.6168814758655546e-05,
      "epoch": 1.508313539192399,
      "step": 6350
    },
    {
      "loss": 0.3193,
      "grad_norm": 2.2589447498321533,
      "learning_rate": 2.553702299722012e-05,
      "epoch": 1.520190023752969,
      "step": 6400
    },
    {
      "loss": 0.3122,
      "grad_norm": 3.1911227703094482,
      "learning_rate": 2.4905231235784687e-05,
      "epoch": 1.5320665083135392,
      "step": 6450
    },
    {
      "loss": 0.3758,
      "grad_norm": 1.0274080038070679,
      "learning_rate": 2.4273439474349256e-05,
      "epoch": 1.5439429928741093,
      "step": 6500
    },
    {
      "loss": 0.3018,
      "grad_norm": 1.4694865942001343,
      "learning_rate": 2.3641647712913824e-05,
      "epoch": 1.5558194774346794,
      "step": 6550
    },
    {
      "loss": 0.3021,
      "grad_norm": 1.3265959024429321,
      "learning_rate": 2.3009855951478393e-05,
      "epoch": 1.5676959619952493,
      "step": 6600
    },
    {
      "loss": 0.3033,
      "grad_norm": 0.5323240160942078,
      "learning_rate": 2.2378064190042965e-05,
      "epoch": 1.5795724465558196,
      "step": 6650
    },
    {
      "loss": 0.3163,
      "grad_norm": 1.186306118965149,
      "learning_rate": 2.174627242860753e-05,
      "epoch": 1.5914489311163895,
      "step": 6700
    },
    {
      "loss": 0.3116,
      "grad_norm": 1.6392995119094849,
      "learning_rate": 2.1114480667172102e-05,
      "epoch": 1.6033254156769596,
      "step": 6750
    },
    {
      "loss": 0.327,
      "grad_norm": 3.4942479133605957,
      "learning_rate": 2.0482688905736667e-05,
      "epoch": 1.6152019002375297,
      "step": 6800
    },
    {
      "loss": 0.3144,
      "grad_norm": 2.275779962539673,
      "learning_rate": 1.985089714430124e-05,
      "epoch": 1.6270783847980996,
      "step": 6850
    },
    {
      "loss": 0.365,
      "grad_norm": 2.0290908813476562,
      "learning_rate": 1.9219105382865808e-05,
      "epoch": 1.63895486935867,
      "step": 6900
    },
    {
      "loss": 0.3237,
      "grad_norm": 0.8917028307914734,
      "learning_rate": 1.8587313621430377e-05,
      "epoch": 1.6508313539192399,
      "step": 6950
    },
    {
      "loss": 0.3256,
      "grad_norm": 1.3430920839309692,
      "learning_rate": 1.795552185999495e-05,
      "epoch": 1.66270783847981,
      "step": 7000
    },
    {
      "loss": 0.3135,
      "grad_norm": 1.4590802192687988,
      "learning_rate": 1.7323730098559514e-05,
      "epoch": 1.67458432304038,
      "step": 7050
    },
    {
      "loss": 0.3046,
      "grad_norm": 1.0418517589569092,
      "learning_rate": 1.6691938337124086e-05,
      "epoch": 1.68646080760095,
      "step": 7100
    },
    {
      "loss": 0.3125,
      "grad_norm": 1.714439868927002,
      "learning_rate": 1.6060146575688655e-05,
      "epoch": 1.6983372921615203,
      "step": 7150
    },
    {
      "loss": 0.3571,
      "grad_norm": 0.9310299158096313,
      "learning_rate": 1.5428354814253223e-05,
      "epoch": 1.7102137767220902,
      "step": 7200
    },
    {
      "loss": 0.3476,
      "grad_norm": 0.7294454574584961,
      "learning_rate": 1.4796563052817792e-05,
      "epoch": 1.7220902612826603,
      "step": 7250
    },
    {
      "loss": 0.3,
      "grad_norm": 1.8953014612197876,
      "learning_rate": 1.4164771291382362e-05,
      "epoch": 1.7339667458432304,
      "step": 7300
    },
    {
      "loss": 0.3311,
      "grad_norm": 1.2331326007843018,
      "learning_rate": 1.3532979529946929e-05,
      "epoch": 1.7458432304038005,
      "step": 7350
    },
    {
      "loss": 0.2961,
      "grad_norm": 1.2480729818344116,
      "learning_rate": 1.29011877685115e-05,
      "epoch": 1.7577197149643706,
      "step": 7400
    },
    {
      "loss": 0.3466,
      "grad_norm": 1.3807002305984497,
      "learning_rate": 1.2269396007076068e-05,
      "epoch": 1.7695961995249405,
      "step": 7450
    },
    {
      "loss": 0.3338,
      "grad_norm": 1.6980645656585693,
      "learning_rate": 1.1637604245640638e-05,
      "epoch": 1.7814726840855108,
      "step": 7500
    },
    {
      "loss": 0.3363,
      "grad_norm": 2.8444101810455322,
      "learning_rate": 1.1005812484205207e-05,
      "epoch": 1.7933491686460807,
      "step": 7550
    },
    {
      "loss": 0.3257,
      "grad_norm": 1.8733065128326416,
      "learning_rate": 1.0374020722769776e-05,
      "epoch": 1.8052256532066508,
      "step": 7600
    },
    {
      "loss": 0.3626,
      "grad_norm": 1.5479339361190796,
      "learning_rate": 9.742228961334344e-06,
      "epoch": 1.817102137767221,
      "step": 7650
    },
    {
      "loss": 0.3204,
      "grad_norm": 1.2164921760559082,
      "learning_rate": 9.110437199898913e-06,
      "epoch": 1.8289786223277908,
      "step": 7700
    },
    {
      "loss": 0.3097,
      "grad_norm": 0.5989081263542175,
      "learning_rate": 8.478645438463483e-06,
      "epoch": 1.8408551068883612,
      "step": 7750
    },
    {
      "loss": 0.2822,
      "grad_norm": 1.5279492139816284,
      "learning_rate": 7.846853677028052e-06,
      "epoch": 1.852731591448931,
      "step": 7800
    },
    {
      "loss": 0.3232,
      "grad_norm": 1.024902582168579,
      "learning_rate": 7.2150619155926204e-06,
      "epoch": 1.8646080760095012,
      "step": 7850
    },
    {
      "loss": 0.2961,
      "grad_norm": 0.5712001919746399,
      "learning_rate": 6.58327015415719e-06,
      "epoch": 1.8764845605700713,
      "step": 7900
    },
    {
      "loss": 0.3393,
      "grad_norm": 0.9715738296508789,
      "learning_rate": 5.951478392721759e-06,
      "epoch": 1.8883610451306412,
      "step": 7950
    },
    {
      "loss": 0.3098,
      "grad_norm": 1.1022921800613403,
      "learning_rate": 5.319686631286328e-06,
      "epoch": 1.9002375296912115,
      "step": 8000
    },
    {
      "loss": 0.3095,
      "grad_norm": 0.8680005669593811,
      "learning_rate": 4.6878948698508975e-06,
      "epoch": 1.9121140142517814,
      "step": 8050
    },
    {
      "loss": 0.3296,
      "grad_norm": 1.485107183456421,
      "learning_rate": 4.056103108415466e-06,
      "epoch": 1.9239904988123515,
      "step": 8100
    },
    {
      "loss": 0.3207,
      "grad_norm": 1.2695093154907227,
      "learning_rate": 3.424311346980036e-06,
      "epoch": 1.9358669833729216,
      "step": 8150
    },
    {
      "loss": 0.3094,
      "grad_norm": 1.431785225868225,
      "learning_rate": 2.7925195855446046e-06,
      "epoch": 1.9477434679334917,
      "step": 8200
    },
    {
      "loss": 0.3284,
      "grad_norm": 0.6026334762573242,
      "learning_rate": 2.1607278241091737e-06,
      "epoch": 1.9596199524940618,
      "step": 8250
    },
    {
      "loss": 0.3465,
      "grad_norm": 1.623226523399353,
      "learning_rate": 1.5289360626737428e-06,
      "epoch": 1.9714964370546317,
      "step": 8300
    },
    {
      "loss": 0.3175,
      "grad_norm": 3.6456174850463867,
      "learning_rate": 8.971443012383118e-07,
      "epoch": 1.9833729216152018,
      "step": 8350
    },
    {
      "loss": 0.3078,
      "grad_norm": 1.7636454105377197,
      "learning_rate": 2.65352539802881e-07,
      "epoch": 1.995249406175772,
      "step": 8400
    },
    {
      "eval_loss": 0.30401694774627686,
      "eval_accuracy": 0.8761467889908257,
      "eval_runtime": 1.3896,
      "eval_samples_per_second": 627.517,
      "eval_steps_per_second": 10.075,
      "epoch": 2.0,
      "step": 8420
    },
    {
      "train_runtime": 531.5139,
      "train_samples_per_second": 253.423,
      "train_steps_per_second": 15.842,
      "total_flos": 8866965978347520.0,
      "train_loss": 0.40203437210545123,
      "epoch": 2.0,
      "step": 8420
    },
    {
      "eval_loss": 0.30401694774627686,
      "eval_accuracy": 0.8761467889908257,
      "eval_runtime": 1.3865,
      "eval_samples_per_second": 628.91,
      "eval_steps_per_second": 10.097,
      "epoch": 2.0,
      "step": 8420
    }
  ]
}