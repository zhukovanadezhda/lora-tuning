{
  "mode": "full_ft",
  "model": "bert-base-uncased",
  "metrics": {
    "eval_loss": 0.2875106930732727,
    "eval_accuracy": 0.9254587155963303,
    "eval_runtime": 1.3316,
    "eval_samples_per_second": 654.843,
    "eval_steps_per_second": 10.514,
    "epoch": 2.0
  },
  "params": {
    "total_parameters": 109483778,
    "trainable_parameters": 109483778,
    "trainable_percentage": 100.0
  },
  "elapsed_sec": 698.1410653591156,
  "config": {
    "mode": "full_ft",
    "model_name": "bert-base-uncased",
    "max_length": 128,
    "epochs": 2,
    "lr": 2e-05,
    "train_batch_size": 16,
    "eval_batch_size": 64,
    "warmup_ratio": 0.06,
    "r": 4,
    "alpha": 16.0,
    "lora_dropout": 0.0,
    "output_dir": "outputs/runs",
    "results_path": "/content/drive/MyDrive/lora-tuning/results/full_ft.json"
  },
  "log_history": [
    {
      "loss": 0.6946,
      "grad_norm": 3.3555214405059814,
      "learning_rate": 1.9367588932806323e-06,
      "epoch": 0.011876484560570071,
      "step": 50
    },
    {
      "loss": 0.6811,
      "grad_norm": 3.201411724090576,
      "learning_rate": 3.91304347826087e-06,
      "epoch": 0.023752969121140142,
      "step": 100
    },
    {
      "loss": 0.6456,
      "grad_norm": 4.736140251159668,
      "learning_rate": 5.8893280632411074e-06,
      "epoch": 0.035629453681710214,
      "step": 150
    },
    {
      "loss": 0.4789,
      "grad_norm": 13.874907493591309,
      "learning_rate": 7.865612648221344e-06,
      "epoch": 0.047505938242280284,
      "step": 200
    },
    {
      "loss": 0.3144,
      "grad_norm": 6.310667991638184,
      "learning_rate": 9.841897233201582e-06,
      "epoch": 0.05938242280285035,
      "step": 250
    },
    {
      "loss": 0.3458,
      "grad_norm": 3.849148750305176,
      "learning_rate": 1.181818181818182e-05,
      "epoch": 0.07125890736342043,
      "step": 300
    },
    {
      "loss": 0.3347,
      "grad_norm": 14.58463191986084,
      "learning_rate": 1.3794466403162057e-05,
      "epoch": 0.0831353919239905,
      "step": 350
    },
    {
      "loss": 0.3233,
      "grad_norm": 7.648555755615234,
      "learning_rate": 1.5770750988142295e-05,
      "epoch": 0.09501187648456057,
      "step": 400
    },
    {
      "loss": 0.2929,
      "grad_norm": 3.7022900581359863,
      "learning_rate": 1.774703557312253e-05,
      "epoch": 0.10688836104513064,
      "step": 450
    },
    {
      "loss": 0.3044,
      "grad_norm": 8.314139366149902,
      "learning_rate": 1.9723320158102768e-05,
      "epoch": 0.1187648456057007,
      "step": 500
    },
    {
      "loss": 0.2959,
      "grad_norm": 2.2606923580169678,
      "learning_rate": 1.989133181703311e-05,
      "epoch": 0.13064133016627077,
      "step": 550
    },
    {
      "loss": 0.3257,
      "grad_norm": 14.797063827514648,
      "learning_rate": 1.9764973464746023e-05,
      "epoch": 0.14251781472684086,
      "step": 600
    },
    {
      "loss": 0.2676,
      "grad_norm": 5.6386542320251465,
      "learning_rate": 1.9638615112458934e-05,
      "epoch": 0.1543942992874109,
      "step": 650
    },
    {
      "loss": 0.2623,
      "grad_norm": 4.761721611022949,
      "learning_rate": 1.951225676017185e-05,
      "epoch": 0.166270783847981,
      "step": 700
    },
    {
      "loss": 0.2772,
      "grad_norm": 5.70596170425415,
      "learning_rate": 1.9385898407884763e-05,
      "epoch": 0.17814726840855108,
      "step": 750
    },
    {
      "loss": 0.2704,
      "grad_norm": 8.060667037963867,
      "learning_rate": 1.9259540055597678e-05,
      "epoch": 0.19002375296912113,
      "step": 800
    },
    {
      "loss": 0.2619,
      "grad_norm": 9.93286418914795,
      "learning_rate": 1.9133181703310592e-05,
      "epoch": 0.20190023752969122,
      "step": 850
    },
    {
      "loss": 0.2681,
      "grad_norm": 14.21302604675293,
      "learning_rate": 1.9006823351023503e-05,
      "epoch": 0.21377672209026127,
      "step": 900
    },
    {
      "loss": 0.2508,
      "grad_norm": 16.719837188720703,
      "learning_rate": 1.8880464998736417e-05,
      "epoch": 0.22565320665083136,
      "step": 950
    },
    {
      "loss": 0.2269,
      "grad_norm": 32.990753173828125,
      "learning_rate": 1.8754106646449332e-05,
      "epoch": 0.2375296912114014,
      "step": 1000
    },
    {
      "loss": 0.2599,
      "grad_norm": 11.194042205810547,
      "learning_rate": 1.8627748294162246e-05,
      "epoch": 0.2494061757719715,
      "step": 1050
    },
    {
      "loss": 0.2512,
      "grad_norm": 8.802264213562012,
      "learning_rate": 1.8501389941875157e-05,
      "epoch": 0.26128266033254155,
      "step": 1100
    },
    {
      "loss": 0.2175,
      "grad_norm": 8.666629791259766,
      "learning_rate": 1.837503158958807e-05,
      "epoch": 0.27315914489311166,
      "step": 1150
    },
    {
      "loss": 0.2229,
      "grad_norm": 11.952839851379395,
      "learning_rate": 1.8248673237300986e-05,
      "epoch": 0.2850356294536817,
      "step": 1200
    },
    {
      "loss": 0.2346,
      "grad_norm": 5.077108383178711,
      "learning_rate": 1.81223148850139e-05,
      "epoch": 0.29691211401425177,
      "step": 1250
    },
    {
      "loss": 0.2335,
      "grad_norm": 7.632525444030762,
      "learning_rate": 1.7995956532726815e-05,
      "epoch": 0.3087885985748218,
      "step": 1300
    },
    {
      "loss": 0.2161,
      "grad_norm": 0.632535457611084,
      "learning_rate": 1.786959818043973e-05,
      "epoch": 0.32066508313539194,
      "step": 1350
    },
    {
      "loss": 0.2275,
      "grad_norm": 4.057933807373047,
      "learning_rate": 1.7743239828152644e-05,
      "epoch": 0.332541567695962,
      "step": 1400
    },
    {
      "loss": 0.2195,
      "grad_norm": 8.665753364562988,
      "learning_rate": 1.7616881475865558e-05,
      "epoch": 0.34441805225653205,
      "step": 1450
    },
    {
      "loss": 0.2641,
      "grad_norm": 5.4249043464660645,
      "learning_rate": 1.749052312357847e-05,
      "epoch": 0.35629453681710216,
      "step": 1500
    },
    {
      "loss": 0.2466,
      "grad_norm": 9.423138618469238,
      "learning_rate": 1.7364164771291383e-05,
      "epoch": 0.3681710213776722,
      "step": 1550
    },
    {
      "loss": 0.1816,
      "grad_norm": 7.380054950714111,
      "learning_rate": 1.7237806419004298e-05,
      "epoch": 0.38004750593824227,
      "step": 1600
    },
    {
      "loss": 0.2246,
      "grad_norm": 7.383593559265137,
      "learning_rate": 1.7111448066717212e-05,
      "epoch": 0.3919239904988123,
      "step": 1650
    },
    {
      "loss": 0.1927,
      "grad_norm": 12.254382133483887,
      "learning_rate": 1.6985089714430127e-05,
      "epoch": 0.40380047505938244,
      "step": 1700
    },
    {
      "loss": 0.1988,
      "grad_norm": 2.9013655185699463,
      "learning_rate": 1.6858731362143038e-05,
      "epoch": 0.4156769596199525,
      "step": 1750
    },
    {
      "loss": 0.1944,
      "grad_norm": 12.528029441833496,
      "learning_rate": 1.6732373009855952e-05,
      "epoch": 0.42755344418052255,
      "step": 1800
    },
    {
      "loss": 0.262,
      "grad_norm": 7.664851665496826,
      "learning_rate": 1.6606014657568867e-05,
      "epoch": 0.43942992874109266,
      "step": 1850
    },
    {
      "loss": 0.1689,
      "grad_norm": 5.658939838409424,
      "learning_rate": 1.647965630528178e-05,
      "epoch": 0.4513064133016627,
      "step": 1900
    },
    {
      "loss": 0.2196,
      "grad_norm": 18.423633575439453,
      "learning_rate": 1.6353297952994692e-05,
      "epoch": 0.46318289786223277,
      "step": 1950
    },
    {
      "loss": 0.1907,
      "grad_norm": 16.47952651977539,
      "learning_rate": 1.6226939600707606e-05,
      "epoch": 0.4750593824228028,
      "step": 2000
    },
    {
      "loss": 0.2811,
      "grad_norm": 1.0327335596084595,
      "learning_rate": 1.610058124842052e-05,
      "epoch": 0.48693586698337293,
      "step": 2050
    },
    {
      "loss": 0.2054,
      "grad_norm": 9.646439552307129,
      "learning_rate": 1.5974222896133435e-05,
      "epoch": 0.498812351543943,
      "step": 2100
    },
    {
      "loss": 0.1718,
      "grad_norm": 6.935689926147461,
      "learning_rate": 1.584786454384635e-05,
      "epoch": 0.5106888361045131,
      "step": 2150
    },
    {
      "loss": 0.1918,
      "grad_norm": 9.66391658782959,
      "learning_rate": 1.5721506191559264e-05,
      "epoch": 0.5225653206650831,
      "step": 2200
    },
    {
      "loss": 0.1967,
      "grad_norm": 4.526412487030029,
      "learning_rate": 1.559514783927218e-05,
      "epoch": 0.5344418052256532,
      "step": 2250
    },
    {
      "loss": 0.1778,
      "grad_norm": 0.16169500350952148,
      "learning_rate": 1.5468789486985093e-05,
      "epoch": 0.5463182897862233,
      "step": 2300
    },
    {
      "loss": 0.23,
      "grad_norm": 7.721001625061035,
      "learning_rate": 1.5342431134698004e-05,
      "epoch": 0.5581947743467933,
      "step": 2350
    },
    {
      "loss": 0.1889,
      "grad_norm": 3.2678513526916504,
      "learning_rate": 1.5216072782410918e-05,
      "epoch": 0.5700712589073634,
      "step": 2400
    },
    {
      "loss": 0.192,
      "grad_norm": 2.0751264095306396,
      "learning_rate": 1.5089714430123833e-05,
      "epoch": 0.5819477434679335,
      "step": 2450
    },
    {
      "loss": 0.2176,
      "grad_norm": 0.41548603773117065,
      "learning_rate": 1.4963356077836745e-05,
      "epoch": 0.5938242280285035,
      "step": 2500
    },
    {
      "loss": 0.1943,
      "grad_norm": 11.826631546020508,
      "learning_rate": 1.483699772554966e-05,
      "epoch": 0.6057007125890737,
      "step": 2550
    },
    {
      "loss": 0.1985,
      "grad_norm": 6.1526899337768555,
      "learning_rate": 1.4710639373262574e-05,
      "epoch": 0.6175771971496437,
      "step": 2600
    },
    {
      "loss": 0.2504,
      "grad_norm": 0.4099874198436737,
      "learning_rate": 1.4584281020975488e-05,
      "epoch": 0.6294536817102138,
      "step": 2650
    },
    {
      "loss": 0.2099,
      "grad_norm": 7.478063106536865,
      "learning_rate": 1.4457922668688403e-05,
      "epoch": 0.6413301662707839,
      "step": 2700
    },
    {
      "loss": 0.1971,
      "grad_norm": 8.001920700073242,
      "learning_rate": 1.4331564316401316e-05,
      "epoch": 0.6532066508313539,
      "step": 2750
    },
    {
      "loss": 0.174,
      "grad_norm": 5.752199649810791,
      "learning_rate": 1.4205205964114228e-05,
      "epoch": 0.665083135391924,
      "step": 2800
    },
    {
      "loss": 0.208,
      "grad_norm": 5.664210796356201,
      "learning_rate": 1.4078847611827143e-05,
      "epoch": 0.6769596199524941,
      "step": 2850
    },
    {
      "loss": 0.1741,
      "grad_norm": 6.335158348083496,
      "learning_rate": 1.3952489259540057e-05,
      "epoch": 0.6888361045130641,
      "step": 2900
    },
    {
      "loss": 0.2406,
      "grad_norm": 20.108856201171875,
      "learning_rate": 1.382613090725297e-05,
      "epoch": 0.7007125890736342,
      "step": 2950
    },
    {
      "loss": 0.2002,
      "grad_norm": 15.79570198059082,
      "learning_rate": 1.3699772554965884e-05,
      "epoch": 0.7125890736342043,
      "step": 3000
    },
    {
      "loss": 0.186,
      "grad_norm": 0.4351568818092346,
      "learning_rate": 1.3573414202678799e-05,
      "epoch": 0.7244655581947743,
      "step": 3050
    },
    {
      "loss": 0.1803,
      "grad_norm": 8.130193710327148,
      "learning_rate": 1.3447055850391713e-05,
      "epoch": 0.7363420427553444,
      "step": 3100
    },
    {
      "loss": 0.1981,
      "grad_norm": 0.535890519618988,
      "learning_rate": 1.3320697498104627e-05,
      "epoch": 0.7482185273159145,
      "step": 3150
    },
    {
      "loss": 0.2192,
      "grad_norm": 3.383277177810669,
      "learning_rate": 1.319433914581754e-05,
      "epoch": 0.7600950118764845,
      "step": 3200
    },
    {
      "loss": 0.187,
      "grad_norm": 15.121256828308105,
      "learning_rate": 1.3067980793530453e-05,
      "epoch": 0.7719714964370546,
      "step": 3250
    },
    {
      "loss": 0.1654,
      "grad_norm": 13.774811744689941,
      "learning_rate": 1.2941622441243367e-05,
      "epoch": 0.7838479809976246,
      "step": 3300
    },
    {
      "loss": 0.1846,
      "grad_norm": 5.454872131347656,
      "learning_rate": 1.281526408895628e-05,
      "epoch": 0.7957244655581948,
      "step": 3350
    },
    {
      "loss": 0.2112,
      "grad_norm": 13.431797981262207,
      "learning_rate": 1.2688905736669194e-05,
      "epoch": 0.8076009501187649,
      "step": 3400
    },
    {
      "loss": 0.2133,
      "grad_norm": 0.5027193427085876,
      "learning_rate": 1.2562547384382109e-05,
      "epoch": 0.8194774346793349,
      "step": 3450
    },
    {
      "loss": 0.1619,
      "grad_norm": 9.000195503234863,
      "learning_rate": 1.2436189032095023e-05,
      "epoch": 0.831353919239905,
      "step": 3500
    },
    {
      "loss": 0.1822,
      "grad_norm": 14.054037094116211,
      "learning_rate": 1.2309830679807938e-05,
      "epoch": 0.8432304038004751,
      "step": 3550
    },
    {
      "loss": 0.1565,
      "grad_norm": 0.8621898889541626,
      "learning_rate": 1.218347232752085e-05,
      "epoch": 0.8551068883610451,
      "step": 3600
    },
    {
      "loss": 0.1641,
      "grad_norm": 0.32362017035484314,
      "learning_rate": 1.2057113975233763e-05,
      "epoch": 0.8669833729216152,
      "step": 3650
    },
    {
      "loss": 0.1788,
      "grad_norm": 3.950167417526245,
      "learning_rate": 1.1930755622946677e-05,
      "epoch": 0.8788598574821853,
      "step": 3700
    },
    {
      "loss": 0.1862,
      "grad_norm": 4.649664402008057,
      "learning_rate": 1.1804397270659592e-05,
      "epoch": 0.8907363420427553,
      "step": 3750
    },
    {
      "loss": 0.1784,
      "grad_norm": 12.25818920135498,
      "learning_rate": 1.1678038918372505e-05,
      "epoch": 0.9026128266033254,
      "step": 3800
    },
    {
      "loss": 0.1706,
      "grad_norm": 7.5645294189453125,
      "learning_rate": 1.1551680566085419e-05,
      "epoch": 0.9144893111638955,
      "step": 3850
    },
    {
      "loss": 0.1486,
      "grad_norm": 0.20523910224437714,
      "learning_rate": 1.1425322213798333e-05,
      "epoch": 0.9263657957244655,
      "step": 3900
    },
    {
      "loss": 0.188,
      "grad_norm": 6.660149097442627,
      "learning_rate": 1.1298963861511248e-05,
      "epoch": 0.9382422802850356,
      "step": 3950
    },
    {
      "loss": 0.1755,
      "grad_norm": 12.177751541137695,
      "learning_rate": 1.1172605509224162e-05,
      "epoch": 0.9501187648456056,
      "step": 4000
    },
    {
      "loss": 0.1803,
      "grad_norm": 0.4472721517086029,
      "learning_rate": 1.1046247156937075e-05,
      "epoch": 0.9619952494061758,
      "step": 4050
    },
    {
      "loss": 0.1925,
      "grad_norm": 8.61634635925293,
      "learning_rate": 1.0919888804649988e-05,
      "epoch": 0.9738717339667459,
      "step": 4100
    },
    {
      "loss": 0.1537,
      "grad_norm": 3.2326362133026123,
      "learning_rate": 1.0793530452362902e-05,
      "epoch": 0.9857482185273159,
      "step": 4150
    },
    {
      "loss": 0.1539,
      "grad_norm": 4.373785018920898,
      "learning_rate": 1.0667172100075815e-05,
      "epoch": 0.997624703087886,
      "step": 4200
    },
    {
      "eval_loss": 0.2545529901981354,
      "eval_accuracy": 0.9162844036697247,
      "eval_runtime": 1.3444,
      "eval_samples_per_second": 648.595,
      "eval_steps_per_second": 10.413,
      "epoch": 1.0,
      "step": 4210
    },
    {
      "loss": 0.1091,
      "grad_norm": 9.209651947021484,
      "learning_rate": 1.0540813747788729e-05,
      "epoch": 1.009501187648456,
      "step": 4250
    },
    {
      "loss": 0.132,
      "grad_norm": 13.371114730834961,
      "learning_rate": 1.0414455395501643e-05,
      "epoch": 1.0213776722090262,
      "step": 4300
    },
    {
      "loss": 0.1062,
      "grad_norm": 5.55086088180542,
      "learning_rate": 1.0288097043214558e-05,
      "epoch": 1.0332541567695963,
      "step": 4350
    },
    {
      "loss": 0.1466,
      "grad_norm": 2.48013973236084,
      "learning_rate": 1.0161738690927472e-05,
      "epoch": 1.0451306413301662,
      "step": 4400
    },
    {
      "loss": 0.1431,
      "grad_norm": 4.248758792877197,
      "learning_rate": 1.0035380338640387e-05,
      "epoch": 1.0570071258907363,
      "step": 4450
    },
    {
      "loss": 0.0916,
      "grad_norm": 3.3466320037841797,
      "learning_rate": 9.9090219863533e-06,
      "epoch": 1.0688836104513064,
      "step": 4500
    },
    {
      "loss": 0.1483,
      "grad_norm": 6.140772342681885,
      "learning_rate": 9.782663634066212e-06,
      "epoch": 1.0807600950118765,
      "step": 4550
    },
    {
      "loss": 0.1086,
      "grad_norm": 10.413935661315918,
      "learning_rate": 9.656305281779127e-06,
      "epoch": 1.0926365795724466,
      "step": 4600
    },
    {
      "loss": 0.1083,
      "grad_norm": 11.222330093383789,
      "learning_rate": 9.52994692949204e-06,
      "epoch": 1.1045130641330165,
      "step": 4650
    },
    {
      "loss": 0.1073,
      "grad_norm": 0.07387349754571915,
      "learning_rate": 9.403588577204954e-06,
      "epoch": 1.1163895486935866,
      "step": 4700
    },
    {
      "loss": 0.1454,
      "grad_norm": 0.46779665350914,
      "learning_rate": 9.277230224917868e-06,
      "epoch": 1.1282660332541568,
      "step": 4750
    },
    {
      "loss": 0.1043,
      "grad_norm": 0.17218656837940216,
      "learning_rate": 9.150871872630782e-06,
      "epoch": 1.1401425178147269,
      "step": 4800
    },
    {
      "loss": 0.1097,
      "grad_norm": 11.912322044372559,
      "learning_rate": 9.024513520343695e-06,
      "epoch": 1.152019002375297,
      "step": 4850
    },
    {
      "loss": 0.1392,
      "grad_norm": 0.15567699074745178,
      "learning_rate": 8.89815516805661e-06,
      "epoch": 1.1638954869358669,
      "step": 4900
    },
    {
      "loss": 0.14,
      "grad_norm": 3.2342967987060547,
      "learning_rate": 8.771796815769524e-06,
      "epoch": 1.175771971496437,
      "step": 4950
    },
    {
      "loss": 0.1291,
      "grad_norm": 2.421294927597046,
      "learning_rate": 8.645438463482437e-06,
      "epoch": 1.187648456057007,
      "step": 5000
    },
    {
      "loss": 0.121,
      "grad_norm": 3.544182538986206,
      "learning_rate": 8.519080111195351e-06,
      "epoch": 1.1995249406175772,
      "step": 5050
    },
    {
      "loss": 0.1199,
      "grad_norm": 8.295388221740723,
      "learning_rate": 8.392721758908264e-06,
      "epoch": 1.2114014251781473,
      "step": 5100
    },
    {
      "loss": 0.0824,
      "grad_norm": 6.221954345703125,
      "learning_rate": 8.266363406621178e-06,
      "epoch": 1.2232779097387174,
      "step": 5150
    },
    {
      "loss": 0.132,
      "grad_norm": 10.321788787841797,
      "learning_rate": 8.140005054334093e-06,
      "epoch": 1.2351543942992875,
      "step": 5200
    },
    {
      "loss": 0.147,
      "grad_norm": 24.431066513061523,
      "learning_rate": 8.013646702047005e-06,
      "epoch": 1.2470308788598574,
      "step": 5250
    },
    {
      "loss": 0.1379,
      "grad_norm": 7.204749584197998,
      "learning_rate": 7.88728834975992e-06,
      "epoch": 1.2589073634204275,
      "step": 5300
    },
    {
      "loss": 0.0846,
      "grad_norm": 15.161677360534668,
      "learning_rate": 7.760929997472834e-06,
      "epoch": 1.2707838479809976,
      "step": 5350
    },
    {
      "loss": 0.1391,
      "grad_norm": 0.17448483407497406,
      "learning_rate": 7.634571645185748e-06,
      "epoch": 1.2826603325415677,
      "step": 5400
    },
    {
      "loss": 0.1229,
      "grad_norm": 13.853449821472168,
      "learning_rate": 7.508213292898662e-06,
      "epoch": 1.2945368171021379,
      "step": 5450
    },
    {
      "loss": 0.1082,
      "grad_norm": 2.9258875846862793,
      "learning_rate": 7.381854940611575e-06,
      "epoch": 1.3064133016627077,
      "step": 5500
    },
    {
      "loss": 0.1289,
      "grad_norm": 0.13326039910316467,
      "learning_rate": 7.255496588324489e-06,
      "epoch": 1.3182897862232779,
      "step": 5550
    },
    {
      "loss": 0.1299,
      "grad_norm": 21.266536712646484,
      "learning_rate": 7.129138236037403e-06,
      "epoch": 1.330166270783848,
      "step": 5600
    },
    {
      "loss": 0.1166,
      "grad_norm": 13.460254669189453,
      "learning_rate": 7.002779883750317e-06,
      "epoch": 1.342042755344418,
      "step": 5650
    },
    {
      "loss": 0.0823,
      "grad_norm": 0.12843109667301178,
      "learning_rate": 6.87642153146323e-06,
      "epoch": 1.3539192399049882,
      "step": 5700
    },
    {
      "loss": 0.1161,
      "grad_norm": 0.3397390842437744,
      "learning_rate": 6.750063179176144e-06,
      "epoch": 1.365795724465558,
      "step": 5750
    },
    {
      "loss": 0.1093,
      "grad_norm": 3.0521047115325928,
      "learning_rate": 6.623704826889058e-06,
      "epoch": 1.3776722090261282,
      "step": 5800
    },
    {
      "loss": 0.1021,
      "grad_norm": 37.51962661743164,
      "learning_rate": 6.497346474601972e-06,
      "epoch": 1.3895486935866983,
      "step": 5850
    },
    {
      "loss": 0.0984,
      "grad_norm": 0.04334869980812073,
      "learning_rate": 6.370988122314885e-06,
      "epoch": 1.4014251781472684,
      "step": 5900
    },
    {
      "loss": 0.1489,
      "grad_norm": 12.444436073303223,
      "learning_rate": 6.244629770027799e-06,
      "epoch": 1.4133016627078385,
      "step": 5950
    },
    {
      "loss": 0.1234,
      "grad_norm": 13.709550857543945,
      "learning_rate": 6.118271417740713e-06,
      "epoch": 1.4251781472684084,
      "step": 6000
    },
    {
      "loss": 0.1059,
      "grad_norm": 0.23975308239459991,
      "learning_rate": 5.991913065453627e-06,
      "epoch": 1.4370546318289787,
      "step": 6050
    },
    {
      "loss": 0.1321,
      "grad_norm": 2.079754590988159,
      "learning_rate": 5.86555471316654e-06,
      "epoch": 1.4489311163895486,
      "step": 6100
    },
    {
      "loss": 0.1124,
      "grad_norm": 0.20249272882938385,
      "learning_rate": 5.739196360879454e-06,
      "epoch": 1.4608076009501187,
      "step": 6150
    },
    {
      "loss": 0.1061,
      "grad_norm": 6.5175557136535645,
      "learning_rate": 5.612838008592369e-06,
      "epoch": 1.4726840855106889,
      "step": 6200
    },
    {
      "loss": 0.1267,
      "grad_norm": 0.25538793206214905,
      "learning_rate": 5.486479656305282e-06,
      "epoch": 1.484560570071259,
      "step": 6250
    },
    {
      "loss": 0.0914,
      "grad_norm": 3.879178047180176,
      "learning_rate": 5.360121304018197e-06,
      "epoch": 1.496437054631829,
      "step": 6300
    },
    {
      "loss": 0.1044,
      "grad_norm": 0.08288771659135818,
      "learning_rate": 5.2337629517311094e-06,
      "epoch": 1.508313539192399,
      "step": 6350
    },
    {
      "loss": 0.0989,
      "grad_norm": 1.4444535970687866,
      "learning_rate": 5.107404599444024e-06,
      "epoch": 1.520190023752969,
      "step": 6400
    },
    {
      "loss": 0.1256,
      "grad_norm": 0.10894826054573059,
      "learning_rate": 4.981046247156937e-06,
      "epoch": 1.5320665083135392,
      "step": 6450
    },
    {
      "loss": 0.1529,
      "grad_norm": 14.448546409606934,
      "learning_rate": 4.854687894869851e-06,
      "epoch": 1.5439429928741093,
      "step": 6500
    },
    {
      "loss": 0.0916,
      "grad_norm": 10.631087303161621,
      "learning_rate": 4.728329542582765e-06,
      "epoch": 1.5558194774346794,
      "step": 6550
    },
    {
      "loss": 0.0779,
      "grad_norm": 0.44350773096084595,
      "learning_rate": 4.601971190295679e-06,
      "epoch": 1.5676959619952493,
      "step": 6600
    },
    {
      "loss": 0.1399,
      "grad_norm": 4.124756813049316,
      "learning_rate": 4.4756128380085925e-06,
      "epoch": 1.5795724465558196,
      "step": 6650
    },
    {
      "loss": 0.0932,
      "grad_norm": 0.11967992782592773,
      "learning_rate": 4.349254485721506e-06,
      "epoch": 1.5914489311163895,
      "step": 6700
    },
    {
      "loss": 0.0955,
      "grad_norm": 0.12260890007019043,
      "learning_rate": 4.2228961334344204e-06,
      "epoch": 1.6033254156769596,
      "step": 6750
    },
    {
      "loss": 0.1363,
      "grad_norm": 4.34605598449707,
      "learning_rate": 4.096537781147334e-06,
      "epoch": 1.6152019002375297,
      "step": 6800
    },
    {
      "loss": 0.1119,
      "grad_norm": 4.096561908721924,
      "learning_rate": 3.970179428860248e-06,
      "epoch": 1.6270783847980996,
      "step": 6850
    },
    {
      "loss": 0.1281,
      "grad_norm": 19.820640563964844,
      "learning_rate": 3.843821076573162e-06,
      "epoch": 1.63895486935867,
      "step": 6900
    },
    {
      "loss": 0.1142,
      "grad_norm": 0.11230391263961792,
      "learning_rate": 3.7174627242860755e-06,
      "epoch": 1.6508313539192399,
      "step": 6950
    },
    {
      "loss": 0.1382,
      "grad_norm": 0.6436219811439514,
      "learning_rate": 3.5911043719989895e-06,
      "epoch": 1.66270783847981,
      "step": 7000
    },
    {
      "loss": 0.0863,
      "grad_norm": 0.11663038283586502,
      "learning_rate": 3.464746019711903e-06,
      "epoch": 1.67458432304038,
      "step": 7050
    },
    {
      "loss": 0.1136,
      "grad_norm": 1.225877285003662,
      "learning_rate": 3.3383876674248174e-06,
      "epoch": 1.68646080760095,
      "step": 7100
    },
    {
      "loss": 0.1344,
      "grad_norm": 0.2348826825618744,
      "learning_rate": 3.2120293151377306e-06,
      "epoch": 1.6983372921615203,
      "step": 7150
    },
    {
      "loss": 0.0899,
      "grad_norm": 0.29356932640075684,
      "learning_rate": 3.085670962850645e-06,
      "epoch": 1.7102137767220902,
      "step": 7200
    },
    {
      "loss": 0.1225,
      "grad_norm": 0.09289057552814484,
      "learning_rate": 2.9593126105635585e-06,
      "epoch": 1.7220902612826603,
      "step": 7250
    },
    {
      "loss": 0.1149,
      "grad_norm": 7.078027248382568,
      "learning_rate": 2.8329542582764725e-06,
      "epoch": 1.7339667458432304,
      "step": 7300
    },
    {
      "loss": 0.11,
      "grad_norm": 0.166573166847229,
      "learning_rate": 2.706595905989386e-06,
      "epoch": 1.7458432304038005,
      "step": 7350
    },
    {
      "loss": 0.0773,
      "grad_norm": 0.48377811908721924,
      "learning_rate": 2.5802375537023e-06,
      "epoch": 1.7577197149643706,
      "step": 7400
    },
    {
      "loss": 0.1213,
      "grad_norm": 5.508439540863037,
      "learning_rate": 2.4538792014152136e-06,
      "epoch": 1.7695961995249405,
      "step": 7450
    },
    {
      "loss": 0.138,
      "grad_norm": 13.133665084838867,
      "learning_rate": 2.3275208491281276e-06,
      "epoch": 1.7814726840855108,
      "step": 7500
    },
    {
      "loss": 0.172,
      "grad_norm": 7.3604044914245605,
      "learning_rate": 2.2011624968410416e-06,
      "epoch": 1.7933491686460807,
      "step": 7550
    },
    {
      "loss": 0.1072,
      "grad_norm": 6.717887878417969,
      "learning_rate": 2.074804144553955e-06,
      "epoch": 1.8052256532066508,
      "step": 7600
    },
    {
      "loss": 0.1038,
      "grad_norm": 0.38450726866722107,
      "learning_rate": 1.948445792266869e-06,
      "epoch": 1.817102137767221,
      "step": 7650
    },
    {
      "loss": 0.1406,
      "grad_norm": 12.508379936218262,
      "learning_rate": 1.8220874399797829e-06,
      "epoch": 1.8289786223277908,
      "step": 7700
    },
    {
      "loss": 0.1115,
      "grad_norm": 0.077034130692482,
      "learning_rate": 1.6957290876926966e-06,
      "epoch": 1.8408551068883612,
      "step": 7750
    },
    {
      "loss": 0.1164,
      "grad_norm": 0.11262772232294083,
      "learning_rate": 1.5693707354056104e-06,
      "epoch": 1.852731591448931,
      "step": 7800
    },
    {
      "loss": 0.1064,
      "grad_norm": 0.19064712524414062,
      "learning_rate": 1.4430123831185242e-06,
      "epoch": 1.8646080760095012,
      "step": 7850
    },
    {
      "loss": 0.1145,
      "grad_norm": 0.9596913456916809,
      "learning_rate": 1.316654030831438e-06,
      "epoch": 1.8764845605700713,
      "step": 7900
    },
    {
      "loss": 0.1351,
      "grad_norm": 0.3361983299255371,
      "learning_rate": 1.190295678544352e-06,
      "epoch": 1.8883610451306412,
      "step": 7950
    },
    {
      "loss": 0.1191,
      "grad_norm": 29.873502731323242,
      "learning_rate": 1.0639373262572657e-06,
      "epoch": 1.9002375296912115,
      "step": 8000
    },
    {
      "loss": 0.1357,
      "grad_norm": 0.23205778002738953,
      "learning_rate": 9.375789739701795e-07,
      "epoch": 1.9121140142517814,
      "step": 8050
    },
    {
      "loss": 0.1084,
      "grad_norm": 0.539139986038208,
      "learning_rate": 8.112206216830932e-07,
      "epoch": 1.9239904988123515,
      "step": 8100
    },
    {
      "loss": 0.0865,
      "grad_norm": 0.07007285207509995,
      "learning_rate": 6.848622693960072e-07,
      "epoch": 1.9358669833729216,
      "step": 8150
    },
    {
      "loss": 0.1125,
      "grad_norm": 4.645601272583008,
      "learning_rate": 5.58503917108921e-07,
      "epoch": 1.9477434679334917,
      "step": 8200
    },
    {
      "loss": 0.1125,
      "grad_norm": 0.3153958320617676,
      "learning_rate": 4.321455648218348e-07,
      "epoch": 1.9596199524940618,
      "step": 8250
    },
    {
      "loss": 0.0995,
      "grad_norm": 0.459071546792984,
      "learning_rate": 3.0578721253474856e-07,
      "epoch": 1.9714964370546317,
      "step": 8300
    },
    {
      "loss": 0.1126,
      "grad_norm": 13.568475723266602,
      "learning_rate": 1.7942886024766238e-07,
      "epoch": 1.9833729216152018,
      "step": 8350
    },
    {
      "loss": 0.0966,
      "grad_norm": 22.046606063842773,
      "learning_rate": 5.30705079605762e-08,
      "epoch": 1.995249406175772,
      "step": 8400
    },
    {
      "eval_loss": 0.2875106930732727,
      "eval_accuracy": 0.9254587155963303,
      "eval_runtime": 1.3308,
      "eval_samples_per_second": 655.222,
      "eval_steps_per_second": 10.52,
      "epoch": 2.0,
      "step": 8420
    },
    {
      "train_runtime": 696.459,
      "train_samples_per_second": 193.404,
      "train_steps_per_second": 12.09,
      "total_flos": 8860133233720320.0,
      "train_loss": 0.17709716133720235,
      "epoch": 2.0,
      "step": 8420
    },
    {
      "eval_loss": 0.2875106930732727,
      "eval_accuracy": 0.9254587155963303,
      "eval_runtime": 1.3316,
      "eval_samples_per_second": 654.843,
      "eval_steps_per_second": 10.514,
      "epoch": 2.0,
      "step": 8420
    }
  ]
}