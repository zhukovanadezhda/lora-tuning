{
  "mode": "full_ft",
  "model": "bert-base-uncased",
  "metrics": {
    "eval_loss": 0.29294347763061523,
    "eval_accuracy": 0.926605504587156,
    "eval_runtime": 1.3266,
    "eval_samples_per_second": 657.333,
    "eval_steps_per_second": 10.554,
    "epoch": 2.0
  },
  "params": {
    "total_parameters": 109483778,
    "trainable_parameters": 109483778,
    "trainable_percentage": 100.0
  },
  "elapsed_sec": 700.5674433708191,
  "config": {
    "mode": "full_ft",
    "model_name": "bert-base-uncased",
    "max_length": 128,
    "epochs": 2.0,
    "lr": 2e-05,
    "train_batch_size": 16,
    "eval_batch_size": 64,
    "warmup_ratio": 0.06,
    "r": 4,
    "alpha": 16.0,
    "lora_dropout": 0.0,
    "output_dir": "outputs/runs",
    "results_path": "/content/drive/MyDrive/lora-tuning/results/full_ft.json"
  },
  "log_history": [
    {
      "loss": 0.6955,
      "grad_norm": 4.957690238952637,
      "learning_rate": 1.9367588932806323e-06,
      "epoch": 0.011876484560570071,
      "step": 50
    },
    {
      "loss": 0.6733,
      "grad_norm": 3.9301414489746094,
      "learning_rate": 3.91304347826087e-06,
      "epoch": 0.023752969121140142,
      "step": 100
    },
    {
      "loss": 0.5998,
      "grad_norm": 5.376052379608154,
      "learning_rate": 5.8893280632411074e-06,
      "epoch": 0.035629453681710214,
      "step": 150
    },
    {
      "loss": 0.4327,
      "grad_norm": 6.56658411026001,
      "learning_rate": 7.865612648221344e-06,
      "epoch": 0.047505938242280284,
      "step": 200
    },
    {
      "loss": 0.3144,
      "grad_norm": 4.696389675140381,
      "learning_rate": 9.841897233201582e-06,
      "epoch": 0.05938242280285035,
      "step": 250
    },
    {
      "loss": 0.3451,
      "grad_norm": 18.98360824584961,
      "learning_rate": 1.181818181818182e-05,
      "epoch": 0.07125890736342043,
      "step": 300
    },
    {
      "loss": 0.3424,
      "grad_norm": 13.188543319702148,
      "learning_rate": 1.3794466403162057e-05,
      "epoch": 0.0831353919239905,
      "step": 350
    },
    {
      "loss": 0.3216,
      "grad_norm": 16.151273727416992,
      "learning_rate": 1.5770750988142295e-05,
      "epoch": 0.09501187648456057,
      "step": 400
    },
    {
      "loss": 0.3053,
      "grad_norm": 6.4549880027771,
      "learning_rate": 1.774703557312253e-05,
      "epoch": 0.10688836104513064,
      "step": 450
    },
    {
      "loss": 0.2942,
      "grad_norm": 10.254722595214844,
      "learning_rate": 1.9723320158102768e-05,
      "epoch": 0.1187648456057007,
      "step": 500
    },
    {
      "loss": 0.2856,
      "grad_norm": 3.2510461807250977,
      "learning_rate": 1.989133181703311e-05,
      "epoch": 0.13064133016627077,
      "step": 550
    },
    {
      "loss": 0.3285,
      "grad_norm": 8.288381576538086,
      "learning_rate": 1.9764973464746023e-05,
      "epoch": 0.14251781472684086,
      "step": 600
    },
    {
      "loss": 0.2573,
      "grad_norm": 8.099385261535645,
      "learning_rate": 1.9638615112458934e-05,
      "epoch": 0.1543942992874109,
      "step": 650
    },
    {
      "loss": 0.2706,
      "grad_norm": 10.664322853088379,
      "learning_rate": 1.951225676017185e-05,
      "epoch": 0.166270783847981,
      "step": 700
    },
    {
      "loss": 0.2705,
      "grad_norm": 8.290822982788086,
      "learning_rate": 1.9385898407884763e-05,
      "epoch": 0.17814726840855108,
      "step": 750
    },
    {
      "loss": 0.2587,
      "grad_norm": 8.714747428894043,
      "learning_rate": 1.9259540055597678e-05,
      "epoch": 0.19002375296912113,
      "step": 800
    },
    {
      "loss": 0.2818,
      "grad_norm": 11.38587760925293,
      "learning_rate": 1.9133181703310592e-05,
      "epoch": 0.20190023752969122,
      "step": 850
    },
    {
      "loss": 0.2752,
      "grad_norm": 13.219659805297852,
      "learning_rate": 1.9006823351023503e-05,
      "epoch": 0.21377672209026127,
      "step": 900
    },
    {
      "loss": 0.2687,
      "grad_norm": 8.076949119567871,
      "learning_rate": 1.8880464998736417e-05,
      "epoch": 0.22565320665083136,
      "step": 950
    },
    {
      "loss": 0.2446,
      "grad_norm": 23.227375030517578,
      "learning_rate": 1.8754106646449332e-05,
      "epoch": 0.2375296912114014,
      "step": 1000
    },
    {
      "loss": 0.2639,
      "grad_norm": 9.78592586517334,
      "learning_rate": 1.8627748294162246e-05,
      "epoch": 0.2494061757719715,
      "step": 1050
    },
    {
      "loss": 0.2553,
      "grad_norm": 8.101361274719238,
      "learning_rate": 1.8501389941875157e-05,
      "epoch": 0.26128266033254155,
      "step": 1100
    },
    {
      "loss": 0.2271,
      "grad_norm": 2.8721933364868164,
      "learning_rate": 1.837503158958807e-05,
      "epoch": 0.27315914489311166,
      "step": 1150
    },
    {
      "loss": 0.218,
      "grad_norm": 7.052878379821777,
      "learning_rate": 1.8248673237300986e-05,
      "epoch": 0.2850356294536817,
      "step": 1200
    },
    {
      "loss": 0.2424,
      "grad_norm": 6.038200855255127,
      "learning_rate": 1.81223148850139e-05,
      "epoch": 0.29691211401425177,
      "step": 1250
    },
    {
      "loss": 0.229,
      "grad_norm": 9.37873649597168,
      "learning_rate": 1.7995956532726815e-05,
      "epoch": 0.3087885985748218,
      "step": 1300
    },
    {
      "loss": 0.2088,
      "grad_norm": 7.4117431640625,
      "learning_rate": 1.786959818043973e-05,
      "epoch": 0.32066508313539194,
      "step": 1350
    },
    {
      "loss": 0.2166,
      "grad_norm": 23.808887481689453,
      "learning_rate": 1.7743239828152644e-05,
      "epoch": 0.332541567695962,
      "step": 1400
    },
    {
      "loss": 0.2122,
      "grad_norm": 11.088618278503418,
      "learning_rate": 1.7616881475865558e-05,
      "epoch": 0.34441805225653205,
      "step": 1450
    },
    {
      "loss": 0.2435,
      "grad_norm": 5.621354103088379,
      "learning_rate": 1.749052312357847e-05,
      "epoch": 0.35629453681710216,
      "step": 1500
    },
    {
      "loss": 0.2757,
      "grad_norm": 10.2533597946167,
      "learning_rate": 1.7364164771291383e-05,
      "epoch": 0.3681710213776722,
      "step": 1550
    },
    {
      "loss": 0.1932,
      "grad_norm": 3.392035484313965,
      "learning_rate": 1.7237806419004298e-05,
      "epoch": 0.38004750593824227,
      "step": 1600
    },
    {
      "loss": 0.2739,
      "grad_norm": 7.951204776763916,
      "learning_rate": 1.7111448066717212e-05,
      "epoch": 0.3919239904988123,
      "step": 1650
    },
    {
      "loss": 0.201,
      "grad_norm": 14.099649429321289,
      "learning_rate": 1.6985089714430127e-05,
      "epoch": 0.40380047505938244,
      "step": 1700
    },
    {
      "loss": 0.2108,
      "grad_norm": 2.0202066898345947,
      "learning_rate": 1.6858731362143038e-05,
      "epoch": 0.4156769596199525,
      "step": 1750
    },
    {
      "loss": 0.2021,
      "grad_norm": 17.150245666503906,
      "learning_rate": 1.6732373009855952e-05,
      "epoch": 0.42755344418052255,
      "step": 1800
    },
    {
      "loss": 0.2566,
      "grad_norm": 13.13301944732666,
      "learning_rate": 1.6606014657568867e-05,
      "epoch": 0.43942992874109266,
      "step": 1850
    },
    {
      "loss": 0.1632,
      "grad_norm": 1.5953153371810913,
      "learning_rate": 1.647965630528178e-05,
      "epoch": 0.4513064133016627,
      "step": 1900
    },
    {
      "loss": 0.214,
      "grad_norm": 7.19954252243042,
      "learning_rate": 1.6353297952994692e-05,
      "epoch": 0.46318289786223277,
      "step": 1950
    },
    {
      "loss": 0.1794,
      "grad_norm": 8.902341842651367,
      "learning_rate": 1.6226939600707606e-05,
      "epoch": 0.4750593824228028,
      "step": 2000
    },
    {
      "loss": 0.277,
      "grad_norm": 1.4643951654434204,
      "learning_rate": 1.610058124842052e-05,
      "epoch": 0.48693586698337293,
      "step": 2050
    },
    {
      "loss": 0.2046,
      "grad_norm": 19.7716007232666,
      "learning_rate": 1.5974222896133435e-05,
      "epoch": 0.498812351543943,
      "step": 2100
    },
    {
      "loss": 0.1747,
      "grad_norm": 5.638509273529053,
      "learning_rate": 1.584786454384635e-05,
      "epoch": 0.5106888361045131,
      "step": 2150
    },
    {
      "loss": 0.187,
      "grad_norm": 17.51172637939453,
      "learning_rate": 1.5721506191559264e-05,
      "epoch": 0.5225653206650831,
      "step": 2200
    },
    {
      "loss": 0.2036,
      "grad_norm": 14.68209171295166,
      "learning_rate": 1.559514783927218e-05,
      "epoch": 0.5344418052256532,
      "step": 2250
    },
    {
      "loss": 0.1941,
      "grad_norm": 0.7558276653289795,
      "learning_rate": 1.5468789486985093e-05,
      "epoch": 0.5463182897862233,
      "step": 2300
    },
    {
      "loss": 0.2211,
      "grad_norm": 9.196080207824707,
      "learning_rate": 1.5342431134698004e-05,
      "epoch": 0.5581947743467933,
      "step": 2350
    },
    {
      "loss": 0.1662,
      "grad_norm": 5.978549003601074,
      "learning_rate": 1.5216072782410918e-05,
      "epoch": 0.5700712589073634,
      "step": 2400
    },
    {
      "loss": 0.2008,
      "grad_norm": 5.204103469848633,
      "learning_rate": 1.5089714430123833e-05,
      "epoch": 0.5819477434679335,
      "step": 2450
    },
    {
      "loss": 0.2093,
      "grad_norm": 0.41007938981056213,
      "learning_rate": 1.4963356077836745e-05,
      "epoch": 0.5938242280285035,
      "step": 2500
    },
    {
      "loss": 0.192,
      "grad_norm": 9.00928020477295,
      "learning_rate": 1.483699772554966e-05,
      "epoch": 0.6057007125890737,
      "step": 2550
    },
    {
      "loss": 0.1987,
      "grad_norm": 6.465901851654053,
      "learning_rate": 1.4710639373262574e-05,
      "epoch": 0.6175771971496437,
      "step": 2600
    },
    {
      "loss": 0.238,
      "grad_norm": 0.38262131810188293,
      "learning_rate": 1.4584281020975488e-05,
      "epoch": 0.6294536817102138,
      "step": 2650
    },
    {
      "loss": 0.2155,
      "grad_norm": 4.067157745361328,
      "learning_rate": 1.4457922668688403e-05,
      "epoch": 0.6413301662707839,
      "step": 2700
    },
    {
      "loss": 0.1903,
      "grad_norm": 5.735799312591553,
      "learning_rate": 1.4331564316401316e-05,
      "epoch": 0.6532066508313539,
      "step": 2750
    },
    {
      "loss": 0.1667,
      "grad_norm": 6.657283782958984,
      "learning_rate": 1.4205205964114228e-05,
      "epoch": 0.665083135391924,
      "step": 2800
    },
    {
      "loss": 0.2141,
      "grad_norm": 6.1812310218811035,
      "learning_rate": 1.4078847611827143e-05,
      "epoch": 0.6769596199524941,
      "step": 2850
    },
    {
      "loss": 0.1702,
      "grad_norm": 7.141865253448486,
      "learning_rate": 1.3952489259540057e-05,
      "epoch": 0.6888361045130641,
      "step": 2900
    },
    {
      "loss": 0.2348,
      "grad_norm": 17.4912166595459,
      "learning_rate": 1.382613090725297e-05,
      "epoch": 0.7007125890736342,
      "step": 2950
    },
    {
      "loss": 0.2136,
      "grad_norm": 10.14511775970459,
      "learning_rate": 1.3699772554965884e-05,
      "epoch": 0.7125890736342043,
      "step": 3000
    },
    {
      "loss": 0.1926,
      "grad_norm": 0.5221239328384399,
      "learning_rate": 1.3573414202678799e-05,
      "epoch": 0.7244655581947743,
      "step": 3050
    },
    {
      "loss": 0.168,
      "grad_norm": 13.321737289428711,
      "learning_rate": 1.3447055850391713e-05,
      "epoch": 0.7363420427553444,
      "step": 3100
    },
    {
      "loss": 0.2172,
      "grad_norm": 0.6608689427375793,
      "learning_rate": 1.3320697498104627e-05,
      "epoch": 0.7482185273159145,
      "step": 3150
    },
    {
      "loss": 0.2163,
      "grad_norm": 7.6142377853393555,
      "learning_rate": 1.319433914581754e-05,
      "epoch": 0.7600950118764845,
      "step": 3200
    },
    {
      "loss": 0.1796,
      "grad_norm": 19.058685302734375,
      "learning_rate": 1.3067980793530453e-05,
      "epoch": 0.7719714964370546,
      "step": 3250
    },
    {
      "loss": 0.1617,
      "grad_norm": 8.078691482543945,
      "learning_rate": 1.2941622441243367e-05,
      "epoch": 0.7838479809976246,
      "step": 3300
    },
    {
      "loss": 0.1805,
      "grad_norm": 6.792150974273682,
      "learning_rate": 1.281526408895628e-05,
      "epoch": 0.7957244655581948,
      "step": 3350
    },
    {
      "loss": 0.2098,
      "grad_norm": 12.240797996520996,
      "learning_rate": 1.2688905736669194e-05,
      "epoch": 0.8076009501187649,
      "step": 3400
    },
    {
      "loss": 0.2115,
      "grad_norm": 3.483067750930786,
      "learning_rate": 1.2562547384382109e-05,
      "epoch": 0.8194774346793349,
      "step": 3450
    },
    {
      "loss": 0.1643,
      "grad_norm": 5.921074390411377,
      "learning_rate": 1.2436189032095023e-05,
      "epoch": 0.831353919239905,
      "step": 3500
    },
    {
      "loss": 0.2057,
      "grad_norm": 15.160085678100586,
      "learning_rate": 1.2309830679807938e-05,
      "epoch": 0.8432304038004751,
      "step": 3550
    },
    {
      "loss": 0.172,
      "grad_norm": 0.7639020681381226,
      "learning_rate": 1.218347232752085e-05,
      "epoch": 0.8551068883610451,
      "step": 3600
    },
    {
      "loss": 0.1647,
      "grad_norm": 0.2090926319360733,
      "learning_rate": 1.2057113975233763e-05,
      "epoch": 0.8669833729216152,
      "step": 3650
    },
    {
      "loss": 0.194,
      "grad_norm": 3.1177632808685303,
      "learning_rate": 1.1930755622946677e-05,
      "epoch": 0.8788598574821853,
      "step": 3700
    },
    {
      "loss": 0.1965,
      "grad_norm": 10.73568344116211,
      "learning_rate": 1.1804397270659592e-05,
      "epoch": 0.8907363420427553,
      "step": 3750
    },
    {
      "loss": 0.175,
      "grad_norm": 11.732888221740723,
      "learning_rate": 1.1678038918372505e-05,
      "epoch": 0.9026128266033254,
      "step": 3800
    },
    {
      "loss": 0.1877,
      "grad_norm": 8.521851539611816,
      "learning_rate": 1.1551680566085419e-05,
      "epoch": 0.9144893111638955,
      "step": 3850
    },
    {
      "loss": 0.1477,
      "grad_norm": 0.22981177270412445,
      "learning_rate": 1.1425322213798333e-05,
      "epoch": 0.9263657957244655,
      "step": 3900
    },
    {
      "loss": 0.1924,
      "grad_norm": 7.389146327972412,
      "learning_rate": 1.1298963861511248e-05,
      "epoch": 0.9382422802850356,
      "step": 3950
    },
    {
      "loss": 0.1709,
      "grad_norm": 12.239343643188477,
      "learning_rate": 1.1172605509224162e-05,
      "epoch": 0.9501187648456056,
      "step": 4000
    },
    {
      "loss": 0.1689,
      "grad_norm": 0.47173380851745605,
      "learning_rate": 1.1046247156937075e-05,
      "epoch": 0.9619952494061758,
      "step": 4050
    },
    {
      "loss": 0.1936,
      "grad_norm": 9.264908790588379,
      "learning_rate": 1.0919888804649988e-05,
      "epoch": 0.9738717339667459,
      "step": 4100
    },
    {
      "loss": 0.1594,
      "grad_norm": 20.250904083251953,
      "learning_rate": 1.0793530452362902e-05,
      "epoch": 0.9857482185273159,
      "step": 4150
    },
    {
      "loss": 0.165,
      "grad_norm": 6.1396002769470215,
      "learning_rate": 1.0667172100075815e-05,
      "epoch": 0.997624703087886,
      "step": 4200
    },
    {
      "eval_loss": 0.26064902544021606,
      "eval_accuracy": 0.9208715596330275,
      "eval_runtime": 1.333,
      "eval_samples_per_second": 654.176,
      "eval_steps_per_second": 10.503,
      "epoch": 1.0,
      "step": 4210
    },
    {
      "loss": 0.106,
      "grad_norm": 1.0159844160079956,
      "learning_rate": 1.0540813747788729e-05,
      "epoch": 1.009501187648456,
      "step": 4250
    },
    {
      "loss": 0.1367,
      "grad_norm": 11.505894660949707,
      "learning_rate": 1.0414455395501643e-05,
      "epoch": 1.0213776722090262,
      "step": 4300
    },
    {
      "loss": 0.0929,
      "grad_norm": 11.40530014038086,
      "learning_rate": 1.0288097043214558e-05,
      "epoch": 1.0332541567695963,
      "step": 4350
    },
    {
      "loss": 0.1454,
      "grad_norm": 2.1610543727874756,
      "learning_rate": 1.0161738690927472e-05,
      "epoch": 1.0451306413301662,
      "step": 4400
    },
    {
      "loss": 0.1593,
      "grad_norm": 11.140106201171875,
      "learning_rate": 1.0035380338640387e-05,
      "epoch": 1.0570071258907363,
      "step": 4450
    },
    {
      "loss": 0.0939,
      "grad_norm": 0.858381450176239,
      "learning_rate": 9.9090219863533e-06,
      "epoch": 1.0688836104513064,
      "step": 4500
    },
    {
      "loss": 0.164,
      "grad_norm": 6.752503871917725,
      "learning_rate": 9.782663634066212e-06,
      "epoch": 1.0807600950118765,
      "step": 4550
    },
    {
      "loss": 0.0979,
      "grad_norm": 39.89297103881836,
      "learning_rate": 9.656305281779127e-06,
      "epoch": 1.0926365795724466,
      "step": 4600
    },
    {
      "loss": 0.1052,
      "grad_norm": 21.6251277923584,
      "learning_rate": 9.52994692949204e-06,
      "epoch": 1.1045130641330165,
      "step": 4650
    },
    {
      "loss": 0.0854,
      "grad_norm": 0.13642366230487823,
      "learning_rate": 9.403588577204954e-06,
      "epoch": 1.1163895486935866,
      "step": 4700
    },
    {
      "loss": 0.1587,
      "grad_norm": 0.2639748752117157,
      "learning_rate": 9.277230224917868e-06,
      "epoch": 1.1282660332541568,
      "step": 4750
    },
    {
      "loss": 0.1226,
      "grad_norm": 0.4244026839733124,
      "learning_rate": 9.150871872630782e-06,
      "epoch": 1.1401425178147269,
      "step": 4800
    },
    {
      "loss": 0.1213,
      "grad_norm": 13.883678436279297,
      "learning_rate": 9.024513520343695e-06,
      "epoch": 1.152019002375297,
      "step": 4850
    },
    {
      "loss": 0.1263,
      "grad_norm": 0.18271516263484955,
      "learning_rate": 8.89815516805661e-06,
      "epoch": 1.1638954869358669,
      "step": 4900
    },
    {
      "loss": 0.1311,
      "grad_norm": 1.7360739707946777,
      "learning_rate": 8.771796815769524e-06,
      "epoch": 1.175771971496437,
      "step": 4950
    },
    {
      "loss": 0.1313,
      "grad_norm": 0.7920498251914978,
      "learning_rate": 8.645438463482437e-06,
      "epoch": 1.187648456057007,
      "step": 5000
    },
    {
      "loss": 0.1191,
      "grad_norm": 9.39661693572998,
      "learning_rate": 8.519080111195351e-06,
      "epoch": 1.1995249406175772,
      "step": 5050
    },
    {
      "loss": 0.1315,
      "grad_norm": 14.035469055175781,
      "learning_rate": 8.392721758908264e-06,
      "epoch": 1.2114014251781473,
      "step": 5100
    },
    {
      "loss": 0.077,
      "grad_norm": 7.361313819885254,
      "learning_rate": 8.266363406621178e-06,
      "epoch": 1.2232779097387174,
      "step": 5150
    },
    {
      "loss": 0.1379,
      "grad_norm": 1.0760815143585205,
      "learning_rate": 8.140005054334093e-06,
      "epoch": 1.2351543942992875,
      "step": 5200
    },
    {
      "loss": 0.1533,
      "grad_norm": 15.270703315734863,
      "learning_rate": 8.013646702047005e-06,
      "epoch": 1.2470308788598574,
      "step": 5250
    },
    {
      "loss": 0.1419,
      "grad_norm": 5.1606221199035645,
      "learning_rate": 7.88728834975992e-06,
      "epoch": 1.2589073634204275,
      "step": 5300
    },
    {
      "loss": 0.0823,
      "grad_norm": 6.045003890991211,
      "learning_rate": 7.760929997472834e-06,
      "epoch": 1.2707838479809976,
      "step": 5350
    },
    {
      "loss": 0.1365,
      "grad_norm": 7.138091564178467,
      "learning_rate": 7.634571645185748e-06,
      "epoch": 1.2826603325415677,
      "step": 5400
    },
    {
      "loss": 0.1138,
      "grad_norm": 31.95591163635254,
      "learning_rate": 7.508213292898662e-06,
      "epoch": 1.2945368171021379,
      "step": 5450
    },
    {
      "loss": 0.1082,
      "grad_norm": 18.54939079284668,
      "learning_rate": 7.381854940611575e-06,
      "epoch": 1.3064133016627077,
      "step": 5500
    },
    {
      "loss": 0.137,
      "grad_norm": 0.1669231355190277,
      "learning_rate": 7.255496588324489e-06,
      "epoch": 1.3182897862232779,
      "step": 5550
    },
    {
      "loss": 0.134,
      "grad_norm": 6.367788791656494,
      "learning_rate": 7.129138236037403e-06,
      "epoch": 1.330166270783848,
      "step": 5600
    },
    {
      "loss": 0.125,
      "grad_norm": 24.932167053222656,
      "learning_rate": 7.002779883750317e-06,
      "epoch": 1.342042755344418,
      "step": 5650
    },
    {
      "loss": 0.0963,
      "grad_norm": 0.09195510298013687,
      "learning_rate": 6.87642153146323e-06,
      "epoch": 1.3539192399049882,
      "step": 5700
    },
    {
      "loss": 0.1217,
      "grad_norm": 0.4616106450557709,
      "learning_rate": 6.750063179176144e-06,
      "epoch": 1.365795724465558,
      "step": 5750
    },
    {
      "loss": 0.1009,
      "grad_norm": 17.88992691040039,
      "learning_rate": 6.623704826889058e-06,
      "epoch": 1.3776722090261282,
      "step": 5800
    },
    {
      "loss": 0.1244,
      "grad_norm": 13.250903129577637,
      "learning_rate": 6.497346474601972e-06,
      "epoch": 1.3895486935866983,
      "step": 5850
    },
    {
      "loss": 0.1016,
      "grad_norm": 0.07968702912330627,
      "learning_rate": 6.370988122314885e-06,
      "epoch": 1.4014251781472684,
      "step": 5900
    },
    {
      "loss": 0.1658,
      "grad_norm": 7.225920677185059,
      "learning_rate": 6.244629770027799e-06,
      "epoch": 1.4133016627078385,
      "step": 5950
    },
    {
      "loss": 0.1175,
      "grad_norm": 13.408604621887207,
      "learning_rate": 6.118271417740713e-06,
      "epoch": 1.4251781472684084,
      "step": 6000
    },
    {
      "loss": 0.1016,
      "grad_norm": 0.31937676668167114,
      "learning_rate": 5.991913065453627e-06,
      "epoch": 1.4370546318289787,
      "step": 6050
    },
    {
      "loss": 0.1117,
      "grad_norm": 0.8283082246780396,
      "learning_rate": 5.86555471316654e-06,
      "epoch": 1.4489311163895486,
      "step": 6100
    },
    {
      "loss": 0.1225,
      "grad_norm": 0.08101247996091843,
      "learning_rate": 5.739196360879454e-06,
      "epoch": 1.4608076009501187,
      "step": 6150
    },
    {
      "loss": 0.1078,
      "grad_norm": 1.4547359943389893,
      "learning_rate": 5.612838008592369e-06,
      "epoch": 1.4726840855106889,
      "step": 6200
    },
    {
      "loss": 0.1225,
      "grad_norm": 0.14868393540382385,
      "learning_rate": 5.486479656305282e-06,
      "epoch": 1.484560570071259,
      "step": 6250
    },
    {
      "loss": 0.0996,
      "grad_norm": 5.06568717956543,
      "learning_rate": 5.360121304018197e-06,
      "epoch": 1.496437054631829,
      "step": 6300
    },
    {
      "loss": 0.0982,
      "grad_norm": 0.07356557995080948,
      "learning_rate": 5.2337629517311094e-06,
      "epoch": 1.508313539192399,
      "step": 6350
    },
    {
      "loss": 0.1225,
      "grad_norm": 25.596420288085938,
      "learning_rate": 5.107404599444024e-06,
      "epoch": 1.520190023752969,
      "step": 6400
    },
    {
      "loss": 0.123,
      "grad_norm": 0.18998610973358154,
      "learning_rate": 4.981046247156937e-06,
      "epoch": 1.5320665083135392,
      "step": 6450
    },
    {
      "loss": 0.1718,
      "grad_norm": 16.926931381225586,
      "learning_rate": 4.854687894869851e-06,
      "epoch": 1.5439429928741093,
      "step": 6500
    },
    {
      "loss": 0.0882,
      "grad_norm": 5.400714874267578,
      "learning_rate": 4.728329542582765e-06,
      "epoch": 1.5558194774346794,
      "step": 6550
    },
    {
      "loss": 0.0702,
      "grad_norm": 0.21869584918022156,
      "learning_rate": 4.601971190295679e-06,
      "epoch": 1.5676959619952493,
      "step": 6600
    },
    {
      "loss": 0.1472,
      "grad_norm": 5.907003402709961,
      "learning_rate": 4.4756128380085925e-06,
      "epoch": 1.5795724465558196,
      "step": 6650
    },
    {
      "loss": 0.1044,
      "grad_norm": 0.8170398473739624,
      "learning_rate": 4.349254485721506e-06,
      "epoch": 1.5914489311163895,
      "step": 6700
    },
    {
      "loss": 0.0991,
      "grad_norm": 7.319243431091309,
      "learning_rate": 4.2228961334344204e-06,
      "epoch": 1.6033254156769596,
      "step": 6750
    },
    {
      "loss": 0.1578,
      "grad_norm": 0.9689083695411682,
      "learning_rate": 4.096537781147334e-06,
      "epoch": 1.6152019002375297,
      "step": 6800
    },
    {
      "loss": 0.1068,
      "grad_norm": 5.601759433746338,
      "learning_rate": 3.970179428860248e-06,
      "epoch": 1.6270783847980996,
      "step": 6850
    },
    {
      "loss": 0.1299,
      "grad_norm": 10.227338790893555,
      "learning_rate": 3.843821076573162e-06,
      "epoch": 1.63895486935867,
      "step": 6900
    },
    {
      "loss": 0.0851,
      "grad_norm": 0.10742508620023727,
      "learning_rate": 3.7174627242860755e-06,
      "epoch": 1.6508313539192399,
      "step": 6950
    },
    {
      "loss": 0.1467,
      "grad_norm": 0.8325359225273132,
      "learning_rate": 3.5911043719989895e-06,
      "epoch": 1.66270783847981,
      "step": 7000
    },
    {
      "loss": 0.0955,
      "grad_norm": 0.13141532242298126,
      "learning_rate": 3.464746019711903e-06,
      "epoch": 1.67458432304038,
      "step": 7050
    },
    {
      "loss": 0.1171,
      "grad_norm": 2.931257724761963,
      "learning_rate": 3.3383876674248174e-06,
      "epoch": 1.68646080760095,
      "step": 7100
    },
    {
      "loss": 0.1467,
      "grad_norm": 0.22332647442817688,
      "learning_rate": 3.2120293151377306e-06,
      "epoch": 1.6983372921615203,
      "step": 7150
    },
    {
      "loss": 0.1102,
      "grad_norm": 0.7767086625099182,
      "learning_rate": 3.085670962850645e-06,
      "epoch": 1.7102137767220902,
      "step": 7200
    },
    {
      "loss": 0.144,
      "grad_norm": 0.13921618461608887,
      "learning_rate": 2.9593126105635585e-06,
      "epoch": 1.7220902612826603,
      "step": 7250
    },
    {
      "loss": 0.1069,
      "grad_norm": 6.309662818908691,
      "learning_rate": 2.8329542582764725e-06,
      "epoch": 1.7339667458432304,
      "step": 7300
    },
    {
      "loss": 0.0909,
      "grad_norm": 0.13636164367198944,
      "learning_rate": 2.706595905989386e-06,
      "epoch": 1.7458432304038005,
      "step": 7350
    },
    {
      "loss": 0.0841,
      "grad_norm": 0.8238579034805298,
      "learning_rate": 2.5802375537023e-06,
      "epoch": 1.7577197149643706,
      "step": 7400
    },
    {
      "loss": 0.1135,
      "grad_norm": 5.410628318786621,
      "learning_rate": 2.4538792014152136e-06,
      "epoch": 1.7695961995249405,
      "step": 7450
    },
    {
      "loss": 0.1387,
      "grad_norm": 13.377851486206055,
      "learning_rate": 2.3275208491281276e-06,
      "epoch": 1.7814726840855108,
      "step": 7500
    },
    {
      "loss": 0.1551,
      "grad_norm": 7.063056945800781,
      "learning_rate": 2.2011624968410416e-06,
      "epoch": 1.7933491686460807,
      "step": 7550
    },
    {
      "loss": 0.1049,
      "grad_norm": 7.721280097961426,
      "learning_rate": 2.074804144553955e-06,
      "epoch": 1.8052256532066508,
      "step": 7600
    },
    {
      "loss": 0.1137,
      "grad_norm": 0.6089680790901184,
      "learning_rate": 1.948445792266869e-06,
      "epoch": 1.817102137767221,
      "step": 7650
    },
    {
      "loss": 0.1234,
      "grad_norm": 9.127057075500488,
      "learning_rate": 1.8220874399797829e-06,
      "epoch": 1.8289786223277908,
      "step": 7700
    },
    {
      "loss": 0.0956,
      "grad_norm": 0.06159232556819916,
      "learning_rate": 1.6957290876926966e-06,
      "epoch": 1.8408551068883612,
      "step": 7750
    },
    {
      "loss": 0.1212,
      "grad_norm": 0.10272519290447235,
      "learning_rate": 1.5693707354056104e-06,
      "epoch": 1.852731591448931,
      "step": 7800
    },
    {
      "loss": 0.1072,
      "grad_norm": 0.4795805811882019,
      "learning_rate": 1.4430123831185242e-06,
      "epoch": 1.8646080760095012,
      "step": 7850
    },
    {
      "loss": 0.118,
      "grad_norm": 6.30371618270874,
      "learning_rate": 1.316654030831438e-06,
      "epoch": 1.8764845605700713,
      "step": 7900
    },
    {
      "loss": 0.1554,
      "grad_norm": 39.62860870361328,
      "learning_rate": 1.190295678544352e-06,
      "epoch": 1.8883610451306412,
      "step": 7950
    },
    {
      "loss": 0.1122,
      "grad_norm": 18.93171501159668,
      "learning_rate": 1.0639373262572657e-06,
      "epoch": 1.9002375296912115,
      "step": 8000
    },
    {
      "loss": 0.1424,
      "grad_norm": 0.31647276878356934,
      "learning_rate": 9.375789739701795e-07,
      "epoch": 1.9121140142517814,
      "step": 8050
    },
    {
      "loss": 0.1076,
      "grad_norm": 1.1400753259658813,
      "learning_rate": 8.112206216830932e-07,
      "epoch": 1.9239904988123515,
      "step": 8100
    },
    {
      "loss": 0.0797,
      "grad_norm": 0.06131032854318619,
      "learning_rate": 6.848622693960072e-07,
      "epoch": 1.9358669833729216,
      "step": 8150
    },
    {
      "loss": 0.126,
      "grad_norm": 24.947864532470703,
      "learning_rate": 5.58503917108921e-07,
      "epoch": 1.9477434679334917,
      "step": 8200
    },
    {
      "loss": 0.0985,
      "grad_norm": 0.40210145711898804,
      "learning_rate": 4.321455648218348e-07,
      "epoch": 1.9596199524940618,
      "step": 8250
    },
    {
      "loss": 0.1137,
      "grad_norm": 29.344711303710938,
      "learning_rate": 3.0578721253474856e-07,
      "epoch": 1.9714964370546317,
      "step": 8300
    },
    {
      "loss": 0.1052,
      "grad_norm": 9.415084838867188,
      "learning_rate": 1.7942886024766238e-07,
      "epoch": 1.9833729216152018,
      "step": 8350
    },
    {
      "loss": 0.0753,
      "grad_norm": 19.444738388061523,
      "learning_rate": 5.30705079605762e-08,
      "epoch": 1.995249406175772,
      "step": 8400
    },
    {
      "eval_loss": 0.29294347763061523,
      "eval_accuracy": 0.926605504587156,
      "eval_runtime": 1.3325,
      "eval_samples_per_second": 654.388,
      "eval_steps_per_second": 10.506,
      "epoch": 2.0,
      "step": 8420
    },
    {
      "train_runtime": 698.9002,
      "train_samples_per_second": 192.729,
      "train_steps_per_second": 12.047,
      "total_flos": 8860133233720320.0,
      "train_loss": 0.17823412404207606,
      "epoch": 2.0,
      "step": 8420
    },
    {
      "eval_loss": 0.29294347763061523,
      "eval_accuracy": 0.926605504587156,
      "eval_runtime": 1.3266,
      "eval_samples_per_second": 657.333,
      "eval_steps_per_second": 10.554,
      "epoch": 2.0,
      "step": 8420
    }
  ]
}